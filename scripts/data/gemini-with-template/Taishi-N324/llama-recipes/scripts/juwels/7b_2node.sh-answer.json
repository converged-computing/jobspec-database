{
    "application": "mpi",
    "software": [
        "mpirun",
        "python",
        "huggingface_hub",
        "transformers",
        "datasets",
        "torch",
        "fairscale",
        "wandb",
        "nvidia-smi"
    ],
    "modules": [
        "/p/project/ccstdl/nakamura2/miniconda3/bin/activate /p/project/ccstdl/nakamura2/llama-recipe-torch2.1_cuda-11.8"
    ],
    "environment_variables": {
        "NCCL_IB_TIMEOUT": "50",
        "UCX_RC_TIMEOUT": "4s",
        "NCCL_IB_RETRY_CNT": "10",
        "CUDA_VISIBLE_DEVICES": "0,1,2,3",
        "NCCL_ASYNC_ERROR_HANDLING": "1",
        "TOTAL_GPUS": "256",
        "MASTER_ADDR": "unknown",
        "HOSTNAMES": "unknown",
        "MASTER_PORT": "12802",
        "COUNT_NODE": "64",
        "NUM_GPUS": "256",
        "NUM_GPU_PER_NODE": "4",
        "NUM_NODES": "64",
        "GLOBAL_BATCH_SIZE": "4096",
        "GRADIENT_ACCUMULATION_STEPS": "16",
        "HOSTFILE_NAME": "./hostfile/hostfile_unknown"
    },
    "resources": {
        "gres": "gpu:4",
        "cpus_per_task": "10",
        "tasks": "256",
        "ntasks_per_code": "256",
        "gpus": "256",
        "gpus_per_node": "4",
        "cores_per_socket": "null",
        "gpus_per_task": "1",
        "exclusive": "null",
        "cpus_per_gpu": "2.5",
        "gpu_type": "null",
        "time": "null",
        "ntasks_per_node": "4",
        "nodes": "64",
        "memory": "null",
        "sockets_per_node": "null",
        "ntasks_per_socket": "null",
        "mem_per_gpu": "null",
        "mem_per_cpu": "null",
        "gres_flags": "gpu:4"
    },
    "versions": {
        "mpi": "null",
        "python": "null",
        "huggingface_hub": "null",
        "transformers": "null",
        "datasets": "null",
        "torch": "2.1",
        "fairscale": "null",
        "wandb": "null",
        "nvidia-smi": "null"
    }
}