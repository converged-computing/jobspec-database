{
    "application": "deepspeed",
    "software": [
        "deepspeed",
        "torch.distributed.run",
        "python",
        "finetune_t0.py"
    ],
    "modules": [
        "torch",
        "socket"
    ],
    "environment_variables": {
        "TRANSFORMERS_CACHE": "$six_ALL_CCFRWORK/models",
        "HF_DATASETS_CACHE": "$six_ALL_CCFRWORK/datasets",
        "HF_MODULES_CACHE": "$six_ALL_CCFRWORK/modules",
        "HF_METRICS_CACHE": "$six_ALL_CCFRWORK/metrics",
        "HF_DATASETS_OFFLINE": "1",
        "TRANSFORMERS_OFFLINE": "1",
        "MASTER_ADDR": "$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
        "MASTER_PORT": "6001",
        "GPUS_PER_NODE": "8",
        "NNODES": "$SLURM_NNODES",
        "PP_SIZE": "1",
        "TP_SIZE": "1",
        "MICRO_BATCH_SIZE": "4",
        "GLOBAL_BATCH_SIZE": "2048",
        "NLAYERS": "30",
        "NHIDDEN": "4096",
        "NHEADS": "32",
        "SEQ_LEN": "2048",
        "SAVE_INTERVAL": "2",
        "TRAIN_SAMPLES": "6_348_800",
        "LAUNCHER": "python -u -m torch.distributed.run \n    --nproc_per_node $GPUS_PER_NODE \n    --nnodes $NNODES \n    --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \n    --rdzv_backend c10d \n    --max_restarts 0 \n    --tee 3 \n    ",
        "CMD": " \n    `pwd`/finetune_t0.py \n    --tensor-model-parallel-size $TP_SIZE \n    --pipeline-model-parallel-size $PP_SIZE \n    $GPT_ARGS \n    $OUTPUT_ARGS \n    --save $CHECKPOINT_PATH \n    --load $CHECKPOINT_PATH \n    --train-weighted-split-paths-path $TRAIN_DATA_PATH \n    --valid-weighted-split-paths-path $VALID_DATA_PATH \n    --dataloader-type single \n    --data-impl mmap \n    --distributed-backend nccl \n     $DEEPSPEED_ARGS \n    ",
        "CUDA_LAUNCH_BLOCKING": "1",
        "TORCHELASTIC_ERROR_FILE": "/tmp/torch-elastic-error.json",
        "six_ALL_CCFRWORK": "$six_ALL_CCFRWORK",
        "six_ALL_CCFRSCRATCH": "$six_ALL_CCFRSCRATCH",
        "variant": "xp3capmixfixlong",
        "DATA_OUTPUT_PATH": "$six_ALL_CCFRSCRATCH/checkpoints/tr13f-6B3-ml-t0",
        "CHECKPOINT_PATH": "$DATA_OUTPUT_PATH/checkpoints/$variant",
        "REPO_PATH": "$DATA_OUTPUT_PATH/tr13f-6B3-ml-t0-logs",
        "TENSORBOARD_PATH": "$REPO_PATH/tensorboard/$variant",
        "LOGS_PATH": "$REPO_PATH/logs/$variant",
        "MEGATRON_DEEPSPEED_REPO": "/gpfswork/rech/six/commun/code/tr13f-6B3-ml-t0/Megatron-DeepSpeed",
        "KILL_SWITCH_PATH": "$MEGATRON_DEEPSPEED_REPO/kill-switch-tr13f-6B3-mtf",
        "TRAIN_DATA_PATH": "$six_ALL_CCFRWORK/code/tr13f-6B3-ml-t0/Megatron-DeepSpeed/data/xp3capmixfixlong_train.txt",
        "VALID_DATA_PATH": "$six_ALL_CCFRWORK/code/tr13f-6B3-ml-t0/Megatron-DeepSpeed/data/xp3capmixfixlong_validation.txt",
        "TOKENIZER_NAME_OR_PATH": "bigscience/tokenizer",
        "OPTIMIZER_ARGS": " \n    --optimizer adam \n    --adam-beta1 0.9 \n    --adam-beta2 0.95 \n    --adam-eps 1e-8 \n    --lr 2e-5 \n    --lr-decay-style constant \n    --lr-warmup-samples 0 \n    --clip-grad 1.0 \n    --weight-decay 1e-4 \n    --no-load-optim \n    ",
        "EXIT_OPTS": " \n    --exit-duration-in-mins 5990 \n    ",
        "GPT_ARGS": " \n    --pp-partition-method 'type:transformer|embedding' \n    --num-layers $NLAYERS \n    --hidden-size $NHIDDEN \n    --num-attention-heads $NHEADS \n    --seq-length $SEQ_LEN \n    --max-position-embeddings $SEQ_LEN \n    --micro-batch-size $MICRO_BATCH_SIZE \n    --global-batch-size $GLOBAL_BATCH_SIZE \n    --train-samples $TRAIN_SAMPLES \n    --tokenizer-type PretrainedFromHF \n    --tokenizer-name-or-path $TOKENIZER_NAME_OR_PATH \n    --init-method-std 0.0048 \n    --embed-layernorm \n    --fp16 \n    --seed 42 \n    --position-embedding-type alibi \n    --checkpoint-activations \n    --abort-on-unmet-fused-kernel-constraints \n    --kill-switch-path $KILL_SWITCH_PATH \n    --pad-vocab-size-to 250880 \n    $OPTIMIZER_ARGS \n    $EXIT_OPTS \n    ",
        "OUTPUT_ARGS": " \n    --log-interval 1 \n    --save-interval $SAVE_INTERVAL \n    --eval-interval 250 \n    --eval-iters 50 \n    --tensorboard-dir $TENSORBOARD_PATH \n    --tensorboard-queue-size 5 \n    --log-timers-to-tensorboard \n    --log-batch-size-to-tensorboard \n    --log-validation-ppl-to-tensorboard \n    ",
        "ZERO_STAGE": "1",
        "config_json": "./ds_config.$SLURM_JOBID.json",
        "DEEPSPEED_ARGS": " \n    --deepspeed \n    --deepspeed_config ${config_json} \n    --zero-stage ${ZERO_STAGE} \n    --deepspeed-activation-checkpointing \n    "
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "64",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "8",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "a100",
        "time": "100:00:00",
        "ntasks_per_node": "1",
        "nodes": "8",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": ""
    },
    "versions": {}
}