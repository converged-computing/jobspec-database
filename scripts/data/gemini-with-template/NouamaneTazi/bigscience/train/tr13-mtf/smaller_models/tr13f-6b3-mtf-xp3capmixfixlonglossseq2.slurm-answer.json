{
    "application": "deepspeed",
    "software": [
        "python",
        "torch",
        "deepspeed",
        "finetune_t0.py",
        "Megatron-DeepSpeed"
    ],
    "modules": [
        "six@a100"
    ],
    "environment_variables": {
        "TRANSFORMERS_CACHE": "$six_ALL_CCFRWORK/models",
        "HF_DATASETS_CACHE": "$six_ALL_CCFRWORK/datasets",
        "HF_MODULES_CACHE": "$six_ALL_CCFRWORK/modules",
        "HF_METRICS_CACHE": "$six_ALL_CCFRWORK/metrics",
        "HF_DATASETS_OFFLINE": "1",
        "TRANSFORMERS_OFFLINE": "1",
        "CUDA_LAUNCH_BLOCKING": "1",
        "TORCHELASTIC_ERROR_FILE": "/tmp/torch-elastic-error.json",
        "LAUNCHER": "python -u -m torch.distributed.run --nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT --rdzv_backend c10d --max_restarts 0 --tee 3 ",
        "CMD": " `pwd`/finetune_t0.py --tensor-model-parallel-size $TP_SIZE --pipeline-model-parallel-size $PP_SIZE  $GPT_ARGS  $OUTPUT_ARGS  --save $CHECKPOINT_PATH  --load $CHECKPOINT_PATH  --train-weighted-split-paths-path $TRAIN_DATA_PATH  --valid-weighted-split-paths-path $VALID_DATA_PATH  --dataloader-type single  --data-impl mmap  --distributed-backend nccl   $DEEPSPEED_ARGS "
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "64",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "8",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "a100",
        "time": "100:00:00",
        "ntasks_per_node": "1",
        "nodes": "8",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}