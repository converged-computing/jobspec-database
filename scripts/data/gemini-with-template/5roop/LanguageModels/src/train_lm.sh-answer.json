{
    "application": "pytorch",
    "software": [
        "transformers",
        "python"
    ],
    "modules": [],
    "environment_variables": {
        "config_sh": "Config sh file with experimental settings",
        "num_processes": "Number of processes",
        "SEED": "Random seed",
        "tpu_call": "Command to run on TPU",
        "pad_to_max": "Flag to pad to maximum length",
        "model_name_or_path": "Name or path of the model",
        "preprocessing_num_workers": "Number of workers for preprocessing",
        "tokenizer_name": "Name of the tokenizer",
        "model_type": "Type of the model",
        "max_steps": "Maximum number of training steps",
        "warmup_ratio": "Warmup ratio",
        "train_file": "Training file",
        "max_seq_length": "Maximum sequence length",
        "line_by_line": "Flag to train line by line",
        "output_dir": "Output directory",
        "do_train": "Flag to enable training",
        "per_device_train_batch_size": "Batch size per device",
        "overwrite_cache": "Flag to overwrite cache",
        "overwrite_output_dir": "Flag to overwrite output directory",
        "gradient_accumulation_steps": "Number of gradient accumulation steps",
        "save_steps": "Save steps",
        "learning_rate": "Learning rate",
        "logging_steps": "Logging steps",
        "piece_masking": "Flag to enable piece masking"
    },
    "resources": {
        "gres": "gpu:v100:1",
        "cpus_per_task": "16",
        "tasks": "1",
        "ntasks_per_code": "1",
        "gpus": "1",
        "gpus_per_node": "1",
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "v100",
        "time": "23:59:59",
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": "50G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": ""
    },
    "versions": {}
}