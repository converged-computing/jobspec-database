{
    "application": "python",
    "software": [
        "nvidia-smi",
        "torchrun",
        "python",
        "wandb",
        "transformers"
    ],
    "modules": [
        "eth_proxy",
        "gcc/11.4.0",
        "python/3.11.6",
        "cuda/12.1.1"
    ],
    "environment_variables": {
        "CONSUL_HTTP_ADDR": "",
        "WANDB__SERVICE_WAIT": "300",
        "TRANSFORMERS_CACHE": "/cluster/scratch/oovcharenko/dsl_hate_speech/cache/",
        "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:512",
        "CUDA_VISIBLE_DEVICES": "0,1"
    },
    "resources": {
        "gres": "gpumem:32G",
        "cpus_per_task": "16",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": "12:00:00",
        "ntasks_per_node": null,
        "nodes": "1",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": "12G",
        "gres_flags": null
    },
    "versions": {}
}