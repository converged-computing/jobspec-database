{
    "application": "LSF",
    "software": [
        "python",
        "pytorchlightning/pytorch_lightning:base-cuda-py3.9-torch1.9"
    ],
    "modules": [],
    "environment_variables": {
        "LSF_DOCKER_SHM_SIZE": "16g",
        "LSF_DOCKER_VOLUMES": "$HOME:$HOME $SCRATCH1:$SCRATCH1 $STORAGE1:$STORAGE1",
        "extra_param": "the output of the 'head -n $LSB_JOBINDEX | tail -1' command on the param_list"
    },
    "resources": {
        "gres": "gpu:TeslaV100_SXM2_32GB",
        "cpus_per_task": "8",
        "tasks": "1",
        "ntasks_per_code": "1",
        "gpus": "1",
        "gpus_per_node": "1",
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": "exclusive_process",
        "cpus_per_gpu": "8",
        "gpu_type": "TeslaV100_SXM2_32GB",
        "time": null,
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": "64GB",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": "mode=exclusive_process"
    },
    "versions": {}
}