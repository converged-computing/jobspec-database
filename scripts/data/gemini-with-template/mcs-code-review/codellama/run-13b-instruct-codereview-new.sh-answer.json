{
    "application": "slurm",
    "software": [
        "torchrun",
        "python",
        "code_review_instructions.py"
    ],
    "modules": [
        "foss/2022a",
        "CUDA/12.2.0",
        "NCCL/2.19.4-CUDA-12.2.0",
        "UCX-CUDA/1.14.1-CUDA-12.2.0",
        "cuDNN/8.9.3.28-CUDA-12.2.0",
        "GCCcore/11.3.0",
        "Python/3.10.4"
    ],
    "environment_variables": {
        "ckpt_dir": "./ckpt/CodeLlama-13b-Instruct/",
        "tokenizer_path": "./ckpt/CodeLlama-13b-Instruct/tokenizer.model",
        "conf_path": "../config/codellama-13b-instruct-codereview-new.json",
        "temperature": "0.0",
        "top_p": "0.95",
        "max_seq_len": "4096",
        "max_batch_size": "10",
        "debug": "True"
    },
    "resources": {
        "gres": "gpu:2",
        "cpus_per_task": "8",
        "tasks": "1",
        "ntasks_per_code": null,
        "gpus": "2",
        "gpus_per_node": "2",
        "cores_per_socket": null,
        "gpus_per_task": "2",
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": "24:0:00",
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}