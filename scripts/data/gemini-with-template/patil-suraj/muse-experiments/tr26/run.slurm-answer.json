{
    "application": "muse",
    "software": [
        "conda",
        "python",
        "torch",
        "torch.distributed",
        "torch.distributed.run",
        "nccl",
        "srun",
        "bash",
        "CUDA",
        "py-spy",
        "slurm"
    ],
    "modules": [],
    "environment_variables": {
        "CUDA_VISIBLE_DEVICES": "${SLURM_STEP_GPUS:-$SLURM_JOB_GPUS}",
        "MASTER_ADDR": "$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
        "MASTER_PORT": "6000",
        "LAUNCHER": "python -u -m torch.distributed.run \n    --nproc_per_node $GPUS_PER_NODE \n    --nnodes $NNODES \n    --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \n    --rdzv_backend c10d \n    --max_restarts 0 \n    --tee 3 \n    ",
        "TORCHELASTIC_ERROR_FILE": "/tmp/torch-elastic-error.json",
        "NCCL_ASYNC_ERROR_HANDLING": "1",
        "NCCL_DEBUG": "INFO",
        "NCCL_DEBUG_SUBSYS": "COLL",
        "NCCL_SOCKET_NTHREADS": "1",
        "NCCL_NSOCKS_PERTHREAD": "1",
        "CUDA_LAUNCH_BLOCKING": "1",
        "NCCL_PROTO": "simple",
        "RDMAV_FORK_SAFE": "1",
        "FI_EFA_FORK_SAFE": "1",
        "FI_EFA_USE_DEVICE_RDMA": "1",
        "FI_PROVIDER": "efa",
        "FI_LOG_LEVEL": "1",
        "NCCL_IB_DISABLE": "1",
        "NCCL_SOCKET_IFNAME": "ens",
        "SRUN_ARGS": " \n    --wait=60 \n    --kill-on-bad-exit=1 \n    "
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "96",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "8",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": true,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": null,
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}