{
    "application": "slurm",
    "software": [
        "python",
        "tools/generate_samples_gpt.py"
    ],
    "modules": [
        "cuda/11.7",
        "cudnn/cuda-11.x/8.9.0",
        "nccl/cuda-11.7/2.14.3",
        "openmpi/4.0.5"
    ],
    "environment_variables": {
        "CHECKPOINT_PATH": "checkpoints/gpt-fugaku/350m_dp512",
        "VOCAB_FILE": "gpt2-vocab.json",
        "MERGE_FILE": "gpt2-merges.txt",
        "MAX_OUTPUT_SEQUENCE_LENGTH": "1024",
        "TEMPERATURE": "1.0",
        "TOP_P": "0.9",
        "NUMBER_OF_SAMPLES": "2",
        "OUTPUT_FILE": "text-generation.json",
        "INPUT_PREFIX": "dataset"
    },
    "resources": {
        "gres": "",
        "cpus_per_task": "",
        "tasks": "",
        "ntasks_per_code": "",
        "gpus": "1",
        "gpus_per_node": "1",
        "cores_per_socket": "",
        "gpus_per_task": "1",
        "exclusive": "",
        "cpus_per_gpu": "",
        "gpu_type": "a100_1",
        "time": "1-00:00:00",
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": "",
        "sockets_per_node": "",
        "ntasks_per_socket": "",
        "mem_per_gpu": "",
        "mem_per_cpu": "",
        "gres_flags": ""
    },
    "versions": {
        "cuda": "11.7",
        "cudnn": "8.9.0",
        "nccl": "2.14.3",
        "openmpi": "4.0.5"
    }
}