{
    "application": "pytorch",
    "software": [
        "pip",
        "torchrun",
        "llama-recipes",
        "torch",
        "torchvision",
        "torchaudio",
        "examples/finetuning.py"
    ],
    "modules": [],
    "environment_variables": {
        "FI_PROVIDER": "efa",
        "LOGLEVEL": "INFO",
        "NCCL_DEBUG": "WARN",
        "NCCL_DEBUG_SUBSYS": "WARN",
        "PYTHONFAULTHANDLER": "1",
        "LD_LIBRARY_PATH": "/usr/local/lib/:$LD_LIBRARY_PATH",
        "CUDA_LAUNCH_BLOCKING": "0",
        "NCCL_SOCKET_IFNAME": "ibs14f0,ibs14f1",
        "FI_EFA_USE_DEVICE_RDMA": "1"
    },
    "resources": {
        "gres": null,
        "cpus_per_task": null,
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": "8",
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "A100",
        "time": null,
        "ntasks_per_node": "8",
        "nodes": "2",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}