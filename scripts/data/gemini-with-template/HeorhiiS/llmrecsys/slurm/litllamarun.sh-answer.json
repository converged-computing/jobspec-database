{
    "application": "lit-llama",
    "software": [
        "python",
        "conda",
        "lit-llama",
        "gcc"
    ],
    "modules": [
        "gcc"
    ],
    "environment_variables": {
        "TARGETFOLDER": "llamadownloads"
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "40",
        "tasks": "8",
        "ntasks_per_code": "8",
        "gpus": "8",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": null,
        "cpus_per_gpu": "5",
        "gpu_type": null,
        "time": "5:30:00",
        "ntasks_per_node": "8",
        "nodes": "1",
        "memory": "480G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": "60G",
        "mem_per_cpu": "12G",
        "gres_flags": null
    },
    "versions": {
        "conda": null,
        "gcc": null,
        "lit-llama": null
    }
}