{
    "application": "megatron-lm",
    "software": [
        "conda",
        "torch.distributed.run",
        "srun",
        "bash",
        "python",
        "nvidia-smi",
        "nccl",
        "efa",
        "cuda",
        "pytorch",
        "wandb",
        "tensorboard"
    ],
    "modules": [
        "megatron"
    ],
    "environment_variables": {
        "SCRIPT_REPO": "/fsx/loubna/code/Megatron-LM",
        "LOG_PATH": "/fsx/loubna/code/Megatron-LM/main_log.txt",
        "GPUS_PER_NODE": "8",
        "MASTER_ADDR": null,
        "MASTER_PORT": "6000",
        "NNODES": null,
        "NODE_RANK": null,
        "WORLD_SIZE": null,
        "CHECKPOINT_PATH": "/fsx/bigcode/experiments/pretraining/7b-starcoder",
        "TOKENIZER_FILE": "/fsx/bigcode/bigcode-training/tokenizer-starcoder/tokenizer.json",
        "WEIGHTS_TRAIN": "/fsx/bigcode/bigcode-training/code/bigcode-data-mix/data/train_data_paths.txt.tmp",
        "WEIGHTS_VALID": "/fsx/bigcode/bigcode-training/code/bigcode-data-mix/data/valid_data_paths.txt.tmp",
        "GPT_ARGS": "       --tensor-model-parallel-size 2 \n       --pipeline-model-parallel-size 1 \n       --num-layers 42 \n       --hidden-size 4096 \n       --num-attention-heads 32 \n       --attention-head-type multiquery \n       --init-method-std 0.015625 \n       --seq-length 8192 \n       --max-position-embeddings 8192 \n       --attention-dropout 0.1 \n       --hidden-dropout 0.1 \n       --micro-batch-size 1 \n       --global-batch-size 512 \n       --lr 0.0003 \n       --min-lr 0.00003 \n       --train-iters 250000 \n       --lr-decay-iters 250000 \n       --lr-decay-style cosine \n       --lr-warmup-iters 2000 \n       --weight-decay .1 \n       --adam-beta2 .95 \n       --clip-grad 1.0 \n       --bf16 \n       --use-flash-attn \n       --fim-rate 0.5 \n       --log-interval 10 \n       --save-interval 2500 \n       --eval-interval 2500 \n       --eval-iters 2 \n       --use-distributed-optimizer \n       --valid-num-workers 0 \n",
        "TENSORBOARD_ARGS": "--tensorboard-dir ${CHECKPOINT_PATH}/tensorboard",
        "CMD": "     /fsx/loubna/code/Megatron-LM/pretrain_gpt.py \n    $GPT_ARGS \n    --tokenizer-type TokenizerFromFile \n    --tokenizer-file $TOKENIZER_FILE \n    --save $CHECKPOINT_PATH \n    --load $CHECKPOINT_PATH \n    --train-weighted-split-paths-path $WEIGHTS_TRAIN \n    --valid-weighted-split-paths-path $WEIGHTS_VALID \n    --structured-logs \n    --structured-logs-dir $CHECKPOINT_PATH/logs \n    $TENSORBOARD_ARGS \n    --wandb-entity-name loubnabnl \n    --wandb-project-name bigcode-pretraining \n    ",
        "LAUNCHER": "python -u -m torch.distributed.run \n    --nproc_per_node $GPUS_PER_NODE \n    --nnodes $NNODES \n    --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT \n    --rdzv_backend c10d \n    --max_restarts 0 \n    --tee 3 \n    ",
        "TORCHELASTIC_ERROR_FILE": "/tmp/torch-elastic-error.json",
        "NCCL_ASYNC_ERROR_HANDLING": "1",
        "NCCL_DEBUG": "INFO",
        "NCCL_DEBUG_SUBSYS": "COLL",
        "NCCL_SOCKET_NTHREADS": "1",
        "NCCL_NSOCKS_PERTHREAD": "1",
        "CUDA_LAUNCH_BLOCKING": "1",
        "NCCL_PROTO": "simple",
        "RDMAV_FORK_SAFE": "1",
        "FI_EFA_FORK_SAFE": "1",
        "FI_EFA_USE_DEVICE_RDMA": "1",
        "FI_PROVIDER": "efa",
        "FI_LOG_LEVEL": "1",
        "NCCL_IB_DISABLE": "1",
        "NCCL_SOCKET_IFNAME": "ens",
        "CUDA_HOME": "/usr/local/cuda-11.6",
        "PATH": "/usr/local/cuda-11.6/bin:$PATH",
        "LD_LIBRARY_PATH": "/usr/local/cuda-11.6/lib64:$LD_LIBRARY_PATH",
        "LD_PRELOAD": "$CUDA_HOME/lib/libnccl.so",
        "SRUN_ARGS": "     --wait=60 \n    --kill-on-bad-exit=1 \n    "
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "38",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": null,
        "ntasks_per_node": "1",
        "nodes": "64",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}