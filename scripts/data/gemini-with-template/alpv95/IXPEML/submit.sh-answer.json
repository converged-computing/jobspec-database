{
    "application": "slurm",
    "software": [
        "python3",
        "nvidia-smi",
        "run_ensemble_eval.py"
    ],
    "modules": [
        "gsl",
        "python/3.9",
        "py-scipy/1.6.3_py39",
        "viz",
        "py-matplotlib/3.4.2_py39",
        "cmake/3.13.1",
        "py-numpy/1.20.3_py39",
        "cudnn/8.1.1.33",
        "py-pytorch/1.8.1_py39",
        "cuda/11.1.1"
    ],
    "environment_variables": {
        "N": "9"
    },
    "resources": {
        "gres": "gpu:1",
        "cpus_per_task": "2",
        "tasks": "1",
        "ntasks_per_code": null,
        "gpus": "1",
        "gpus_per_node": null,
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "GEFORCE",
        "time": "120:00",
        "ntasks_per_node": null,
        "nodes": null,
        "memory": "50G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": "16GB",
        "mem_per_cpu": null,
        "gres_flags": "-C GPU_MEM:16GB\n-C GPU_BRD:GEFORCE\n-C GPU_SKU:RTX_2080Ti\n-C GPU_CC:7.5"
    },
    "versions": {}
}