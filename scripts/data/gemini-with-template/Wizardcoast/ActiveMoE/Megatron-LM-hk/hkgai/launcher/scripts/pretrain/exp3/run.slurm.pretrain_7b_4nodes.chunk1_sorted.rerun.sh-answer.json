{
    "application": "slurm",
    "software": [
        "docker",
        "bash",
        "nvidia-docker",
        "hkgai/launcher/scripts/pretrain/exp3/pretrain.sh",
        "pytorch:23.10-py3"
    ],
    "modules": [],
    "environment_variables": {
        "LOGLEVEL": "INFO",
        "WANDB_API_KEY": "YourOwnWandbAPIKey",
        "PROJECT_ROOT": "/aifs4su/code/",
        "TASK_ID": "exp3.6",
        "CUDA_DEVICE_MAX_CONNECTIONS": "10",
        "OMP_NUM_THREADS": "10",
        "DATA_PATH": "/workspace/megatron/slimpajama-icp-chunk1_sorted-8node_text_document",
        "DATA_CACHE_PATH": "/workspace/megatron/slimpajama-icp-chunk1_sorted-8node_text_document",
        "TOKENIZER_MODEL_PATH": "/workspace/megatron/baichuan.tokenizer.model",
        "ENABLE_SHUFFLE": "false",
        "NCCL_SOCKET_IFNAME": "ibp",
        "NCCL_IB_HCA": "mlx5",
        "NCCL_DEBUG_SUBSYS": "ALL",
        "GPUS_PER_NODE": "8",
        "MASTER_ADDR": "head_node_ip",
        "MASTER_PORT": "6000",
        "NODE_RANK": "SLURM_PROCID",
        "NNODES": "4",
        "GRAD_ACC_STEPS": "2"
    },
    "resources": {
        "gres": null,
        "cpus_per_task": "200",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "all",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": true,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": null,
        "ntasks_per_node": "1",
        "nodes": "4",
        "memory": "1024G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}