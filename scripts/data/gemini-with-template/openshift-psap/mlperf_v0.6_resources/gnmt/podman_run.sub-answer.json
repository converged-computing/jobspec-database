{
    "application": "slurm",
    "software": [
        "podman",
        "nvidia-docker",
        "python3",
        "torch",
        "mlperf_compliance",
        "mlperf_log_utils",
        "preprocess_data.py",
        "run_and_time.sh",
        "config_DGX1.sh"
    ],
    "modules": [],
    "environment_variables": {
        "DATESTAMP": null,
        "BENCHMARK": "rnn_translator",
        "BENCHMARK_NAME": "GNMT",
        "CONT": "mlperf-nvidia:rnn_translator",
        "DATADIR": "/raid/data/wmt16_de_en",
        "PREPROC_DATADIR": "/raid/scratch/gnmt",
        "LOGDIR": "/raid/results/rnn_translator",
        "NEXP": 10,
        "SYSLOGGING": 1,
        "PREPROCESS": 1,
        "SYS_LOG_GET": "'import mlperf_compliance; from mlperf_log_utils import mlperf_submission_log; mlperf_submission_log(mlperf_compliance.constants.GNMT)'",
        "DGXSYSTEM": "DGX1",
        "IBDEVICES": null,
        "INSLURM": 1,
        "LOGFILE_BASE": null,
        "CONTVOLS": "-v /raid/data/wmt16_de_en:/data -v /raid/results/rnn_translator:/results -v /raid/scratch/gnmt:/preproc_data",
        "DOCKEREXEC": "env NV_GPU=${NV_GPU} podman run --rm --net=host --uts=host --ipc=host --ulimit stack=67108864 --ulimit memlock=-1 -e NVIDIA_VISIBLE_DEVICES=ALL --cap-drop=ALL --security-opt label=type:nvidia_container_t --security-opt seccomp=unconfined --name=cont_${SLURM_JOB_ID} $NVIDIA_DEVICES",
        "MLPERF_HOST_OS": null,
        "MASTER_IP": null,
        "PORT": null,
        "SSH": null,
        "SRUN": null,
        "PULL": null,
        "DOCKERPULL": "podman pull mlperf-nvidia:rnn_translator",
        "VARS": [
            "-e",
            "SLURM_NNODES=$SLURM_NNODES",
            "-e",
            "MLPERF_HOST_OS"
        ],
        "VARS_STR": "-e SLURM_NNODES=$SLURM_NNODES -e MLPERF_HOST_OS",
        "LOG_COMPLIANCE": "'import mlperf_compliance; mlperf_compliance.mlperf_log.mlperf_print(mlperf_compliance.constants.CACHE_CLEAR, value=True, stack_offset=0)'",
        "MULTI_NODE": null,
        "DOCKERENV": [
            "-e",
            "DGXSYSTEM=$DGXSYSTEM",
            "-e",
            "MULTI_NODE=$MULTI_NODE",
            "-e",
            "LR=$LR",
            "-e",
            "TRAIN_BATCH_SIZE=$TRAIN_BATCH_SIZE",
            "-e",
            "TEST_BATCH_SIZE=$TEST_BATCH_SIZE",
            "-e",
            "WARMUP_STEPS=$WARMUP_STEPS",
            "-e",
            "REMAIN_STEPS=$REMAIN_STEPS",
            "-e",
            "DECAY_INTERVAL=$DECAY_INTERVAL",
            "-e",
            "TARGET=$TARGET",
            "-e",
            "NUMEPOCHS=$NUMEPOCHS",
            "-e",
            "MAX_SEQ_LEN=$MAX_SEQ_LEN",
            "-e",
            "EXTRA_OPTS=$EXTRA_OPTS",
            "-e",
            "SLURM_JOB_ID=$SLURM_JOB_ID",
            "-e",
            "SLURM_NTASKS_PER_NODE=$SLURM_NTASKS_PER_NODE",
            "-e",
            "SLURM_NNODES=$SLURM_NNODES"
        ],
        "nrun": null,
        "h": null,
        "hostn": null
    },
    "resources": {
        "gres": null,
        "cpus_per_task": "2",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": null,
        "cores_per_socket": "20",
        "gpus_per_task": "1",
        "exclusive": "True",
        "cpus_per_gpu": "20",
        "gpu_type": null,
        "time": "12:00:00",
        "ntasks_per_node": "8",
        "nodes": "1",
        "memory": "0",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}