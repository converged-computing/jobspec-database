{
    "application": "ollama",
    "software": [
        "ollama",
        "python3"
    ],
    "modules": [
        "cuda/12.1.0"
    ],
    "environment_variables": {
        "OLLAMA_DEBUG": "1",
        "OLLAMA_NUM_PARALLEL": "4",
        "OLLAMA_MAX_LOADED": "4",
        "OLLAMA_HOST": "0.0.0.0",
        "BASE_LOG_PATH": "/scratch/$USER/JOB-$SLURM_JOB_ID/"
    },
    "resources": {
        "gres": "gpu:3",
        "cpus_per_task": "12",
        "tasks": "1",
        "ntasks_per_code": "1",
        "gpus": "3",
        "gpus_per_node": "3",
        "cores_per_socket": null,
        "gpus_per_task": "3",
        "exclusive": null,
        "cpus_per_gpu": "4",
        "gpu_type": null,
        "time": "2:00:00",
        "ntasks_per_node": "1",
        "nodes": "1",
        "memory": "100G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}