{
    "application": "lm_eval",
    "software": [
        "python3",
        "nvidia-smi",
        "lm_eval"
    ],
    "modules": [
        "cuda/12.1"
    ],
    "environment_variables": {
        "model_path": "/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2/1000",
        "model_name": "llama_both_1000it"
    },
    "resources": {
        "gres": "gpu:1",
        "cpus_per_task": "16",
        "tasks": "1",
        "ntasks_per_code": "1",
        "gpus": "1",
        "gpus_per_node": "1",
        "cores_per_socket": null,
        "gpus_per_task": "1",
        "exclusive": "process",
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": "24:00",
        "ntasks_per_node": null,
        "nodes": "1",
        "memory": "11800MB",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": ""
    },
    "versions": {
        "cuda": "12.1"
    }
}