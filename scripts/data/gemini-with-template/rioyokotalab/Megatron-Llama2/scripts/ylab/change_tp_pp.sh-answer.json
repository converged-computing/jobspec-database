{
    "application": "slurm",
    "software": [
        "python",
        "openmpi"
    ],
    "modules": [
        "cuda/11.8",
        "cudnn/cuda-11.x/8.9.0",
        "nccl/cuda-11.7/2.14.3",
        "openmpi/4.0.5"
    ],
    "environment_variables": {
        "TARGET_TENSOR_PARALLEL_SIZE": "1",
        "TARGET_PIPELINE_PARALLEL_SIZE": "1",
        "BASE_TENSOR_PARALLEL_SIZE": "8",
        "BASE_PIPELINE_PARALLEL_SIZE": "8",
        "BASE_CHECKPOINT_DIR": "/home/kazuki/checkpoints/llama-2-70b-base/tp8-pp8",
        "TARGET_CHECKPOINT_DIR": "/home/kazuki/checkpoints/llama-2-70b-base/tp1-pp1",
        "TOKENIZER_MODEL": "/home/kazuki/hf_models/Llama-2-7b-hf/tokenizer.model",
        "ITERATION": "5000"
    },
    "resources": {
        "gres": null,
        "cpus_per_task": null,
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": null,
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "dgx-a100_8",
        "time": "6:00:00",
        "ntasks_per_node": null,
        "nodes": null,
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}