{
    "application": "pytorch",
    "software": [
        "torchrun",
        "python",
        "pretrain_llama.py"
    ],
    "modules": [],
    "environment_variables": {
        "NCCL_SOCKET_IFNAME": "ens",
        "NCCL_ASYNC_ERROR_HANDLING": "1",
        "NCCL_DEBUG": "INFO",
        "CUDA_DEVICE_MAX_CONNECTIONS": "1",
        "WANDB_API_KEY": "334c1fea66a31bc72bbfc9bb2244852031413811",
        "PYTHONPATH": "/workspace/Pai-Megatron-Patch-Llama3-70B/Megatron-LM:/workspace/Pai-Megatron-Patch-Llama3-70B:$PYTHONPATH"
    },
    "resources": {
        "gres": "",
        "cpus_per_task": "",
        "tasks": "",
        "ntasks_per_code": "",
        "gpus": "",
        "gpus_per_node": "8",
        "cores_per_socket": "",
        "gpus_per_task": "",
        "exclusive": "1",
        "cpus_per_gpu": "",
        "gpu_type": "A100",
        "time": "",
        "ntasks_per_node": "",
        "nodes": "4",
        "memory": "",
        "sockets_per_node": "",
        "ntasks_per_socket": "",
        "mem_per_gpu": "",
        "mem_per_cpu": "",
        "gres_flags": ""
    },
    "versions": {}
}