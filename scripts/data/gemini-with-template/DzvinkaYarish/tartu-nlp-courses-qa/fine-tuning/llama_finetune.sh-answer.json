{
    "application": "llama_finetune",
    "software": [
        "gcc",
        "nvidia-smi",
        "conda",
        "python3.10"
    ],
    "modules": [
        "cuda/11.7.0",
        "any/python/3.8.3-conda"
    ],
    "environment_variables": {
        "ROOT": "/gpfs/space/projects/stud_ml_22/NLP",
        "RUN_NAME": "a100_longer_training_vicuna"
    },
    "resources": {
        "gres": "gpu:a100-40g",
        "cpus_per_task": "4",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": null,
        "gpus_per_node": null,
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": null,
        "gpu_type": "a100-40g",
        "time": "4000",
        "ntasks_per_node": null,
        "nodes": null,
        "memory": "32G",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {
        "gcc": null,
        "python": "3.10"
    }
}