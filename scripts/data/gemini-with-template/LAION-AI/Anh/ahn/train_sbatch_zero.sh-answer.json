{
    "application": "pytorch",
    "software": [
        "torchrun",
        "train_zero.py"
    ],
    "modules": [
        "miniconda3"
    ],
    "environment_variables": {
        "TRANSFORMERS_CACHE": "/mnt/nvme/home/ryan01/.cache/huggingface/transformers",
        "HF_DATASETS_CACHE": "/mnt/nvme/home/ryan01/.cache/huggingface/datasets",
        "TORCH_HOME": "/mnt/nvme/home/ryan01/.cache/torch",
        "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:512",
        "OMP_NUM_THREADS": "1",
        "GPUS_PER_NODE": "8",
        "MASTER_ADDR": "$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
        "MASTER_PORT": "9901"
    },
    "resources": {
        "gres": "gpu:8",
        "cpus_per_task": "4",
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "8",
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": null,
        "cpus_per_gpu": "4",
        "gpu_type": "a100",
        "time": "14-0:00",
        "ntasks_per_node": "8",
        "nodes": "1",
        "memory": "10GB",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}