{
    "application": "slurm",
    "software": [
        "singularity",
        "parallel",
        "python",
        "nvidia-smi",
        "lscpu",
        "zip"
    ],
    "modules": [
        "singularity/3.3.0",
        "parallel/20180222"
    ],
    "environment_variables": {
        "SLURM_SUBMIT_DIR": "Directory from which the job was submitted",
        "PBS_NODEFILE": "File containing list of cores available to the job",
        "PBS_GPUFILE": "File containing list of GPUs available to the job",
        "SLURM_JOBID": "Job ID (e.g., 107619.master.cluster)",
        "SLURM_NTASKS": "Number of cores allocated to the job",
        "HOME": "Home directory. Use for permanent files.",
        "WORK": "Work directory. Use for fast I/O.",
        "TMPFS": "File system set up in memory for this job. Use for very fast, small I/O",
        "TMPDIR": "Local disk (hard drive) space set up for this job"
    },
    "resources": {
        "gres": "gpu:1",
        "cpus_per_task": null,
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "1",
        "gpus_per_node": null,
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": "true",
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": "48:00:00",
        "ntasks_per_node": null,
        "nodes": "1",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": null
    },
    "versions": {}
}