{
    "application": "deepspeed",
    "software": [
        "singularity",
        "deepspeed",
        "megatron-lm",
        "pytorch",
        "gcc",
        "g++",
        "python",
        "tensorboard"
    ],
    "modules": [],
    "environment_variables": {
        "MASTER_ADDR": null,
        "MASTER_PORT": "9999",
        "WORLD_SIZE": null,
        "CC": "gcc-10",
        "CXX": "g++-10",
        "CONTAINER": "pytorch-lumi_sles-rocm-5.5.1-python-3.10-pytorch-v2.0.1-apex-torchvision-torchdata-torchtext-torchaudio.sif",
        "SING_BIND": "/scratch/project_462000273,/flash/project_462000273",
        "LD_LIBRARY_PATH": null,
        "LEARNING_RATE": "1.5e-4",
        "CHECKPOINT_PATH": "checkpoints",
        "TENSORBOARD_PATH": "tensorboard",
        "TRAIN_DATA_PATH": "train-data.txt",
        "VALID_DATA_PATH": "validation-data.txt",
        "TOKENIZER_PATH": "tokenizer",
        "PP_SIZE": "1",
        "TP_SIZE": "1",
        "MICRO_BATCH_SIZE": "2",
        "GLOBAL_BATCH_SIZE": "1024",
        "TRAIN_SAMPLES": "146500000",
        "LR_DECAY_SAMPLES": "146500000",
        "LR_WARMUP_SAMPLES": "1465000",
        "NLAYERS": "32",
        "NHIDDEN": "2560",
        "NHEADS": "32",
        "FFN_HIDDEN_SIZE": "10240",
        "SEQ_LEN": "2048",
        "SAVE_INTERVAL": "1000",
        "OPTIMIZER_ARGS": "     --optimizer adam     --adam-beta1 0.9     --adam-beta2 0.95     --adam-eps 1e-8     --lr 1.5e-4     --min-lr 2e-5     --lr-decay-style cosine     --lr-decay-samples 146500000     --lr-warmup-samples 1465000     --clip-grad 1.0     --weight-decay 1e-1     ",
        "GPT_ARGS": "     --num-layers 32     --hidden-size 2560     --num-attention-heads 32     --ffn-hidden-size 10240     --seq-length 2048     --max-position-embeddings 2048     --micro-batch-size 2     --global-batch-size 1024     --train-samples 146500000     --tokenizer-type GPT2BPETokenizer     --vocab-file vocab.json     --merge-file merges.txt     --init-method-std 0.0048     --embed-layernorm     --sync-tp-duplicated-parameters     --bf16     --seed 42     --position-embedding-type alibi     --checkpoint-activations     --make-vocab-size-divisible-by 128     --optimizer adam     --adam-beta1 0.9     --adam-beta2 0.95     --adam-eps 1e-8     --lr 1.5e-4     --min-lr 2e-5     --lr-decay-style cosine     --lr-decay-samples 146500000     --lr-warmup-samples 1465000     --clip-grad 1.0     --weight-decay 1e-1     ",
        "OUTPUT_ARGS": "     --log-interval 1     --save-interval 1000     --eval-interval 100     --eval-iters 100     --tensorboard-dir tensorboard     --tensorboard-queue-size 5     --log-timers-to-tensorboard     --log-batch-size-to-tensorboard     --log-validation-ppl-to-tensorboard     ",
        "ZERO_STAGE": "0",
        "DS_CONFIG_PATH": "ds_configs/1975123.json",
        "BIND_MASK_1": "0xfe0000000000,0xfe000000000000,0xfe0000,0xfe000000,0xfe,0xfe00,0xfe000000,0xfe00000000",
        "BIND_MASK_2": "0xfe000000000000fe0000000000,0xfe000000000000fe000000000000,0xfe000000000000fe0000,0xfe000000000000fe000000,0xfe000000000000fe,0xfe000000000000fe00,0xfe000000000000fe00000000,0xfe000000000000fe0000000000",
        "BIND_MASK": "0xfe0000000000,0xfe000000000000,0xfe0000,0xfe000000,0xfe,0xfe00,0xfe000000,0xfe00000000",
        "CMD": "     Megatron-DeepSpeed/pretrain_gpt.py     --tensor-model-parallel-size 1     --pipeline-model-parallel-size 1     --num-layers 32     --hidden-size 2560     --num-attention-heads 32     --ffn-hidden-size 10240     --seq-length 2048     --max-position-embeddings 2048     --micro-batch-size 2     --global-batch-size 1024     --train-samples 146500000     --tokenizer-type GPT2BPETokenizer     --vocab-file vocab.json     --merge-file merges.txt     --init-method-std 0.0048     --embed-layernorm     --sync-tp-duplicated-parameters     --bf16     --seed 42     --position-embedding-type alibi     --checkpoint-activations     --make-vocab-size-divisible-by 128     --optimizer adam     --adam-beta1 0.9     --adam-beta2 0.95     --adam-eps 1e-8     --lr 1.5e-4     --min-lr 2e-5     --lr-decay-style cosine     --lr-decay-samples 146500000     --lr-warmup-samples 1465000     --clip-grad 1.0     --weight-decay 1e-1     --log-interval 1     --save-interval 1000     --eval-interval 100     --eval-iters 100     --tensorboard-dir tensorboard     --tensorboard-queue-size 5     --log-timers-to-tensorboard     --log-batch-size-to-tensorboard     --log-validation-ppl-to-tensorboard     --save checkpoints     --load checkpoints     --train-weighted-split-paths-path train-data.txt     --valid-weighted-split-paths-path validation-data.txt     --data-impl mmap     --dataloader-type single     --num-workers 2     --deepspeed     --deepspeed_config ds_configs/1975123.json     --zero-stage 0     "
    },
    "resources": {
        "gres": "mi250:8",
        "cpus_per_task": null,
        "tasks": null,
        "ntasks_per_code": null,
        "gpus": "8",
        "gpus_per_node": "mi250:8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": "user",
        "cpus_per_gpu": null,
        "gpu_type": "mi250",
        "time": "0-00:30:00",
        "ntasks_per_node": "8",
        "nodes": "1",
        "memory": "0",
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": ""
    },
    "versions": {}
}