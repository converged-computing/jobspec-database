{
    "application": "litgpt",
    "software": [
        "gcloud",
        "srun",
        "bash",
        "docker"
    ],
    "modules": [],
    "environment_variables": {
        "MODEL_NAME": "'Llama-2-70b-hf'",
        "GCS_EXPERIMENT_BUCKET": "# myBucket",
        "EXPERIMENT_ROOT_DIR": "# llama-2/training_logs",
        "UDS_PATH": "/run/tcpx-${SLURM_JOB_ID}"
    },
    "resources": {
        "gres": "",
        "cpus_per_task": "1",
        "tasks": "1",
        "ntasks_per_code": "1",
        "gpus": null,
        "gpus_per_node": "8",
        "cores_per_socket": null,
        "gpus_per_task": null,
        "exclusive": true,
        "cpus_per_gpu": null,
        "gpu_type": null,
        "time": null,
        "ntasks_per_node": "1",
        "nodes": "4",
        "memory": null,
        "sockets_per_node": null,
        "ntasks_per_socket": null,
        "mem_per_gpu": null,
        "mem_per_cpu": null,
        "gres_flags": ""
    },
    "versions": {}
}