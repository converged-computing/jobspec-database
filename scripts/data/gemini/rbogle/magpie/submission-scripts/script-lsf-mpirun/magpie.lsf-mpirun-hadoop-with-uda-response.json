{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Magpie\",\n  \"details\": {\n    \"software\": {\n      \"hadoop\": {\n        \"versions\": [\n          \"1.0\",\n          \"2.0\"\n        ],\n        \"modes\": [\n          \"terasort\",\n          \"script\",\n          \"interactive\",\n          \"upgradehdfs\",\n          \"decommissionhdfsnodes\",\n          \"launch\",\n          \"setuponly\",\n          \"hdfsonly\"\n        ],\n        \"filesystem_modes\": [\n          \"hdfs\",\n          \"hdfsoverlustre\",\n          \"hdfsovernetworkfs\",\n          \"rawnetworkfs\"\n        ],\n        \"configurations\": {\n          \"HADOOP_HOME\": {\n            \"description\": \"Path to your Hadoop build/binaries\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/hadoop-2.8.0\"\n          },\n          \"HADOOP_VERSION\": {\n            \"description\": \"Version of Hadoop\",\n            \"type\": \"string\",\n            \"example\": \"2.8.0\"\n          },\n          \"HADOOP_SETUP_TYPE\": {\n            \"description\": \"Type of Hadoop setup\",\n            \"type\": \"string\",\n            \"options\": [\n              \"MR1\",\n              \"MR2\",\n              \"HDFS1\",\n              \"HDFS2\"\n            ],\n            \"example\": \"MR2\"\n          },\n          \"HADOOP_LOCAL_DIR\": {\n            \"description\": \"Path to store local data for Hadoop\",\n            \"type\": \"string\",\n            \"example\": \"/tmp/user/hadoop\"\n          },\n          \"HADOOP_CONF_FILES\": {\n            \"description\": \"Directory where alternate Hadoop configuration templates are stored\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/myconf\"\n          },\n          \"HADOOP_DAEMON_HEAP_MAX\": {\n            \"description\": \"Heap maximum for Hadoop daemons\",\n            \"type\": \"integer\",\n            \"example\": \"2000\"\n          },\n          \"HADOOP_NAMENODE_DAEMON_HEAP_MAX\": {\n            \"description\": \"Heap maximum for Hadoop Namenode daemon\",\n            \"type\": \"integer\",\n            \"example\": \"2000\"\n          },\n          \"HADOOP_ENVIRONMENT_EXTRA_PATH\": {\n            \"description\": \"Specify extra environment information that should be passed into Hadoop\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/hadoop-my-environment\"\n          },\n          \"HADOOP_MAX_TASKS_PER_NODE\": {\n            \"description\": \"Tasks per node\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_DEFAULT_MAP_TASKS\": {\n            \"description\": \"Default Map tasks for Job\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_DEFAULT_REDUCE_TASKS\": {\n            \"description\": \"Default Reduce tasks for Job\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_MAX_MAP_TASKS\": {\n            \"description\": \"Max Map tasks for Task Tracker\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_MAX_REDUCE_TASKS\": {\n            \"description\": \"Max Reduce tasks for Task Tracker\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_CHILD_HEAPSIZE\": {\n            \"description\": \"Heap size for JVM\",\n            \"type\": \"integer\",\n            \"example\": \"2048\"\n          },\n          \"HADOOP_CHILD_MAP_HEAPSIZE\": {\n            \"description\": \"Heap size for JVM (Map tasks)\",\n            \"type\": \"integer\",\n            \"example\": \"2048\"\n          },\n          \"HADOOP_CHILD_REDUCE_HEAPSIZE\": {\n            \"description\": \"Heap size for JVM (Reduce tasks)\",\n            \"type\": \"integer\",\n            \"example\": \"4096\"\n          },\n          \"HADOOP_CHILD_MAP_CONTAINER_BUFFER\": {\n            \"description\": \"Container Buffer (Map tasks)\",\n            \"type\": \"integer\",\n            \"example\": \"256\"\n          },\n          \"HADOOP_CHILD_REDUCE_CONTAINER_BUFFER\": {\n            \"description\": \"Container Buffer (Reduce tasks)\",\n            \"type\": \"integer\",\n            \"example\": \"512\"\n          },\n          \"HADOOP_MAPREDUCE_SLOWSTART\": {\n            \"description\": \"Mapreduce Slowstart\",\n            \"type\": \"float\",\n            \"example\": \"0.05\"\n          },\n          \"YARN_RESOURCE_MEMORY\": {\n            \"description\": \"Container Memory\",\n            \"type\": \"integer\",\n            \"example\": \"32768\"\n          },\n          \"HADOOP_COMPRESSION\": {\n            \"description\": \"Enable compression\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_IO_SORT_FACTOR\": {\n            \"description\": \"IO Sort Factors\",\n            \"type\": \"integer\",\n            \"example\": \"10\"\n          },\n          \"HADOOP_IO_SORT_MB\": {\n            \"description\": \"IO Sort MB\",\n            \"type\": \"integer\",\n            \"example\": \"100\"\n          },\n          \"HADOOP_PARALLEL_COPIES\": {\n            \"description\": \"Parallel Copies\",\n            \"type\": \"integer\",\n            \"example\": \"10\"\n          },\n          \"HADOOP_HDFS_PATH\": {\n            \"description\": \"Path for HDFS when using local disk\",\n            \"type\": \"string\",\n            \"example\": \"/ssd/user/hdfs\"\n          },\n          \"HADOOP_HDFS_PATH_CLEAR\": {\n            \"description\": \"HDFS cleanup\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_HDFS_BLOCKSIZE\": {\n            \"description\": \"HDFS Block Size\",\n            \"type\": \"integer\",\n            \"example\": \"134217728\"\n          },\n          \"HADOOP_HDFSOVERLUSTRE_PATH\": {\n            \"description\": \"Lustre path to do Hadoop HDFS out of\",\n            \"type\": \"string\",\n            \"example\": \"/lustre/user/hdfsoverlustre/\"\n          },\n          \"HADOOP_HDFSOVERLUSTRE_REMOVE_LOCKS\": {\n            \"description\": \"HDFS over Lustre ignore lock\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_HDFSOVERNETWORKFS_PATH\": {\n            \"description\": \"Networkfs path to do Hadoop HDFS out of\",\n            \"type\": \"string\",\n            \"example\": \"/networkfs/user/hdfsovernetworkfs/\"\n          },\n          \"HADOOP_HDFSOVERNETWORKFS_REMOVE_LOCKS\": {\n            \"description\": \"HDFS over Networkfs ignore lock\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_RAWNETWORKFS_PATH\": {\n            \"description\": \"Path for rawnetworkfs\",\n            \"type\": \"string\",\n            \"example\": \"/lustre/user/rawnetworkfs/\"\n          },\n          \"HADOOP_RAWNETWORKFS_BLOCKSIZE\": {\n            \"description\": \"RawNetworkFS Block Size\",\n            \"type\": \"integer\",\n            \"example\": \"33554432\"\n          },\n          \"HADOOP_LOCALSTORE\": {\n            \"description\": \"If you have a local SSD or NVRAM, performance may be better to store intermediate data on it rather than Lustre or some other networked filesystem\",\n            \"type\": \"string\",\n            \"example\": \"/ssd/user/localstore/\"\n          },\n          \"HADOOP_LOCALSTORE_CLEAR\": {\n            \"description\": \"HADOOP_LOCALSTORE_CLEAR\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_PER_JOB_HDFS_PATH\": {\n            \"description\": \"Option to use unique locations per job to store hdfs data\",\n            \"type\": \"boolean\",\n            \"example\": \"yes\"\n          },\n          \"HADOOP_TERASORT_SIZE\": {\n            \"description\": \"Terasort size\",\n            \"type\": \"integer\",\n            \"example\": \"50000000\"\n          },\n          \"HADOOP_TERAGEN_MAP_COUNT\": {\n            \"description\": \"Terasort map count\",\n            \"type\": \"integer\",\n            \"example\": \"4\"\n          },\n          \"HADOOP_TERASORT_REDUCER_COUNT\": {\n            \"description\": \"Terasort reducer count\",\n            \"type\": \"integer\",\n            \"example\": \"4\"\n          },\n          \"HADOOP_TERASORT_CLEAR_CACHE\": {\n            \"description\": \"Terasort cache\",\n            \"type\": \"boolean\",\n            \"example\": \"no\"\n          },\n          \"HADOOP_TERASORT_OUTPUT_REPLICATION\": {\n            \"description\": \"Terasort output replication count\",\n            \"type\": \"integer\",\n            \"example\": \"1\"\n          },\n          \"HADOOP_TERASORT_RUN_TERACHECKSUM\": {\n            \"description\": \"Terachecksum\",\n            \"type\": \"boolean\",\n            \"example\": \"no\"\n          },\n          \"HADOOP_TERASORT_RUN_TERAVALIDATE\": {\n            \"description\": \"Teravalidate\",\n            \"type\": \"boolean\",\n            \"example\": \"no\"\n          },\n          \"HADOOP_SCRIPT_PATH\": {\n            \"description\": \"Specify script to execute for \\\"script\\\" mode\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/my-job-script\"\n          },\n          \"HADOOP_SCRIPT_ARGS\": {\n            \"description\": \"Specify arguments for script specified in HADOOP_SCRIPT_PATH\",\n            \"type\": \"string\",\n            \"example\": \"\"\n          },\n          \"HADOOP_DECOMMISSION_HDFS_NODE_SIZE\": {\n            \"description\": \"Specify decommission node size for \\\"decommissionhdfsnodes\\\" mode\",\n            \"type\": \"integer\",\n            \"example\": \"8\"\n          },\n          \"HADOOP_UDA_SETUP\": {\n            \"description\": \"Should Hadoop run with UDA\",\n            \"type\": \"boolean\",\n            \"example\": \"no\"\n          },\n          \"HADOOP_UDA_JAR\": {\n            \"description\": \"Specify UDA jar\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/uda/uda-hadoop-2.x.jar\"\n          },\n          \"HADOOP_UDA_LIBPATH\": {\n            \"description\": \"Specify UDA shared object file\",\n            \"type\": \"string\",\n            \"example\": \"/home/user/uda/lib/\"\n          },\n          \"HADOOP_UDA_RDMA_BUFFER_SIZE\": {\n            \"description\": \"Specify RDMA buffer size\",\n            \"type\": \"integer\",\n            \"example\": \"1024\"\n          }\n        }\n      },\n      \"lsf\": {\n        \"configurations\": {\n          \"BSUB_n\": {\n            \"description\": \"Node count.  Node count should include one node for the head/management/master node.  For example, if you want 8 compute nodes to process data, specify 9 nodes below\",\n            \"type\": \"integer\",\n            \"example\": \"9\"\n          },\n          \"BSUB_o\": {\n            \"description\": \"Standard output filename\",\n            \"type\": \"string\",\n            \"example\": \"lsf-%J.out\"\n          },\n          \"BSUB_W\": {\n            \"description\": \"Wall time for the job\",\n            \"type\": \"string\",\n            \"example\": \"01:00\"\n          },\n          \"BSUB_J\": {\n            \"description\": \"Job name\",\n            \"type\": \"string\",\n            \"example\": \"my_job_name\"\n          },\n          \"BSUB_q\": {\n            \"description\": \"Queue to launch job in\",\n            \"type\": \"string\",\n            \"example\": \"my_queue\"\n          },\n          \"BSUB_R\": {\n            \"description\": \"Resource requirements\",\n            \"type\": \"string\",\n            \"example\": \"span[ptile=1]\"\n          }\n        }\n      },\n      \"mpirun\": {\n        \"configurations\": {\n          \"MPIRUN_OPTIONS\": {\n            \"description\": \"Set alternate mpirun options here\",\n            \"type\": \"string\",\n            \"example\": \"-genvall -genv MV2_USE_APM 0\"\n          }\n        }\n      }\n    },\n    \"resource_requirements\": {\n      \"java_home\": {\n        \"description\": \"Path to Java installation\",\n        \"type\": \"string\",\n        \"example\": \"/usr/lib/jvm/jre-1.7.0-oracle.x86_64/\"\n      }\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 8960,
        "candidates_token_count": 3157,
        "total_token_count": 12117,
        "cached_content_token_count": 0
    }
}