{
    "application": "Magpie",
    "software_requirements": [
        "Hadoop",
        "HDFS",
        "HBase",
        "Tensorflow",
        "SLURM",
        "Python",
        "MPIRUN"
    ],
    "resource_requirements": [
        "nodes",
        "time (minutes)",
        "partition",
        "local scratch space (/tmp)",
        "NFS mount"
    ],
    "additional_details": [
        "Magpie is a set of scripts for running Hadoop on traditional HPC systems.",
        "It leverages SLURM for job management and MPIRUN for distributed execution.",
        "The script utilizes a number of environment variables for configuration, including:",
        "- MAGPIE_SCRIPTS_HOME: Directory where the Magpie scripts are stored.",
        "- MAGPIE_LOCAL_DIR: Path for local data storage on each node.",
        "- MAGPIE_JOB_TYPE: Type of job to run (e.g., 'tensorflow', 'testall').",
        "- TENSORFLOW_SETUP: Whether to setup Tensorflow.",
        "- TENSORFLOW_JOB: Specific Tensorflow job to run.",
        "- MAGPIE_PRE_JOB_RUN: Pre-job script to run on all nodes.",
        "- MAGPIE_POST_JOB_RUN: Post-job script to run on all nodes."
    ]
}