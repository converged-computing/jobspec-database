{
    "application": "Magpie",
    "details": {
        "purpose": "Running Hadoop on traditional HPC systems.",
        "software": {
            "hadoop": "Hadoop is a framework for distributed storage and processing of large data sets.",
            "tensorflow": "TensorFlow is an open-source software library for numerical computation and large-scale machine learning.",
            "horovod": "Horovod is a distributed deep learning training framework for TensorFlow.",
            "slurm": "SLURM (Simple Linux Utility for Resource Management) is a job scheduler that provides the resource management for the HPC system.",
            "magpie": "Magpie is a collection of scripts for running Hadoop on traditional HPC systems, providing a framework for managing the resources and dependencies required for these tasks."
        },
        "resource requirements": {
            "nodes": "<my_node_count>",
            "time": "<my_time_in_minutes>",
            "partition": "<my_partition>"
        },
        "configuration options": {
            "MAGPIE_SCRIPTS_HOME": "${HOME}/magpie",
            "MAGPIE_LOCAL_DIR": "/tmp/${USER}/magpie",
            "MAGPIE_JOB_TYPE": "tensorflow-horovod",
            "TENSORFLOW_HOROVOD_SETUP": "yes",
            "TENSORFLOW_HOROVOD_LOCAL_DIR": "/tmp/${USER}/tensorflow-horovod",
            "TENSORFLOW_HOROVOD_JOB": "synthetic-benchmark"
        }
    }
}