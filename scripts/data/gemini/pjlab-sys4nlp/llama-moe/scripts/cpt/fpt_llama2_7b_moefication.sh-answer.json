{
    "application": "SLURM",
    "details": {
        "job_name": "cpt-llama2_moefication_scale4_112gpus",
        "output_file": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_moefication_scale4_112gpus/%x-%j.log",
        "error_file": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_moefication_scale4_112gpus/%x-%j.log",
        "partition": "MoE",
        "tasks_per_node": 1,
        "cpus_per_task": 64,
        "memory": 0,
        "nodes": 14,
        "gpus": 8,
        "quota_type": "reserved",
        "environment": "smoe",
        "model_type": "llama_moe",
        "pretrained_model": "/mnt/petrelfs/share_data/quxiaoye/models/LlamaMoEForCausalLM/Gradient-max-l1_norm-sample-feature_change/llama2_7B-16Select4-688Neurons",
        "tokenizer_path": "/mnt/petrelfs/share_data/quxiaoye/models/llama2_7B",
        "dataset_dir": "/mnt/petrelfs/share_data/quxiaoye/SlimPajama_processed",
        "validation_dir": "/mnt/petrelfs/share_data/quxiaoye/data/llama1_7B_val_set_tokenized",
        "lr": "2e-4",
        "final_lr_portion": 0.1,
        "per_device_train_batch_size": 8,
        "per_device_eval_batch_size": 8,
        "gradient_accumulation_steps": 4,
        "block_size": 4096,
        "num_tokens": "2*10^11",
        "seed": 1227,
        "deepspeed_config_file": "conf/deepspeed/bf16_zero1_default.json",
        "num_selects": 4,
        "data_cache": "resources/cache",
        "base_dir": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_moefication_scale4_112gpus",
        "output_dir": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_moefication_scale4_112gpus/outputs/cpt-llama2_moefication_scale4_112gpus-$SLURM_JOB_ID",
        "comment": "llama 2 7B, gradient 4/16, per-device bsz 32, lr 2e-4, 112gpus",
        "OMP_NUM_THREADS": 32,
        "LOGLEVEL": "INFO",
        "framework": "PyTorch",
        "deepspeed": true
    }
}