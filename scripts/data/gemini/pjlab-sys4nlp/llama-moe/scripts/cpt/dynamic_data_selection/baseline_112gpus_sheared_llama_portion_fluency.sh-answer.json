{
    "application": "SLURM",
    "details": {
        "slurm_job_name": "cpt-llama2_random_scale4_112gpus_dynamic_data",
        "slurm_output_file": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_random_scale4_112gpus_dynamic_data/%x-%j.log",
        "slurm_error_file": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_random_scale4_112gpus_dynamic_data/%x-%j.log",
        "slurm_partition": "MoE",
        "slurm_ntasks_per_node": 1,
        "slurm_cpus_per_task": 64,
        "slurm_mem": 0,
        "slurm_nodes": 14,
        "slurm_gres": "gpu:8",
        "slurm_quotatype": "reserved",
        "conda_env": "smoe",
        "deepspeed_config_file": "conf/deepspeed/bf16_zero1_default.json",
        "model_type": "llama_moe",
        "pretrained_model": "/mnt/petrelfs/share_data/quxiaoye/models/LlamaMoEForCausalLM/Random/llama2_7B-16Select4-up_proj-Scale4.0",
        "tokenizer_path": "/mnt/petrelfs/share_data/quxiaoye/models/llama2_7B",
        "dataset_dir": "/mnt/petrelfs/share_data/quxiaoye/SlimPajama-fluency-processed-agg",
        "validation_dir": "/mnt/petrelfs/share_data/quxiaoye/data/llama1_7B_val_set_tokenized",
        "lr": "2e-4",
        "final_lr_portion": 0.1,
        "per_device_train_batch_size": 8,
        "per_device_eval_batch_size": 8,
        "gradient_accumulation_steps": 4,
        "block_size": 4096,
        "num_tokens": "200*10^9",
        "warmup_tokens": "15*10^8",
        "eval_tokens": "2.5*10^9",
        "seed": 1227,
        "num_selects": 4,
        "data_cache": "resources/cache",
        "base_dir": "/mnt/petrelfs/share_data/quxiaoye/runs/llama2_random_scale4_112gpus_dynamic_data",
        "gate_type": "TopKBalancedNoisyGate",
        "calculator_type": "UniversalCalculator"
    }
}