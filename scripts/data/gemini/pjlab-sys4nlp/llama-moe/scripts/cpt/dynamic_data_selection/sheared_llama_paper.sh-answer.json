{
    "application": "DeepSpeed",
    "details": {
        "framework": "PyTorch",
        "deepspeed_config": "bf16_zero1_default.json",
        "model_type": "llama_moe",
        "model_name": "llama2_7B-16Select4-up_proj-Scale4.0",
        "tokenizer": "llama2_7B",
        "dataset": "SlimPajama_processed",
        "validation_set": "llama1_7B_val_set_tokenized",
        "optimizer": "adamw_torch",
        "learning_rate": "1e-4",
        "batch_size": "4M tokens",
        "gradient_accumulation_steps": 8,
        "block_size": 4096,
        "num_tokens": "200*10^9",
        "warmup_tokens": "1*10^9",
        "eval_tokens": "500*10^6",
        "num_selects": 4,
        "hardware": {
            "nodes": 2,
            "gpus_per_node": 8,
            "cpus_per_task": 64,
            "memory": "0"
        },
        "environment": {
            "OMP_NUM_THREADS": 32,
            "LOGLEVEL": "INFO"
        }
    }
}