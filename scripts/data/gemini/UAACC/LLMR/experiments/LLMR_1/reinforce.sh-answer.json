{
    "application": "SLURM",
    "details": {
        "script": "reinforce.py",
        "language": "Python",
        "framework": "Transformers",
        "library": "PyTorch",
        "resource_requirements": {
            "time": "72 hours",
            "job_name": "train",
            "account": "rrg-lilimou",
            "nodes": 1,
            "exclusive": true,
            "memory": "0 MB",
            "gpus": {
                "type": "v100l",
                "count": 4
            },
            "output_log": "/project/def-lilimou/mrli/logs/output-%j.log",
            "error_log": "/project/def-lilimou/mrli/logs/error-%j.log"
        },
        "environment_variables": [
            "TRANSFORMERS_OFFLINE=1",
            "MASTER_ADDR=127.0.0.1",
            "MASTER_PORT=(dynamically assigned)",
            "NCCL_SOCKET_IFNAME=ib0",
            "NCCL_IB_GID_INDEX=mlx5_0",
            "NCCL_DEBUG=WARN",
            "HF_HOME='/project/def-lilimou/ychao/hf'"
        ],
        "model_names": [
            "t5t0pce_rl",
            "t5_base",
            "t0-3b"
        ],
        "data_path": "/project/def-lilimou/ychao/data/dialogue/cleaned_dd/single-turn",
        "config_path": "/project/def-lilimou/ychao/hf/hub/t5-base/config.json",
        "tokenizer_path": "/project/def-lilimou/ychao/hf/hub/t5-base",
        "save_path": "/home/mrli/scratch/projects/LLMR/ckpts/LLMR_11",
        "training_parameters": {
            "max_tokens": 512,
            "num_training_steps": 100000,
            "learning_rate": 1e-06,
            "num_warmup_steps": 5000,
            "iterations_per_update": 16,
            "updates_per_save": 1000,
            "updates_per_log": 1,
            "topk": 5,
            "scheduler": "constant",
            "max_norm": 1,
            "softmax": true,
            "entropy": 0.1,
            "denominator": 100,
            "reward_clip": 1,
            "template_file": "templates/dialogue_T0.txt"
        }
    }
}