{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Secora\",\n  \"software_requirements\": [\n    \"gcc/8.2.0\",\n    \"cmake\",\n    \"cuda/11.2\",\n    \"python3\"\n  ],\n  \"resource_requirements\": [\n    \"partition: gpu4\",\n    \"nodes: 1\",\n    \"tasks per node: 32\",\n    \"memory: 96 GB\",\n    \"time: 00:50:00\",\n    \"output file: slurm_logs/slurm_debug.%j.out\",\n    \"error file: slurm_logs/slurm_debug.%j.err\"\n  ],\n  \"environment_variables\": [\n    \"HF_HOME: /scratch/fhoels2s/huggingface\",\n    \"MASTER_ADDR: localhost\",\n    \"MASTER_PORT: 15000 + random port\",\n    \"TORCH_DISTRIBUTED_DEBUG: DETAIL\",\n    \"NCCL_DEBUG_SUBSYS: ALL\",\n    \"NCCL_DEBUG: INFO\",\n    \"NCCL_IB_DISABLE: 1\",\n    \"CUDA_LAUNCH_BLOCKING: 1\",\n    \"TOKENIZERS_PARALLELISM: false\"\n  ],\n  \"command\": \"pipenv run python secora/train.py --debug configs/cluster.yml --name debug_cluster_gpu4\"\n}\n```\n"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 423,
        "candidates_token_count": 327,
        "total_token_count": 750,
        "cached_content_token_count": 0
    }
}