{
    "application": "SLURM",
    "details": {
        "resource_requirements": {
            "partition": "batch",
            "nodes": 1,
            "tasks": 1,
            "cores": 2,
            "time": "24:00:00",
            "gpu": 1,
            "memory": "8GB"
        },
        "notifications": {
            "type": "END, FAIL",
            "email": "axxx@gmail.com"
        },
        "monitoring": {
            "gpu_utilization": "nvidia-smi -l > nv-smi_sa.log.${SLURM_JOB_ID} 2>&1 &"
        },
        "script_execution": {
            "command": "python ./main.py"
        }
    }
}