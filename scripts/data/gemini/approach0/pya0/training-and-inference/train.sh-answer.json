{
    "application": "PyTorch",
    "software": [
        "PyTorch",
        "Transformers",
        "NCCL",
        "SLURM",
        "wget",
        "tar",
        "nc",
        "git"
    ],
    "resources": [
        "GPU",
        "CPU",
        "Memory",
        "Network"
    ],
    "resource_details": {
        "GPU": {
            "type": "NVIDIA",
            "count": 2,
            "details": "Uses NCCL for distributed training"
        },
        "CPU": {
            "count": 2,
            "details": "Cores proportional to GPUs"
        },
        "Memory": {
            "amount": "64GB",
            "details": "Memory proportional to GPUs"
        },
        "Network": {
            "type": "TCP",
            "details": "Uses TCP for communication between nodes"
        }
    }
}