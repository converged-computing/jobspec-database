{
    "application": "SLURM",
    "details": {
        "job_name": "together-alpa-OPT-175B",
        "time_limit": "1:00:00",
        "number_of_tasks": 1,
        "excluded_nodes": "sphinx[1-3]",
        "cpus_per_task": 8,
        "memory_per_cpu": "12G",
        "output_file": "/afs/cs.stanford.edu/u/biyuan/fm/together/together-accelerate-OPT-iml-175B-max-%j.out",
        "error_file": "/afs/cs.stanford.edu/u/biyuan/fm/together/together-accelerate-OPT-iml-175B-max-%j.err",
        "partition": "sphinx",
        "account": "nlp",
        "gpus": "a100:8",
        "docker_image": "binhang/alpa",
        "docker_command": "start_local_optiml175bmax.sh",
        "docker_mount_point": "/nlp/scr2/nlp/fmStore/fm:/home/fm"
    }
}