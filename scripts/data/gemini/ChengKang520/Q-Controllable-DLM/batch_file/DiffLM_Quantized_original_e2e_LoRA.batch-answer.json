{
    "application": "SLURM",
    "details": [
        {
            "key": "partition",
            "value": "amdgpulong"
        },
        {
            "key": "time",
            "value": "72:00:00"
        },
        {
            "key": "gres",
            "value": "gpu:1"
        },
        {
            "key": "ntasks-per-node",
            "value": "1"
        },
        {
            "key": "mem-per-gpu",
            "value": "32000"
        },
        {
            "key": "job-name",
            "value": "LoRA_Q_original_E2E"
        },
        {
            "key": "err",
            "value": "LoRA_Q_original_E2E.err"
        },
        {
            "key": "out",
            "value": "LoRA_Q_original_E2E.out"
        },
        {
            "key": "mail-user",
            "value": "kangchen@fel.cvut.cz"
        },
        {
            "key": "mail-type",
            "value": "ALL"
        },
        {
            "key": "software",
            "value": "PyTorch/1.9.0-fosscuda-2020b"
        },
        {
            "key": "environment",
            "value": "EnvDiff"
        },
        {
            "key": "libraries",
            "value": [
                "mpi4py",
                "python",
                "transformers"
            ]
        },
        {
            "key": "other",
            "value": "The script also uses the following resources:  \n * A GPU with 32GB of memory \n * A single task per node \n * The MPI library for parallel processing"
        }
    ]
}