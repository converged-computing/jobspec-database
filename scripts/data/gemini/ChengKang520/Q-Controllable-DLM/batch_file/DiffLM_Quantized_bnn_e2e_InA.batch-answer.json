{
    "application": "Slurm",
    "details": "The script is designed to run on a Slurm cluster, utilizing the following resources:\n\n* **Partition:** `amdgpulong`\n* **Time:** 72 hours\n* **GPU:** 1 GPU\n* **Tasks per Node:** 1\n* **Memory per GPU:** 32 GB\n* **Job Name:** `AdapterQ_bnn_E2E`\n* **Error Output File:** `AdapterQ_bnn_E2E.err`\n* **Output File:** `AdapterQ_bnn_E2E.out`\n* **Mail User:** `kangchen@fel.cvut.cz`\n* **Mail Type:** `ALL` (send notifications for job start, end, failure, requeue, and all events)\n\nThe script utilizes a Python environment with PyTorch version 1.9.0, OpenMPI with warnings disabled, and runs the `run_train.py` and `batch_decode.py` scripts from the `improved-diffusion` directory. The script also uses a virtual environment named `EnvDiff`.  A series of experiments are then run with different tasks like control_tree, control_length, control_spans, control_pos, and control_attribute.",
    "software": [
        "Slurm",
        "PyTorch",
        "OpenMPI",
        "Python"
    ],
    "resource_requirements": {
        "partition": "amdgpulong",
        "time": "72:00:00",
        "gres": "gpu:1",
        "ntasks_per_node": 1,
        "mem_per_gpu": "32000",
        "job_name": "AdapterQ_bnn_E2E",
        "err": "AdapterQ_bnn_E2E.err",
        "out": "AdapterQ_bnn_E2E.out",
        "mail_user": "kangchen@fel.cvut.cz",
        "mail_type": "ALL"
    }
}