{
    "application": "PyTorch",
    "details": {
        "resource_requirements": {
            "walltime": "1 hour",
            "cpus": "4",
            "nodes": "1",
            "gpus": "4",
            "memory": "60GB per CPU core",
            "software": [
                "SLURM",
                "Python3",
                "NCCL",
                "Miniconda3",
                "PyTorch"
            ]
        },
        "script_description": "This script runs a PyTorch training job on a SLURM cluster. It utilizes 4 GPUs and 4 CPUs across a single node, with a 60GB memory allocation per CPU core. The training script is 'newmain.py', which is executed with the following arguments: 'tutorial', '../data/query.fasta', 4, '--epochs 5', '--strategy fsdp'. The script also utilizes environment variables such as MASTER_ADDR, MASTER_PORT, NCCL_SOCKET_IFNAME, and LD_LIBRARY_PATH to configure the PyTorch training process."
    }
}