{
    "application": "Deep Learning",
    "software": [
        "Singularity",
        "SLURM",
        "Python",
        "CUDA",
        "gcc-10",
        "g++-10",
        "flash-attention"
    ],
    "resource_requirements": {
        "nodes": 256,
        "cpus_per_task": 7,
        "ntasks_per_node": 8,
        "memory": 0,
        "partition": "standard-g",
        "time": "01-00:00:00",
        "gpus_per_node": "mi250:8",
        "account": "project_462000353"
    },
    "model": "GPT-3 33B",
    "training_data": [
        "finnish",
        "slimpajama",
        "starcoderdata",
        "nordic-en-xling-combined",
        "train-books_text_document",
        "mc4-da-train_text_document",
        "mc4-is-train_text_document",
        "mc4-sv-train_text_document",
        "nor_all_combined_text_document",
        "natural_instruct_train_text_document"
    ],
    "validation_data": [
        "finnish_eval_text_document",
        "slim-pajama-validation_text_document",
        "starcoder-eval_content_document",
        "xlint-test-all-combined_text_document",
        "eval-books.json_text_document",
        "mc4-da-validation_text_document",
        "mc4-is-validation_text_document",
        "mc4-sv-validation_text_document",
        "nor_eval_all_text_document",
        "natural_instruct_validation_text_document"
    ],
    "hyperparameters": {
        "learning_rate": 0.00015,
        "optimizer": "adam",
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "adam_eps": 1e-05,
        "min_lr": 1.5e-05,
        "lr_decay_style": "cosine",
        "lr_decay_samples": 2000000000000,
        "lr_warmup_samples": 2000,
        "clip_grad": 1.0,
        "weight_decay": 0.1,
        "num_layers": 56,
        "hidden_size": 7168,
        "num_attention_heads": 56,
        "ffn_hidden_size": 20480,
        "seq_length": 4096,
        "num_key_value_heads": 8,
        "max_position_embeddings": 4096,
        "micro_batch_size": 1,
        "global_batch_size": 1024,
        "train_samples": 500000000,
        "tokenizer_type": "GPT2BPETokenizer",
        "vocab_file": "/scratch/project_462000319/tokenizers/nordic_tokenizer_131072/vocab.json",
        "merge_file": "/scratch/project_462000319/tokenizers/nordic_tokenizer_131072/merges.txt",
        "bf16": true,
        "disable_bias_linear": true,
        "init_method_std": 0.0048,
        "make_vocab_size_divisible_by": 128,
        "no_gradient_accumulation_fusion": true,
        "normalization": "rmsnorm",
        "recompute_activations": true,
        "seed": 42,
        "swiglu": true,
        "untie_embeddings_and_output_weights": true,
        "use_distributed_optimizer": true,
        "use_flash_attn_v2": true,
        "use_rotary_position_embeddings": true,
        "attention_dropout": 0,
        "hidden_dropout": 0,
        "no_query_key_layer_scaling": true,
        "memory_opt_allreduce_size": 1250000000,
        "log_interval": 10,
        "save_interval": 1000,
        "save": "/scratch/project_462000086/viking-v2/33B_high_eps",
        "load": "/scratch/project_462000086/viking-v2/33B_high_eps",
        "eval_interval": 4000,
        "eval_iters": 100,
        "tensorboard_dir": "tensorboard/33B_high_eps.${SLURM_JOB_ID}",
        "tensorboard_queue_size": 5,
        "log_timers_to_tensorboard": true,
        "log_batch_size_to_tensorboard": true,
        "log_validation_ppl_to_tensorboard": true,
        "tensor_model_parallel_size": 4,
        "pipeline_model_parallel_size": 4,
        "data_impl": "mmap",
        "dataloader_type": "single",
        "num_workers": 0
    }
}