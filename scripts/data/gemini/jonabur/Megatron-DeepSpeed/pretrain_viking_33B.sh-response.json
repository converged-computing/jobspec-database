{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Deep Learning\",\n  \"software\": [\n    \"Singularity\",\n    \"SLURM\",\n    \"Python\",\n    \"CUDA\",\n    \"gcc-10\",\n    \"g++-10\",\n    \"flash-attention\"\n  ],\n  \"resource_requirements\": {\n    \"nodes\": 256,\n    \"cpus_per_task\": 7,\n    \"ntasks_per_node\": 8,\n    \"memory\": 0,\n    \"partition\": \"standard-g\",\n    \"time\": \"01-00:00:00\",\n    \"gpus_per_node\": \"mi250:8\",\n    \"account\": \"project_462000353\"\n  },\n  \"model\": \"GPT-3 33B\",\n  \"training_data\": [\n    \"finnish\",\n    \"slimpajama\",\n    \"starcoderdata\",\n    \"nordic-en-xling-combined\",\n    \"train-books_text_document\",\n    \"mc4-da-train_text_document\",\n    \"mc4-is-train_text_document\",\n    \"mc4-sv-train_text_document\",\n    \"nor_all_combined_text_document\",\n    \"natural_instruct_train_text_document\"\n  ],\n  \"validation_data\": [\n    \"finnish_eval_text_document\",\n    \"slim-pajama-validation_text_document\",\n    \"starcoder-eval_content_document\",\n    \"xlint-test-all-combined_text_document\",\n    \"eval-books.json_text_document\",\n    \"mc4-da-validation_text_document\",\n    \"mc4-is-validation_text_document\",\n    \"mc4-sv-validation_text_document\",\n    \"nor_eval_all_text_document\",\n    \"natural_instruct_validation_text_document\"\n  ],\n  \"hyperparameters\": {\n    \"learning_rate\": 1.5e-4,\n    \"optimizer\": \"adam\",\n    \"adam_beta1\": 0.9,\n    \"adam_beta2\": 0.95,\n    \"adam_eps\": 1e-5,\n    \"min_lr\": 1.5e-5,\n    \"lr_decay_style\": \"cosine\",\n    \"lr_decay_samples\": 2000000000000,\n    \"lr_warmup_samples\": 2000,\n    \"clip_grad\": 1.0,\n    \"weight_decay\": 1e-1,\n    \"num_layers\": 56,\n    \"hidden_size\": 7168,\n    \"num_attention_heads\": 56,\n    \"ffn_hidden_size\": 20480,\n    \"seq_length\": 4096,\n    \"num_key_value_heads\": 8,\n    \"max_position_embeddings\": 4096,\n    \"micro_batch_size\": 1,\n    \"global_batch_size\": 1024,\n    \"train_samples\": 500000000,\n    \"tokenizer_type\": \"GPT2BPETokenizer\",\n    \"vocab_file\": \"/scratch/project_462000319/tokenizers/nordic_tokenizer_131072/vocab.json\",\n    \"merge_file\": \"/scratch/project_462000319/tokenizers/nordic_tokenizer_131072/merges.txt\",\n    \"bf16\": true,\n    \"disable_bias_linear\": true,\n    \"init_method_std\": 0.0048,\n    \"make_vocab_size_divisible_by\": 128,\n    \"no_gradient_accumulation_fusion\": true,\n    \"normalization\": \"rmsnorm\",\n    \"recompute_activations\": true,\n    \"seed\": 42,\n    \"swiglu\": true,\n    \"untie_embeddings_and_output_weights\": true,\n    \"use_distributed_optimizer\": true,\n    \"use_flash_attn_v2\": true,\n    \"use_rotary_position_embeddings\": true,\n    \"attention_dropout\": 0,\n    \"hidden_dropout\": 0,\n    \"no_query_key_layer_scaling\": true,\n    \"memory_opt_allreduce_size\": 1250000000,\n    \"log_interval\": 10,\n    \"save_interval\": 1000,\n    \"save\": \"/scratch/project_462000086/viking-v2/33B_high_eps\",\n    \"load\": \"/scratch/project_462000086/viking-v2/33B_high_eps\",\n    \"eval_interval\": 4000,\n    \"eval_iters\": 100,\n    \"tensorboard_dir\": \"tensorboard/33B_high_eps.${SLURM_JOB_ID}\",\n    \"tensorboard_queue_size\": 5,\n    \"log_timers_to_tensorboard\": true,\n    \"log_batch_size_to_tensorboard\": true,\n    \"log_validation_ppl_to_tensorboard\": true,\n    \"tensor_model_parallel_size\": 4,\n    \"pipeline_model_parallel_size\": 4,\n    \"data_impl\": \"mmap\",\n    \"dataloader_type\": \"single\",\n    \"num_workers\": 0\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "citation_metadata": {
                "citation_sources": [
                    {
                        "start_index": 2907,
                        "end_index": 3051,
                        "uri": "https://github.com/Deegue/llm-on-ray",
                        "license_": ""
                    }
                ]
            },
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 3413,
        "candidates_token_count": 1354,
        "total_token_count": 4767,
        "cached_content_token_count": 0
    }
}