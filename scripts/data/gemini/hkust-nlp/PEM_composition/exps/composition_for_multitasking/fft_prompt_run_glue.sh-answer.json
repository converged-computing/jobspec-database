{
    "application": "pytorch",
    "details": {
        "framework": "pytorch",
        "library": "transformers",
        "resources": {
            "gpu": "a40",
            "memory": "30 GB",
            "cpu": 4,
            "time": "48 hours",
            "nodes": 2
        },
        "task": "text classification",
        "dataset": "GLUE",
        "model": "t5-base",
        "hyperparameters": {
            "learning_rate": 0.0005,
            "batch_size": 8,
            "gradient_accumulation_steps": 1,
            "max_steps": -1,
            "num_train_epochs": 1,
            "max_tokens_per_batch": 0,
            "max_seq_length": 512,
            "lr_scheduler_type": "polynomial",
            "max_eval_samples": 1600,
            "logging_steps": 10,
            "save_strategy": "epochs",
            "eval_strategy": "steps",
            "save_steps": 100,
            "eval_steps": 100,
            "weight_decay": 0.01,
            "warmup_updates": 0,
            "warmup_ratio": 0.06
        },
        "logging": "wandb",
        "output_dir": "checkpoints/glue/${TASK_NAME}/${DATE}/${exp_name}"
    }
}