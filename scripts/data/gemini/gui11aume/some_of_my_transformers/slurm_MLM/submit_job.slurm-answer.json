{
    "application": "SLURM",
    "details": {
        "software": [
            "CUDA 11.4.4",
            "Anaconda3",
            "PyTorch"
        ],
        "resources": {
            "nodes": 4,
            "tasks_per_node": 4,
            "gpus_per_node": 4,
            "cpus_per_task": 2,
            "time": "24:00:00",
            "partition": "compute_full_node",
            "environment_variables": [
                "CUBLAS_WORKSPACE_CONFIG=:4096:2",
                "NCCL_DEBUG=INFO",
                "PYTHONFAULTHANDLER=1"
            ],
            "script": "./pretrain_MLM.py majestic_tokenizer.json flat_claims.txt.gz trained.pt"
        }
    }
}