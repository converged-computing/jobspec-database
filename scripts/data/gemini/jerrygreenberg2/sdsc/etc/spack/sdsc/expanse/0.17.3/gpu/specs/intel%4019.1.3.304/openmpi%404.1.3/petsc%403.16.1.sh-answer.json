{
    "application": "Spack",
    "details": {
        "scheduler": "Slurm",
        "scheduler_module": "slurm/expanse/current",
        "spack_version": "0.17.3",
        "spack_instance_name": "gpu",
        "spack_instance_dir": "/cm/shared/apps/spack/0.17.3/gpu",
        "spack_package": "petsc@3.16.1",
        "spack_compiler": "intel@19.1.3.304",
        "spack_variants": "~X ~batch ~cgns ~complex ~cuda ~debug +double ~exodusii ~fftw ~giflib +hdf5 ~hpddm ~hwloc ~hypre ~int64 ~jpeg ~knl ~libpng ~libyaml ~memkind +metis ~mkl-pardiso ~mmg ~moab ~mpfr +mpi ~mumps ~p4est ~parmmg +ptscotch ~random123 ~rocm ~saws ~scalapack +shared ~strumpack ~suite-sparse ~superlu-dist ~tetgen ~trilinos ~valgrind",
        "spack_dependencies": "^python@3.8.12/$(spack find --format '{hash:7}' python@3.8.12 % ${SPACK_COMPILER}) ^openblas@0.3.18/$(spack find --format '{hash:7}' openblas@0.3.18 % ${SPACK_COMPILER} ~ilp64 threads=none) ^hdf5@1.10.7/$(spack find --format '{hash:7}' hdf5@1.10.7 % ${SPACK_COMPILER} +mpi ^openmpi@4.1.3) ^parmetis@4.0.3/$(spack find --format '{hash:7}' parmetis@4.0.3 % ${SPACK_COMPILER} ~int64 ^openmpi@4.1.3)",
        "spack_spec": "petsc@3.16.1 % intel@19.1.3.304 ~X ~batch ~cgns ~complex ~cuda ~debug +double ~exodusii ~fftw ~giflib +hdf5 ~hpddm ~hwloc ~hypre ~int64 ~jpeg ~knl ~libpng ~libyaml ~memkind +metis ~mkl-pardiso ~mmg ~moab ~mpfr +mpi ~mumps ~p4est ~parmmg +ptscotch ~random123 ~rocm ~saws ~scalapack +shared ~strumpack ~suite-sparse ~superlu-dist ~tetgen ~trilinos ~valgrind ^python@3.8.12/$(spack find --format '{hash:7}' python@3.8.12 % ${SPACK_COMPILER}) ^openblas@0.3.18/$(spack find --format '{hash:7}' openblas@0.3.18 % ${SPACK_COMPILER} ~ilp64 threads=none) ^hdf5@1.10.7/$(spack find --format '{hash:7}' hdf5@1.10.7 % ${SPACK_COMPILER} +mpi ^openmpi@4.1.3) ^parmetis@4.0.3/$(spack find --format '{hash:7}' parmetis@4.0.3 % ${SPACK_COMPILER} ~int64 ^openmpi@4.1.3)",
        "slurm_job_name": "petsc@3.16.1",
        "slurm_account": "use300",
        "slurm_partition": "ind-gpu-shared",
        "slurm_nodes": "1",
        "slurm_ntasks_per_node": "1",
        "slurm_cpus_per_task": "10",
        "slurm_gpus": "1",
        "slurm_mem": "93G",
        "slurm_time": "00:30:00"
    }
}