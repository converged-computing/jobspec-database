{
    "application": "Spack",
    "details": {
        "scheduler": "Slurm",
        "scheduler_module": "slurm",
        "spack_version": "0.17.3",
        "spack_instance_name": "cpu",
        "spack_instance_dir": "/home/cm/shared/apps/spack/0.17.3/cpu",
        "system_name": "expanse",
        "intel_license_file": "40000@elprado.sdsc.edu:40200@elprado.sdsc.edu",
        "spack_package": "openmpi@4.1.3",
        "spack_compiler": "intel@19.1.1.217",
        "spack_variants": "~atomics~cuda~cxx~cxx_exceptions~gpfs~internal-hwloc~java+legacylaunchers+lustre~memchecker+pmi+pmix+romio~rsh~singularity+static+vt+wrapper-rpath cuda_arch=none fabrics=ucx schedulers=slurm",
        "spack_dependencies": "^lustre@2.12.8 ^slurm@21.08.8 ^rdma-core ^ucx@1.10.1/$(spack find --format '{hash:7}' ucx@1.10.1 % gcc@8.5.0)",
        "spack_spec": "openmpi@4.1.3 % intel@19.1.1.217 ~atomics~cuda~cxx~cxx_exceptions~gpfs~internal-hwloc~java+legacylaunchers+lustre~memchecker+pmi+pmix+romio~rsh~singularity+static+vt+wrapper-rpath cuda_arch=none fabrics=ucx schedulers=slurm ^lustre@2.12.8 ^slurm@21.08.8 ^rdma-core ^ucx@1.10.1/$(spack find --format '{hash:7}' ucx@1.10.1 % gcc@8.5.0)",
        "slurm_job_name": "openmpi@4.1.3",
        "slurm_account": "sdsc",
        "slurm_partition": "hotel",
        "slurm_nodes": 1,
        "slurm_tasks_per_node": 1,
        "slurm_cpus_per_task": 16,
        "slurm_memory": "32G",
        "slurm_time": "00:30:00"
    }
}