{
    "application": "slurm",
    "details": {
        "job_name": "transformer-trainer",
        "ntasks": 2,
        "nodes": 2,
        "gpus_per_task": 8,
        "cpus_per_task": 96,
        "software": [
            "torchrun",
            "c10d",
            "efa",
            "nccl"
        ],
        "environment_variables": [
            "LOGLEVEL",
            "FI_PROVIDER",
            "NCCL_P2P_DISABLE",
            "NCCL_IB_DISABLE",
            "NCCL_DEBUG",
            "NCCL_DEBUG_SUBSYS",
            "PYTHONFAULTHANDLER",
            "LD_LIBRARY_PATH",
            "CUDA_LAUNCH_BLOCKING",
            "NCCL_SOCKET_IFNAME",
            "RESNET",
            "IMAGENET"
        ],
        "resources": [
            "GPU (A100)",
            "CPU",
            "network interface (ens)",
            "cluster (with Slurm)"
        ],
        "file": "main_training.py"
    }
}