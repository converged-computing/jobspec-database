{
    "application": "Python",
    "details": {
        "queue": "isi80",
        "walltime": "1:00:00",
        "nodes": "1",
        "ppn": "16",
        "gpus": "4",
        "libraries": [
            "tensorflow"
        ],
        "script": "run.py",
        "arguments": [
            "--mode",
            "DUMP_LSTM",
            "--model_dir",
            "$MODEL_DIR",
            "--test_path_from",
            "$TEST_PATH_FROM",
            "--test_path_to",
            "$DECODE_OUTPUT",
            "--dump_lstm_output",
            "$DUMP_LSTM_OUTPUT",
            "--size",
            "100",
            "--num_layers",
            "2",
            "--attention",
            "True",
            "--from_vocab_size",
            "100",
            "--to_vocab_size",
            "100",
            "--min_source_length",
            "0",
            "--max_source_length",
            "22",
            "--min_target_length",
            "0",
            "--max_target_length",
            "22",
            "--n_bucket",
            "2",
            "--N",
            "00000",
            "--attention_style",
            "additive",
            "--attention_scale",
            "False",
            "--check_attention",
            "False",
            "--layer_normalization",
            "True"
        ]
    }
}