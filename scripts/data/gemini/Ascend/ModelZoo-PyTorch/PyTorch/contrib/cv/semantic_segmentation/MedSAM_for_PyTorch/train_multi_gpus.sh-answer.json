{
    "application": "SLURM",
    "details": {
        "resource_requirements": {
            "nodes": 5,
            "tasks": 5,
            "cpus_per_task": 24,
            "memory": "200GB",
            "gpus": 4,
            "partition": "a100",
            "time": "20-00:00:00",
            "exclude_nodes": "gpu101,gpu113"
        },
        "environment_variables": {
            "GPUS_PER_NODE": "SLURM_GPUS_ON_NODE",
            "MASTER_ADDR": "MAIN_HOST",
            "MASTER_PORT": "randomly assigned free port",
            "NNODES": "SLURM_NNODES",
            "WORLD_SIZE": "(GPUS_PER_NODE * NNODES)",
            "NCCL_IB_DISABLE": "1",
            "OMP_NUM_THREADS": "1",
            "NCCL_DEBUG": "INFO"
        },
        "script_execution": {
            "command": "/opt/slurm/bin/srun -lN1 --mem=200G --gres=gpu:4 -c $SLURM_CPUS_ON_NODE -N 1 -n 1 -r $i bash -c \"python train_multi_gpus.py -task_name MedSAM-ViT-B-20GPUs -work_dir ./work_dir -batch_size 8 -num_workers 8 --world_size ${WORLD_SIZE} --bucket_cap_mb 25 --grad_acc_steps 1 --node_rank ${i} --init_method tcp://${MASTER_ADDR}:${MASTER_PORT}\"",
            "output_logs": "./logs/log_for_${SLURM_JOB_ID}_node_${i}.log"
        },
        "software": {
            "python": "used to get a free port",
            "train_multi_gpus.py": "Python script for multi-GPU training",
            "SLURM": "job scheduler"
        }
    }
}