{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"deepspeed\",\n  \"details\": {\n    \"framework\": \"PyTorch\",\n    \"model\": \"GPT\",\n    \"distributed_training\": true,\n    \"resource_requirements\": {\n      \"nodes\": 48,\n      \"walltime\": \"06:00:00\",\n      \"filesystem\": \"eagle:home\",\n      \"queue\": \"prod\",\n      \"account\": \"argonne_tpc\"\n    },\n    \"libraries\": [\n      \"deepspeed\",\n      \"python3\",\n      \"conda\",\n      \"mpich\"\n    ],\n    \"environment\": {\n      \"conda_env\": \"polaris/2024-03-14\",\n      \"deepspeed_config\": \"deepspeed_config.json\"\n    },\n    \"command_line_arguments\": {\n      \"--use-flash-attn-v2\": true,\n      \"--DTYPE\": \"float16\",\n      \"--num-workers\": 0,\n      \"--split\": \"100,0,0\",\n      \"--log-interval\": 1,\n      \"--no-bias-gelu-fusion\": true,\n      \"--lr-decay-style\": \"cosine\",\n      \"--no-bias-dropout-fusion\": true,\n      \"--no-masked-softmax-fusion\": true,\n      \"--tokenizer-type\": \"Llama2Tokenizer\",\n      \"--no-gradient-accumulation-fusion\": true,\n      \"--accumulate-allreduce-grads-in-fp32\": true,\n      \"--use-checkpoint-opt_param-scheduler\": true,\n      \"--lr\": \"${LR}\",\n      \"--seq-length\": \"$SEQ\",\n      \"--save\": \"${CKPT_DIR}\",\n      \"--load\": \"${CKPT_DIR}\",\n      \"--num-layers\": \"${NLAYERS}\",\n      \"--hidden-size\": \"${HIDDEN}\",\n      \"--train-iters\": \"${TRAIN_ITER}\",\n      \"--eval-iters\": \"${EVAL_ITERS}\",\n      \"--distributed-backend\": \"${BE}\",\n      \"--num-attention-heads\": \"${HEADS}\",\n      \"--save-interval\": \"${SAVE_INTERVAL}\",\n      \"--eval-interval\": \"${EVAL_INTERVAL}\",\n      \"--max-position-embeddings\": \"${SEQ}\",\n      \"--micro-batch-size\": \"${MICRO_BATCH}\",\n      \"--data-file-list\": \"${DATA_FILE_LIST}\",\n      \"--tensor-model-parallel-size\": \"${TP}\",\n      \"--global-batch-size\": \"${GLOBAL_BATCH}\",\n      \"--pipeline-model-parallel-size\": \"${PP}\",\n      \"--num-key-value-heads\": \"${NUM_KV_HEAD}\",\n      \"--data-cache-path\": \"${DATA_CACHE_PATH}\",\n      \"--ffn-hidden-size\": \"${FFN_HIDDEN_SIZE}\",\n      \"--tokenizer-model\": \"${TOKENIZER_MODEL}\",\n      \"${LLAMA_ARGS}\": \"${LLAMA_ARGS}\",\n      \"$ds_args\": \"$ds_args\",\n      \"${gpt_args[*]}\": \"${gpt_args[*]}\",\n      \"$custom_args\": \"$custom_args\"\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 1350,
        "candidates_token_count": 720,
        "total_token_count": 2070,
        "cached_content_token_count": 0
    }
}