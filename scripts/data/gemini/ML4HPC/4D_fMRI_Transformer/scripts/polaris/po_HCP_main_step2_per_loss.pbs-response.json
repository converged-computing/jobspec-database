{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"SLURM\",\n  \"details\": {\n    \"scheduler\": \"SLURM\",\n    \"resource_requirements\": {\n      \"nodes\": 1,\n      \"system\": \"polaris\",\n      \"placement\": \"scatter\",\n      \"walltime\": \"0:30:00\",\n      \"filesystems\": \"home:grand\",\n      \"queue\": \"debug\",\n      \"account\": \"STlearn\"\n    },\n    \"software_requirements\": {\n      \"conda\": \"3DCNN\",\n      \"python\": \"main.py\",\n      \"gpu_devices\": \"NVIDIA\",\n      \"script\": \"export_DDP_vars.sh\"\n    },\n    \"environment_variables\": {\n      \"MASTER_ADDR\": \"hostname\",\n      \"NNODES\": \"number of nodes\",\n      \"NRANKS_PER_NODE\": \"number of ranks per node\",\n      \"NDEPTH\": 8,\n      \"NTHREADS\": 1,\n      \"NTOTRANKS\": \"total number of ranks\"\n    },\n    \"command\": \"srun bash -c \\\"source export_DDP_vars.sh  python main.py --step 2 --batch_size_phase2 2 --exp_name per_loss_Stella_1024 --which_perceptual densenet3d --image_path /lus/grand/projects/STlearn/HCP_MNI_to_TRs --workers_phase2 4 \\\"\"\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 450,
        "candidates_token_count": 349,
        "total_token_count": 799,
        "cached_content_token_count": 0
    }
}