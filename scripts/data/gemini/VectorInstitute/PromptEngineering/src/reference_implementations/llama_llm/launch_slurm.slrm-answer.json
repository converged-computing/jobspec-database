{
    "application": "SLURM",
    "details": {
        "software": [
            "SLURM",
            "bash",
            "torchrun",
            "python",
            "LLaMA"
        ],
        "resources": {
            "nodes": 1,
            "tasks_per_node": 1,
            "gpus": 4,
            "cpus_per_task": 16,
            "memory": 0,
            "partition": "a40",
            "qos": "normal"
        },
        "environment_variables": [
            "LOGLEVEL",
            "NCCL_IB_DISABLE",
            "NCCL_DEBUG"
        ],
        "files": [
            "worker_script.sh",
            "llama/example.py",
            "tokenizer.model",
            "logs/output-%j-%t.out"
        ]
    }
}