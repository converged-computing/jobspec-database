{
    "application": "Deep Learning",
    "details": {
        "framework": "PyTorch",
        "model": "LLaMA 7B",
        "resource requirements": {
            "partition": "{Partition Name}",
            "gpus": 8,
            "nodes": 2,
            "cores per node": 16,
            "cores per task": 16
        },
        "training parameters": {
            "epochs": 1,
            "dataset": "image",
            "batch size": 40,
            "accumulation steps": 8,
            "model parallelism": 1,
            "data parallelism": "sdp",
            "checkpoint directory": "${LLAMA_7B_PATH}",
            "configuration file": "config/llama2/7B.json",
            "tokenizer": "config/llama2/tokenizer.model",
            "weight decay": 0.1,
            "output directory": "${OUTPUT_DIR}",
            "warmup iterations": 2000,
            "learning rate decay iterations": 200000,
            "learning rate": 5e-05,
            "minimum learning rate": 5e-06,
            "gradient clipping": 2,
            "save frequency": 1000
        }
    }
}