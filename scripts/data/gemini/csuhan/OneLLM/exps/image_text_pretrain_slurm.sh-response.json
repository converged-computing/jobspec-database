{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Deep Learning\",\n  \"details\": {\n    \"framework\": \"PyTorch\",\n    \"model\": \"LLaMA 7B\",\n    \"resource requirements\": {\n      \"partition\": \"{Partition Name}\",\n      \"gpus\": 8,\n      \"nodes\": 2,\n      \"cores per node\": 16,\n      \"cores per task\": 16\n    },\n    \"training parameters\": {\n      \"epochs\": 1,\n      \"dataset\": \"image\",\n      \"batch size\": 40,\n      \"accumulation steps\": 8,\n      \"model parallelism\": 1,\n      \"data parallelism\": \"sdp\",\n      \"checkpoint directory\": \"${LLAMA_7B_PATH}\",\n      \"configuration file\": \"config/llama2/7B.json\",\n      \"tokenizer\": \"config/llama2/tokenizer.model\",\n      \"weight decay\": 0.1,\n      \"output directory\": \"${OUTPUT_DIR}\",\n      \"warmup iterations\": 2000,\n      \"learning rate decay iterations\": 200000,\n      \"learning rate\": 5e-5,\n      \"minimum learning rate\": 5e-6,\n      \"gradient clipping\": 2,\n      \"save frequency\": 1000\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 315,
        "candidates_token_count": 310,
        "total_token_count": 625,
        "cached_content_token_count": 0
    }
}