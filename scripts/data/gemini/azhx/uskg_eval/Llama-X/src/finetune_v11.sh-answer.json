{
    "application": "SLURM",
    "details": {
        "software": [
            "conda",
            "huggingface transformers",
            "deepspeed",
            "torchrun",
            "python"
        ],
        "resource_requirements": {
            "memory": "200G",
            "cores": 10,
            "partition": "a100",
            "qos": "a100_wenhuchen",
            "gpu": 4,
            "nodes": 1
        },
        "environment_variables": {
            "NCCL_IB_HCA": "mlx5",
            "NCCL_IB_TC": 136,
            "NCCL_IB_SL": 5,
            "NCCL_IB_GID_INDEX": 3,
            "NCCL_SOCKET_IFNAME": "bond0",
            "NCCL_DEBUG": "INFO",
            "HF_HOME": "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/.cache/huggingface",
            "WANDB_DISABLED": "True"
        },
        "conda_environment": "SKGLM",
        "model_dir": "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/codellama/CodeLlama-7b-Instruct-hf",
        "data_path": "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/llama_data_v11_kg.json",
        "output_dir": "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/models/llama/v11_kg",
        "script": "train_on_formatted.py",
        "script_arguments": [
            "--model_name_or_path",
            "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/codellama/CodeLlama-7b-Instruct-hf",
            "--data_path",
            "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/llama_data_v11_kg.json",
            "--output_dir",
            "/cpfs/29cd2992fe666f2a/user/huangwenhao/alex/uskg_eval/models/llama/v11_kg",
            "--pkl_path",
            "cl_2048_v11_formatted.pkl",
            "--has_instruction",
            "True",
            "--dataset_type",
            "skg",
            "--num_train_epochs",
            "3",
            "--model_max_length",
            "2048",
            "--per_device_train_batch_size",
            "16",
            "--per_device_eval_batch_size",
            "1",
            "--gradient_accumulation_steps",
            "2",
            "--evaluation_strategy",
            "no",
            "--save_total_limit",
            "3",
            "--save_strategy",
            "epoch",
            "--learning_rate",
            "2e-5",
            "--warmup_ratio",
            "0.01",
            "--logging_steps",
            "2",
            "--lr_scheduler_type",
            "cosine",
            "--report_to",
            "tensorboard",
            "--gradient_checkpointing",
            "True",
            "--deepspeed",
            "configs/deepspeed_config_transformers4.31.json",
            "--fp16",
            "True"
        ]
    }
}