{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"TorchRun\",\n  \"details\": {\n    \"environment\": {\n      \"python\": \"3.10.12\",\n      \"cuda\": \"11.8\",\n      \"llm-env\": \"virtual environment\",\n      \"NCCL_IB_DISABLE\": \"1\",\n      \"NCCL_DEBUG\": \"WARN\",\n      \"NCCL_DEBUG_SUBSYS\": \"WARN\",\n      \"TORCH_DISTRIBUTED_DEBUG\": \"DETAIL\",\n      \"TORCH_CPP_LOG_LEVEL\": \"INFO\",\n      \"LOGLEVEL\": \"INFO\",\n      \"PYTHONFAULTHANDLER\": \"1\",\n      \"CUDA_LAUNCH_BLOCKING\": \"1\"\n    },\n    \"resources\": {\n      \"nodes\": \"1\",\n      \"memory\": \"0\",\n      \"tasks_per_node\": \"1\",\n      \"cpus_per_gpu\": \"4\",\n      \"gpus\": \"4\",\n      \"partition\": \"a40\",\n      \"qos\": \"m2\",\n      \"time\": \"01:00:00\"\n    },\n    \"other\": {\n      \"logging\": {\n        \"output\": \"llama-research.%j.out\",\n        \"error\": \"llama-research.%j.err\"\n      },\n      \"slurm\": {\n        \"job_name\": \"llama-research\",\n        \"open_mode\": \"append\",\n        \"wait_all_nodes\": \"1\"\n      },\n      \"rdzv\": {\n        \"id\": \"$RANDOM\",\n        \"backend\": \"c10d\"\n      }\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 2,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 665,
        "candidates_token_count": 385,
        "total_token_count": 1050,
        "cached_content_token_count": 0
    }
}