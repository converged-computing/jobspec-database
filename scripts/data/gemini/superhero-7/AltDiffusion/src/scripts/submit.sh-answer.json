{
    "application": "Slurm",
    "details": {
        "partition": "g40",
        "job_name": "laion5b",
        "nodes": 2,
        "ntasks_per_node": 8,
        "cpus_per_gpu": 12,
        "gres": "gpu:8",
        "time": "0-02:00:00",
        "modules": [
            "openmpi",
            "cuda/11.6",
            "NCCL/2.4.7-1-cuda.10.0"
        ],
        "conda_env": "$1",
        "python_path": "/fsx/zacliu/AltTools/Altdiffusion/src",
        "cuda_visible_devices": "0,1,2,3,4,5,6,7",
        "script": "/fsx/zacliu/AltTools/Altdiffusion/src/scripts/train_hpc.py",
        "output": "/fsx/zacliu/AltTools/Altdiffusion/src/laion5b.txt",
        "environment_variables": {
            "NCCL_DEBUG": "INFO",
            "PYTHONFAULTHANDLER": "1",
            "NCCL_SOCKET_IFNAME": "^docker0,lo",
            "NCCL_PROTO": "simple",
            "FI_EFA_FORK_SAFE": "1",
            "FI_LOG_LEVEL": "1",
            "FI_EFA_USE_DEVICE_RDMA": "1",
            "CUDA_LAUNCH_BLOCKING": "0",
            "OMPI_MCA_mtl_base_verbose": "1",
            "FI_EFA_ENABLE_SHM_TRANSFER": "0",
            "FI_PROVIDER": "efa",
            "FI_EFA_TX_MIN_CREDITS": "64",
            "NCCL_TREE_THRESHOLD": "0"
        }
    }
}