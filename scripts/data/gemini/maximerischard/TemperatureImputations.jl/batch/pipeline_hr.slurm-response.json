{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Julia\",\n  \"details\": {\n    \"runtime\": \"12 hours\",\n    \"memory\": \"2GB per core\",\n    \"cores\": \"1\",\n    \"nodes\": \"1\",\n    \"email\": \"mrischard@g.harvard.edu\",\n    \"job array\": \"1-119\",\n    \"dependencies\": {\n      \"julia_depots\": \"${HOME}/julia_depots/climate\",\n      \"julia_modules\": \"~/julia_modules.sh\",\n      \"pipeline_hr.jl\": \"/n/home04/mrischard/TempModel/batch/pipeline_hr.jl\"\n    },\n    \"data\": {\n      \"saved data\": \"/n/scratchlfs/pillai_lab/mrischard/temperature_model/saved\"\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 320,
        "candidates_token_count": 200,
        "total_token_count": 520,
        "cached_content_token_count": 0
    }
}