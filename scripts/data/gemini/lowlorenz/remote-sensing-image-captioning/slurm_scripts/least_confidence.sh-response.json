{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Slurm\",\n  \"details\": {\n    \"job_name\": \"conf_l_2\",\n    \"output_file\": \"/home/users/l/lorenz-08-15/activelearning_ic/cluster_outputs/conf_least_2.log\",\n    \"working_directory\": \"/home/users/l/lorenz-08-15/activelearning_ic/\",\n    \"nodes\": 1,\n    \"gpus\": 1,\n    \"tasks_per_node\": 1,\n    \"gpu_memory\": \"64G\",\n    \"cpus_per_task\": 16,\n    \"partition\": \"gpu_short\",\n    \"time_limit\": \"16:00:00\",\n    \"proxy\": {\n      \"https\": \"http://frontend01:3128/\",\n      \"http\": \"http://frontend01:3128/\"\n    },\n    \"cuda_version\": \"11.2\",\n    \"python_script\": \"main.py\",\n    \"script_arguments\": [\n      \"--batch_size\", \"12\",\n      \"--max_cycles\", \"9\",\n      \"--epochs\", \"10\",\n      \"--run_name\", \"conf_least_2\",\n      \"--sample_method\", \"confidence\",\n      \"--conf_mode\", \"least\",\n      \"--seed\", \"2\"\n    ]\n  }\n}\n``` \n"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 368,
        "candidates_token_count": 340,
        "total_token_count": 708,
        "cached_content_token_count": 0
    }
}