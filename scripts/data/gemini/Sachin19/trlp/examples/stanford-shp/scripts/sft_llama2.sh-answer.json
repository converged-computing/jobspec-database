{
    "application": "Torchrun",
    "details": {
        "software": [
            "CUDA 11.1.1",
            "cuDNN 11.1.1-v8.0.4.30",
            "gcc-7.4",
            "Anaconda3 (version 2022)",
            "Accelerate (not explicitly specified, but likely used)"
        ],
        "resource_requirements": {
            "nodes": 1,
            "processes_per_node": 1,
            "memory": "50 GB",
            "gpu": 1,
            "output_file": "./slurm-outputs/%j.out",
            "excluded_nodes": [
                "tir-0-32",
                "tir-0-36",
                "tir-0-11",
                "tir-1-32",
                "tir-1-18",
                "tir-1-13",
                "tir-1-11",
                "tir-0-3"
            ]
        },
        "environment_variables": {
            "HF_DATASETS_CACHE": "/projects/tir6/general/sachink/huggingface",
            "OMP_NUM_THREADS": "12"
        },
        "other_dependencies": [
            "huggingface datasets",
            "stanfordnlp/shp (data source, possibly via huggingface)"
        ],
        "model": "llama-7B",
        "data_source": "chp",
        "learning_rate": "1e-5",
        "max_steps": "5000",
        "output_dir": "/projects/tir6/general/sachink/personalized-LM/2023/models/1023-chp/sft/llama-7B_${instrtype}_${subset}"
    }
}