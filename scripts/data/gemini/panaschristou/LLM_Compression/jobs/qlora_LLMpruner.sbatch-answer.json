{
    "application": "SLURM",
    "details": {
        "job_name": "qlora",
        "nodes": 1,
        "cpus_per_task": 2,
        "memory": "36GB",
        "time": "47:59:00",
        "gres": "gpu:a100:1",
        "modules": [
            "cudnn/8.6.0.163-cuda11",
            "cuda/11.3.1"
        ],
        "overlay_ext3": "/home/xc1490/home/apps/llm2/overlay-15GB-500K.ext3",
        "singularity_image": "/scratch/work/public/singularity/cuda11.8.86-cudnn8.7-devel-ubuntu22.04.2.sif",
        "env_variables": {
            "BNB_CUDA_VERSION": "113",
            "LD_LIBRARY_PATH": "$LD_LIBRARY_PATH:/share/apps/cuda/11.3.1/lib64"
        },
        "python_script": "qlora.py",
        "model_name_or_path": [
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.2/checkpoint-1400",
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.4/checkpoint-1400",
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.5_block/checkpoint-1400",
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.2_channel/checkpoint-1200",
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.4_block/checkpoint-1400",
            "/scratch/pc2442/Project/LLM-Pruner-main/tune_log/llama_0.3/checkpoint-1400"
        ],
        "tokenizer": "huggyllama/llama-7b",
        "use_auth": true,
        "output_dir": [
            "./output/llmpruner_7B_llama_0.2_quant",
            "./output/llmpruner_7B_llama_0.4_quant",
            "./output/llmpruner_7B_llama_0.5_block_quant",
            "./output/llmpruner_7B_llama_0.2_channel_quant",
            "./output/llmpruner_7B_llama_0.4_quant",
            "./output/llmpruner_7B_llama_0.3_quant"
        ],
        "logging_steps": 10,
        "save_strategy": "steps",
        "data_seed": 42,
        "save_steps": 500,
        "save_total_limit": 40,
        "evaluation_strategy": "steps",
        "eval_dataset_size": 1024,
        "max_eval_samples": 1000,
        "per_device_eval_batch_size": 1,
        "max_new_tokens": 32,
        "dataloader_num_workers": 1,
        "group_by_length": true,
        "logging_strategy": "steps",
        "remove_unused_columns": false,
        "do_train": true,
        "do_eval": true,
        "do_mmlu_eval": true,
        "lora_r": 64,
        "lora_alpha": 16,
        "lora_modules": "all",
        "double_quant": true,
        "quant_type": "nf4",
        "bf16": true,
        "bits": 4,
        "warmup_ratio": 0.03,
        "lr_scheduler_type": "constant",
        "gradient_checkpointing": true,
        "dataset": "oasst1",
        "source_max_len": 16,
        "target_max_len": 512,
        "per_device_train_batch_size": 1,
        "gradient_accumulation_steps": 16,
        "max_steps": 1875,
        "eval_steps": 187,
        "learning_rate": 0.0002,
        "adam_beta2": 0.999,
        "max_grad_norm": 0.3,
        "lora_dropout": 0.1,
        "weight_decay": 0.0,
        "seed": 0
    }
}