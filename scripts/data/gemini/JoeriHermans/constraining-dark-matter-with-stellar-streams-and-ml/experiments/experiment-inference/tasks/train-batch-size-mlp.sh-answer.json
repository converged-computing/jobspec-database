{
    "application": "Slurm",
    "details": {
        "resources": {
            "cpus_per_task": 4,
            "gpus": 1,
            "memory_per_cpu": "5000M",
            "tasks": 1
        },
        "time_limit": "7-00:00:00",
        "output_file": "logging/train_batch_size_mlp_%a.log",
        "job_name": "STREAM_INFERENCE_TRAIN_BATCH_SIZE_MLP",
        "requeue": true,
        "export": "ALL",
        "parsable": true
    },
    "other_software": [
        "Python",
        "train.py"
    ]
}