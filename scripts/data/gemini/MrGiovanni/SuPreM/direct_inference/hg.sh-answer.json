{
    "application": "Slurm",
    "details": {
        "job_name": "inference",
        "nodes": 1,
        "tasks_per_node": 6,
        "gpu": "a100:1",
        "memory": "80G",
        "partition": "general",
        "time": "3:00:00",
        "queue": "public",
        "modules": [
            "mamba/latest"
        ],
        "conda_env": "suprem",
        "python_version": "3.9",
        "packages": [
            "torch==1.11.0+cu113",
            "torchvision==0.12.0+cu113",
            "torchaudio==0.11.0",
            "monai[all]==0.9.0"
        ],
        "requirements_file": "requirements.txt",
        "script": "inference.py"
    }
}