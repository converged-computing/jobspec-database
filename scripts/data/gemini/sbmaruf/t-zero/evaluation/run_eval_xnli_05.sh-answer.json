{
    "application": "SLURM",
    "details": {
        "scheduler": "SLURM",
        "partition": "PA100q",
        "nodes": "node03",
        "cores": 1,
        "gpu": "1",
        "modules": [
            "cuda11.6/toolkit/11.6.0"
        ],
        "environment": "anaconda3",
        "python_version": "py3",
        "cuda_device": 5,
        "output_directory": "dumped_trans",
        "datasets": [
            "xnli"
        ],
        "models": [
            "bigscience/tr13f-6b3-ml-t0-lmtoks341b-t0toks4b2-xp3capmixnewcodelonglossseq",
            "bigscience/tr13f-6b3-ml-t0-lmtoks341b-t0toks4b2-xp3mt"
        ],
        "templates": [
            "take the following as truth",
            "does this imply",
            "GPT-3 style",
            "does it follow that",
            "based on the previous passage",
            "guaranteed true",
            "should assume",
            "must be true",
            "can we infer",
            "justified in saying",
            "claim true/false/inconclusive",
            "consider always/sometimes/never",
            "always/sometimes/never",
            "guaranteed/possible/impossible",
            "MNLI crowdsource"
        ],
        "script": "run_eval.py",
        "additional_scripts": [
            "run_eval_xcopa_05.sh",
            "run.py"
        ]
    }
}