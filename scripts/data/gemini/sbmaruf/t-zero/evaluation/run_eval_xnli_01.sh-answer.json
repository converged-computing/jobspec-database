{
    "application": "SLURM",
    "details": {
        "queue": "PA100q",
        "nodes": 1,
        "nodelist": "node03",
        "gpu": 1,
        "modules": [
            "cuda11.6/toolkit/11.6.0"
        ],
        "environment": "anaconda3",
        "python_version": "3",
        "cuda_visible_devices": 1,
        "scripts": [
            "run_eval.py",
            "run_eval_xcopa_01.sh",
            "run.py"
        ],
        "datasets": [
            "xnli"
        ],
        "model_signatures": [
            "tr13f-6b3-ml-t0-lmtoks341b-t0toks4b2-xp3capmixnewcodelonglossseq",
            "tr13f-6b3-ml-t0-lmtoks341b-t0toks4b2-xp3mt"
        ],
        "dataset_config_names": [
            "en",
            "fr",
            "es",
            "de",
            "el",
            "bg",
            "ru",
            "tr",
            "ar",
            "vi",
            "th",
            "zh",
            "hi",
            "sw",
            "ur"
        ],
        "template_names": [
            "take the following as truth",
            "does this imply",
            "GPT-3 style",
            "does it follow that",
            "based on the previous passage",
            "guaranteed true",
            "should assume",
            "must be true",
            "can we infer",
            "justified in saying",
            "claim true/false/inconclusive",
            "consider always/sometimes/never",
            "always/sometimes/never",
            "guaranteed/possible/impossible",
            "MNLI crowdsource"
        ],
        "output_dir": "dumped_trans",
        "sleep_intervals": 2,
        "scripts_to_run_after": [
            "run_eval_pawsx_00.sh"
        ]
    }
}