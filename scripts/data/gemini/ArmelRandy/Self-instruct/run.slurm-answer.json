{
    "application": "Self-Instruct",
    "software": [
        "Python 3",
        "Torch.distributed",
        "Accelerate (optional)",
        "Conda",
        "WandB",
        "Hugging Face Datasets",
        "CUDA 11.6",
        "NCCL",
        "EFA",
        "Slurm"
    ],
    "resource_requirements": {
        "nodes": 1,
        "tasks_per_node": 1,
        "cpus_per_task": 48,
        "gpus": 8,
        "memory_per_cpu": "11G",
        "partition": "production-cluster",
        "output_directory": "/fsx/armel/Self-instruct/logs",
        "environment_variables": {
            "GPUS_PER_NODE": 8,
            "MASTER_ADDR": "Determined by scontrol",
            "MASTER_PORT": 6000,
            "NNODES": "Determined by Slurm",
            "NODE_RANK": "Determined by Slurm",
            "WORLD_SIZE": "Determined by GPUS_PER_NODE and NNODES",
            "WANDB_PROJECT": "test",
            "HF_DATASETS_CACHE": "/fsx/armel/.cache",
            "PATH_TO_LOG": "/fsx/armel/Self-instruct/logs",
            "LOG_PATH": "/fsx/armel/Self-instruct/logs/test_log.txt",
            "LAUNCHER": "python3 -u -m torch.distributed.run --nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --rdzv_endpoint $MASTER_ADDR:$MASTER_PORT --rdzv_backend c10d --max_restarts 0 --tee 3",
            "CUDA_HOME": "/usr/local/cuda-11.6",
            "LD_PRELOAD": "$CUDA_HOME/lib/libnccl.so",
            "LD_LIBRARY_PATH": "$CUDA_HOME/efa/lib:$CUDA_HOME/lib:$CUDA_HOME/lib64:$LD_LIBRARY_PATH",
            "NCCL_PROTO": "simple",
            "RDMAV_FORK_SAFE": 1,
            "FI_EFA_FORK_SAFE": 1,
            "FI_EFA_USE_DEVICE_RDMA": 1,
            "FI_PROVIDER": "efa",
            "FI_LOG_LEVEL": 1,
            "NCCL_IB_DISABLE": 1,
            "NCCL_SOCKET_IFNAME": "ens",
            "SRUN_ARGS": "--wait=60 --kill-on-bad-exit=1"
        }
    }
}