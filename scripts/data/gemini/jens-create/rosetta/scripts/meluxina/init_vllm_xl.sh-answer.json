{
    "application": "SLURM",
    "details": {
        "resource_requests": {
            "nodes": 1,
            "tasks": 1,
            "gpus_per_task": 4,
            "cpus_per_task": 1,
            "time": "02:00:00",
            "partition": "gpu",
            "account": "p200149",
            "qos": "default"
        },
        "software": {
            "python": "vllm.entrypoints.api_server",
            "cuda": "CUDA/11.7"
        },
        "other_requirements": {
            "credentials": "credentials.txt",
            "download_dir": "/project/scratch/p200149/vllm",
            "models": [
                "mistralai/Mixtral-8x7B-v0.1",
                "mistralai/Mixtral-8x7B-Instruct-v0.1",
                "meta-llama/Llama-2-70b-hf",
                "meta-llama/Llama-2-70b-chat-hf",
                "codellama/CodeLlama-34b-Instruct-hf",
                "codellama/CodeLlama-34b-hf"
            ]
        }
    }
}