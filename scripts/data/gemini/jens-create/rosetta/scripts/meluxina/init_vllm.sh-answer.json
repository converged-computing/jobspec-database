{
    "application": "SLURM",
    "details": {
        "resource_requirements": {
            "nodes": 1,
            "tasks": 4,
            "gpus_per_task": 1,
            "cpus_per_task": 1,
            "time": "03:00:00",
            "partition": "gpu",
            "account": "p200149",
            "qos": "default"
        },
        "software_requirements": {
            "python": "vllm.entrypoints.api_server",
            "models": [
                "mistralai/Mistral-7B-Instruct-v0.1",
                "mistralai/Mistral-7B-Instruct-v0.2",
                "meta-llama/Llama-2-13b-chat-hf",
                "codellama/CodeLlama-13b-Instruct-hf"
            ]
        },
        "other_requirements": {
            "credentials": "credentials.txt",
            "working_directory": "/project/scratch/p200149/vllm"
        }
    }
}