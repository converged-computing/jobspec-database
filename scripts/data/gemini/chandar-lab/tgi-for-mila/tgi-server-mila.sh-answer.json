{
    "application": "text-generation-server",
    "software": [
        "micromamba",
        "python",
        "git-lfs",
        "pyarrow",
        "pytorch",
        "cuda",
        "cudnn",
        "openssl",
        "ninja",
        "flash_attn",
        "vllm",
        "rotary_emb",
        "dropout_layer_norm",
        "awq_inference_engine",
        "EETQ",
        "exllama_kernels",
        "exllamav2_kernels",
        "custom_kernels",
        "megablocks",
        "causal_conv1d",
        "mamba_ssm",
        "text-generation-launcher"
    ],
    "resource_requirements": {
        "cpus": 4,
        "gpus": 1,
        "memory": "24G",
        "time": "2:59:00",
        "constraints": "ampere"
    },
    "environment_variables": {
        "TGI_VERSION": "1.4.4",
        "FLASH_ATTN_VERSION": "2.3.2",
        "RELEASE_DIR": "$HOME/tgi-release",
        "TGI_DIR": "$SCRATCH/tgi",
        "TGI_TMP": "$SLURM_TMPDIR/tgi",
        "HF_HUB_OFFLINE": "1",
        "HF_DATASETS_OFFLINE": "1",
        "TRANSFORMERS_OFFLINE": "1",
        "HF_HUB_DISABLE_TELEMETRY": "1",
        "HF_HUB_ENABLE_HF_TRANSFER": "1",
        "HUGGINGFACE_HUB_CACHE": "$TGI_DIR/tgi-data",
        "MODEL_PATH": "$TGI_DIR/tgi-repos/$MODEL_ID",
        "NUM_SHARD": "$default_num_shard",
        "PORT": "$default_port",
        "MASTER_PORT": "$default_master_port",
        "SHARD_UDS_PATH": "$default_shard_usd_path"
    }
}