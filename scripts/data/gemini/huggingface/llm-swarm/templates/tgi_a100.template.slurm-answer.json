{
    "application": "Docker",
    "software": [
        "Slurm",
        "Docker",
        "Hugging Face Text Generation Inference",
        "ss",
        "awk",
        "cut",
        "sort",
        "comm",
        "shuf",
        "head"
    ],
    "resources": {
        "gpu": "8",
        "cpu": "12",
        "memory": "11G",
        "volume": "/fsx/.cache"
    },
    "parameters": {
        "model": "{{model}}",
        "revision": "{{revision}}",
        "slurm_hosts_path": "{{slurm_hosts_path}}",
        "model_max_length": "{{model_max_length}}",
        "model_input_length": "{{model_input_length}}"
    }
}