{
    "application": "accelerate",
    "details": {
        "framework": "PyTorch",
        "library": "Transformers",
        "model": "rinna/japanese-gpt-neox-3.6b",
        "compute_resources": {
            "cpus": 8,
            "memory": "64G",
            "gpus": 1
        },
        "docker_image": "imc.tut.ac.jp/transformers-pytorch-cuda118:4.31.0",
        "mixed_precision": "bf16",
        "environment_variables": {
            "TORCH_HOME": "${PBS_O_WORKDIR}/.cache/torch",
            "TRANSFORMERS_CACHE": "${PBS_O_WORKDIR}/.cache/transformers",
            "HF_HOME": "${PBS_O_WORKDIR}/.cache/huggingface",
            "TORCH_USE_CUDA_DSA": "1"
        }
    }
}