{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Torque\",\n  \"details\": {\n    \"scheduler\": \"Torque\",\n    \"resource_requirements\": {\n      \"nodes\": \"determined by the script based on the number of CPUs and GPUs required\",\n      \"gres\": \"atlas1%atlas2\",\n      \"account\": \"NTI112\",\n      \"queue\": \"debug (if debug_q is set)\"\n    },\n    \"modules\": [\n      \"PrgEnv-gnu\",\n      \"fftw\",\n      \"lammps\",\n      \"dynamic-link\",\n      \"gromacs/5.1.0\",\n      \"python/3.5.1\",\n      \"wraprun\"\n    ],\n    \"environment_variables\": {\n      \"CRAY_CUDA_MPS\": \"1\",\n      \"LD_LIBRARY_PATH\": \"set dynamically based on conda environment\",\n      \"PATH\": \"/ccs/proj/nti112/incite35/bin:$PATH\",\n      \"OMP_NUM_THREADS\": \"set dynamically based on operation directives\",\n      \"CONDALIBS\": \"set dynamically based on conda environment\"\n    },\n    \"conda_environment\": \"/ccs/proj/nti112/incite35\",\n    \"mpiexec\": \"aprun\",\n    \"parallelism\": \"supported using 'wraprun' or 'mpiexec' with 'aprun'\"\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 906,
        "candidates_token_count": 325,
        "total_token_count": 1231,
        "cached_content_token_count": 0
    }
}