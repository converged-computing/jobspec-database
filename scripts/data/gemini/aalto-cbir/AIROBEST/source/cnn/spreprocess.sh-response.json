{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"SLURM\",\n  \"details\": {\n    \"job_name\": \"preprocess\",\n    \"account\": \"project_2001284\",\n    \"gpu\": \"v100\",\n    \"gpu_count\": 1,\n    \"partition\": \"gpu\",\n    \"time\": \"1:30:00\",\n    \"memory_per_cpu\": \"200000\",\n    \"modules\": [\n      \"pytorch\"\n    ],\n    \"python_version\": \"3.6\",\n    \"python_environment\": \"intelpython3.6-2018.3\",\n    \"gcc_version\": \"5.4.0\",\n    \"script\": \"preprocess.py\",\n    \"data_dir\": \"/scratch/project_2001284/hyperspectral\",\n    \"save_dir\": \"new_TAIGA\",\n    \"hyperspec_image\": \"20170615_reflectance_mosaic_128b.hdr\",\n    \"forestdata\": \"forestdata_stands.hdr\",\n    \"src_file_name\": \"hyperspectral_src\",\n    \"tgt_file_name\": \"hyperspectral_tgt_normalized\",\n    \"metadata_file_name\": \"metadata\",\n    \"normalize_method\": \"l2norm_along_channel\",\n    \"label_normalize_method\": \"clip\",\n    \"ignored_bands\": [],\n    \"additional_arguments\": [\n      \"--ignore_zero_labels\",\n      \"--remove_bad_data\"\n    ]\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 850,
        "candidates_token_count": 380,
        "total_token_count": 1230,
        "cached_content_token_count": 0
    }
}