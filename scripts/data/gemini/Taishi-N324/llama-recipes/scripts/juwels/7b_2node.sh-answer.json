{
    "application": "MPI",
    "details": {
        "software": [
            "SLURM",
            "Miniconda",
            "Python",
            "MPI",
            "CUDA",
            "NCCL",
            "UCX",
            "Hugging Face Transformers",
            "PyTorch",
            "FSDP",
            "WandB"
        ],
        "resources": {
            "nodes": 64,
            "tasks_per_node": 4,
            "gpus_per_node": 4,
            "cpus_per_task": 10,
            "partition": "booster",
            "environment": "/p/project/ccstdl/nakamura2/llama-recipe-torch2.1_cuda-11.8",
            "dataset": "/p/project/ccstdl/nakamura2/ABCI-llama-recipes/sample_datasets",
            "checkpoint_path": "/p/home/jusers/nakamura2/juwels/nakamura2/ABCI-llama-recipes/checkpoints/"
        },
        "configuration": {
            "batch_size": 8,
            "global_batch_size": 4096,
            "gradient_accumulation_steps": 128,
            "learning_rate": 0.0001,
            "learning_rate_min": 1e-05,
            "learning_rate_decay": 0.8,
            "learning_rate_warmup": 0.05,
            "learning_rate_decay_style": "cosine",
            "weight_decay": 0.1,
            "seed": 42,
            "num_epochs": 50,
            "num_workers_dataloader": 2,
            "model_name": "/p/home/jusers/nakamura2/juwels/nakamura2/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9",
            "tokenizer_name": "/p/home/jusers/nakamura2/juwels/nakamura2/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9"
        }
    }
}