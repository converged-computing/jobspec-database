{
    "application": "SLURM",
    "details": {
        "job_name": "pth0.005-pretrain-full",
        "qos": "qos_gpu-t4",
        "ntasks": 1,
        "gres": "gpu:2",
        "array": "1-3",
        "cpus_per_task": 16,
        "mem_per_cpu": "8g",
        "output": "slurm_out/vqa/pth0.005-trunc-pretrain-full-%j.out",
        "error": "slurm_out/vqa/pth0.005-trunc-pretrain-full-%j.err",
        "time": "100:00:00",
        "modules": [
            "pytorch-gpu/py3/1.7.1"
        ],
        "conda_env": "rl-nlp-2",
        "python_path": "src:${PYTHONPATH}",
        "script": "run.py",
        "arguments": [
            "-env",
            "vqa",
            "-max_len",
            "10",
            "-data_path",
            "data/vqa-v2/",
            "-out_path",
            "output/RL/VQAv2_add/truncated_policy/${SLURM_ARRAY_TASK_ID}",
            "-model",
            "lstm",
            "-update_every",
            "128",
            "-agent",
            "PPO",
            "-K_epochs",
            "20",
            "-eps_clip",
            "0.01",
            "-lr",
            "0.001",
            "-word_emb_size",
            "128",
            "-hidden_size",
            "256",
            "-num_episodes_train",
            "100000",
            "-lm_path",
            "output/vqa_lm_model/model.pt",
            "-reward",
            "vilbert_rank2",
            "-num_episodes_test",
            "20000",
            "-mask_answers",
            "1",
            "-fusion",
            "average",
            "-condition_answer",
            "after_fusion",
            "-features_path",
            "data/vqa-v2/coco_trainval.lmdb/",
            "-reward_vocab",
            "output/vilbert_vqav2/bert_base_6layer_6conect.json",
            "-reward_path",
            "output/vilbert_vqav2/model.bin",
            "-grad_clip",
            "5",
            "-truncate_mode",
            "proba_thr",
            "-p_th",
            "0.005",
            "-truncation_optim",
            "1",
            "-policy_path",
            "output/vqa_policy_128_256_answer/model.pt",
            "-eval_no_trunc",
            "0"
        ],
        "resources": {
            "data": [
                "data/vqa-v2/",
                "data/vqa-v2/coco_trainval.lmdb/",
                "output/vqa_lm_model/model.pt",
                "output/vqa_lm_model_smallvocab/model.pt",
                "output/RL/VQAv2",
                "output/vqa_policy_128_256_answer/model.pt",
                "output/vqa_policy_128_256_answer_smallvocab/model.pt",
                "output/vilbert_vqav2/bert_base_6layer_6conect.json",
                "output/vilbert_vqav2/model.bin"
            ],
            "output": [
                "output/RL/VQAv2_add/truncated_policy/${SLURM_ARRAY_TASK_ID}"
            ]
        }
    }
}