{
    "application": "slurm",
    "details": {
        "job_name": "temp3-pth",
        "qos": "qos_gpu-t4",
        "ntasks": 1,
        "gres": "gpu:2",
        "array": "1-3",
        "cpus_per_task": 16,
        "mem_per_cpu": "8g",
        "output": "slurm_out/vqa/temp3-pth-full%j.out",
        "error": "slurm_out/vqa/temp3-pth-full%j.err",
        "time": "100:00:00",
        "modules": [
            "pytorch-gpu/py3/1.7.1"
        ],
        "conda_env": "rl-nlp-2",
        "python_path": "src:${PYTHONPATH}",
        "data_path": "data/vqa-v2/",
        "features_path": "data/vqa-v2/coco_trainval.lmdb/",
        "lm_path": "output/vqa_lm_model/model.pt",
        "lm_path_min": "output/vqa_lm_model_smallvocab/model.pt",
        "output_path": "output/RL/VQAv2/trunc_policy",
        "policy_path": "output/vqa_policy_128_256_answer/model.pt",
        "policy_path_min": "output/vqa_policy_128_256_answer_smallvocab/model.pt",
        "vilbert_vocab": "output/vilbert_vqav2/bert_base_6layer_6conect.json",
        "vilbert_path": "output/vilbert_vqav2/model.bin",
        "k_epochs": 20,
        "max_len": 10,
        "update_every": 128,
        "debug": "0,20000",
        "num_episode_train": 100000,
        "num_episode_test": 20000,
        "env_": "vqa",
        "model": "lstm",
        "agent": "PPO",
        "lr": 0.001,
        "word_emb_size": 128,
        "hidden_size": 256,
        "eps_clip": 0.01,
        "reward": "vilbert_rank2",
        "fusion": "average",
        "condition_answer": "after_fusion",
        "temperature": 1.5,
        "temp_step": 15000,
        "temp_factor": 0.75,
        "temp_min": 1,
        "s_min": 1,
        "script": "src/scripts/run.py"
    }
}