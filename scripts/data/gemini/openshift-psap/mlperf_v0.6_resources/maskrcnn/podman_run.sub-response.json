{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n\"application\": \"Slurm\",\n\"details\": {\n\"partition\": \"mlperf\",\n\"nodes\": 1,\n\"walltime\": \"12:00:00\",\n\"job_name\": \"object_detection\",\n\"exclusive\": true,\n\"memory\": \"all available\",\n\"mail_type\": \"FAIL\",\n\"tasks_per_node\": 8,\n\"threads_per_core\": 2,\n\"cores_per_socket\": 20,\n\"benchmark\": \"object_detection\",\n\"benchmark_name\": \"MASKRCNN\",\n\"container\": \"mlperf-nvidia:object_detection\",\n\"data_dir\": \"/raid/data/coco-2017\",\n\"log_dir\": \"/raid/results/object_detection\",\n\"nexp\": 5,\n\"syslogging\": 1,\n\"dgxsystem\": \"DGX1\",\n\"ibdevices\": \"$DGXIBDEVICES\",\n\"docker_volumes\": \"-v $DATADIR:/data -v $LOGDIR:/results\",\n\"docker_exec\": \"env NV_GPU=${NV_GPU} podman run --rm --net=host --uts=host --ipc=host --ulimit stack=67108864 --ulimit memlock=-1 -e NVIDIA_VISIBLE_DEVICES=ALL --cap-drop=ALL --security-opt label=type:nvidia_container_t --security-opt seccomp=unconfined --name=cont_${SLURM_JOB_ID} $IBDEVICES\",\n\"mlperf_host_os\": \"$(cat /etc/redhat-release)\",\n\"pull\": \"0\"\n}\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 2407,
        "candidates_token_count": 380,
        "total_token_count": 2787,
        "cached_content_token_count": 0
    }
}