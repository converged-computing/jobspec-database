{
    "application": "SLURM",
    "details": {
        "job_name": "lm_eval_xgen-7b_multilingual-mt-few-shot",
        "cpus_per_task": 8,
        "nodes": 1,
        "ntasks_per_node": 1,
        "time": 0,
        "mem": "50GB",
        "gres": "gpu:1",
        "output": "../.slurm/lm_eval_xgen-7b_multilingual-mt-few-shot.out",
        "error": "../.slurm/lm_eval_xgen-7b_multilingual-mt-few-shot.err",
        "virtual_environment": "/gaueko0/users/jetxaniz007/phd/venv2",
        "transformers_cache": "/gaueko0/transformers_cache/",
        "tokenizers_parallelism": false,
        "models": [
            "Salesforce/xgen-7b-8k-base",
            "Salesforce/xgen-7b-4k-base",
            "Salesforce/xgen-7b-8k-inst"
        ],
        "tasks": [
            "xcopa-mt",
            "xstory_cloze-mt",
            "pawsx-mt",
            "xnli-mt",
            "xnli-mt-all"
        ],
        "python_script": "../../lm-evaluation-harness/main.py",
        "model_type": "hf-causal-experimental",
        "model_args": "pretrained=$model_name,dtype=bfloat16,trust_remote_code=True",
        "device": "cuda",
        "output_path": "../../results/xgen/${model_name:11}/${model_name:11}_${group_name}-few-shot_${num_fewshot}-shot.json",
        "batch_size": "auto",
        "cache": false,
        "num_fewshot": 0
    }
}