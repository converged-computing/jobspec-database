{
    "application": "SLURM",
    "details": {
        "job_name": "lm_eval_xgen-7b_mgsm",
        "cpus_per_task": 8,
        "nodes": 1,
        "ntasks_per_node": 1,
        "time": 0,
        "mem": "50GB",
        "gres": "gpu:1",
        "output": "../.slurm/lm_eval_xgen-7b_mgsm.out",
        "error": "../.slurm/lm_eval_xgen-7b_mgsm.err",
        "virtual_environment": "/gaueko0/users/jetxaniz007/phd/venv2",
        "transformers_cache": "/gaueko0/transformers_cache/",
        "tokenizers_parallelism": false,
        "models": [
            "Salesforce/xgen-7b-8k-base",
            "Salesforce/xgen-7b-4k-base",
            "Salesforce/xgen-7b-8k-inst"
        ],
        "tasks": [
            "mgsm"
        ],
        "num_fewshot": 8,
        "python_script": "../../lm-evaluation-harness/main.py",
        "model_type": "hf-causal-experimental",
        "model_args": "pretrained=$model_name,dtype=bfloat16,trust_remote_code=True",
        "device": "cuda",
        "output_path": "../../results/xgen/${model_name:11}/${model_name:11}_${group_name}_${num_fewshot}-shot.json",
        "batch_size": "auto",
        "no_cache": true
    }
}