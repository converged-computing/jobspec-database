{
    "application": "SLURM",
    "details": {
        "job_name": "llama",
        "output_file": "run_outputs/llama.%j.out",
        "cpus_per_task": 12,
        "time": "4:00:00",
        "gres": "gpu:a100_40gb:4",
        "partition": "brown,red",
        "mail_type": "BEGIN,FAIL,END",
        "account": "researchers",
        "other_software": [
            "nvidia-smi",
            "poetry",
            "python"
        ],
        "python_module": "src.worker_vs_gpt.llm_local"
    }
}