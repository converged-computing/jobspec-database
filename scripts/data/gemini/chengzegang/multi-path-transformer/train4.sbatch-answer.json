{
    "application": "Slurm",
    "details": {
        "resource_requirements": {
            "nodes": 1,
            "tasks_per_node": 1,
            "cpus_per_task": 64,
            "time": "168:00:00",
            "memory": "490GB",
            "gpu": "a100:4"
        },
        "software_requirements": {
            "singularity_image": "/scratch/work/public/singularity/cuda12.2.2-cudnn8.9.4-devel-ubuntu22.04.3.sif",
            "overlay": "/scratch/$USER/containers/overlay.ext3:ro",
            "environment_file": "/ext3/env.sh"
        },
        "other_requirements": {
            "cuda_version": "12.2.2",
            "cudnn_version": "8.9.4",
            "torch_version": "not specified",
            "python_version": "not specified",
            "framework": "PyTorch"
        },
        "script_description": "The script runs a PyTorch model using Singularity and Slurm to manage distributed training across multiple GPUs. It uses the `torchrun` command for launching and managing the training processes."
    }
}