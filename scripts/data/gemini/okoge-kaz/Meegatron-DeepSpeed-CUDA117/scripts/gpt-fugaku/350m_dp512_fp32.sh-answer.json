{
    "application": "SLURM",
    "details": {
        "software": [
            "CUDA 11.7",
            "cuDNN 8.9.0",
            "NCCL 2.14.3",
            "OpenMPI 4.0.5",
            "Python",
            "PyTorch"
        ],
        "resources": [
            "a100 GPU",
            "8 GPUs per node",
            "1 node",
            "7 days runtime",
            "1024 sequence length",
            "512 global batch size",
            "64 micro batch size",
            "350M parameter model",
            "checkpoint path: checkpoints/gpt-fugaku/350m_dp512_fp32/",
            "input prefix: dataset",
            "vocab file: gpt2-vocab.json",
            "merge file: gpt2-merges.txt",
            "data path: dataset/wikipedia/binarized/gpt-2/ja_wiki_text_document",
            "tensorboard directory: experiments/tensorboard",
            "distributed backend: nccl",
            "data implementation: mmap",
            "learning rate: 0.00015",
            "minimum learning rate: 1.0e-5",
            "learning rate decay style: cosine",
            "weight decay: 1e-2",
            "gradient clipping: 1.0",
            "learning rate warmup fraction: 0.01",
            "log interval: 1",
            "save interval: 300",
            "evaluation interval: 100",
            "evaluation iterations: 10",
            "checkpoint activations: enabled",
            "tensorboard logging: enabled",
            "wandb name: gpu-ja-wiki-350m_dp512"
        ]
    }
}