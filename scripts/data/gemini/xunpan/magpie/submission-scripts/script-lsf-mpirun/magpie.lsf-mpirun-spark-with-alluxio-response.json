{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "Magpie\n```json\n{\n\"application\": \"Magpie\",\n\"description\": \"Magpie is a framework that allows you to run Big Data applications on traditional HPC systems, specifically targeting Apache Spark and Alluxio.\",\n\"software_requirements\": {\n\"hadoop\": {\n\"description\": \"Apache Hadoop is a framework that allows for distributed storage and processing of large datasets.\",\n\"options\": {\n\"HADOOP_SETUP\": \"yes/no\",\n\"HADOOP_SETUP_TYPE\": \"MR/YARN\"\n}\n},\n\"spark\": {\n\"description\": \"Apache Spark is a cluster computing framework that provides a general engine for distributed data processing.\",\n\"options\": {\n\"SPARK_SETUP\": \"yes/no\",\n\"SPARK_SETUP_TYPE\": \"STANDALONE/YARN\",\n\"SPARK_VERSION\": \"version string\",\n\"SPARK_HOME\": \"path to Spark binaries\",\n\"SPARK_LOCAL_DIR\": \"path to local directory for Spark\",\n\"SPARK_CONF_FILES\": \"path to directory for alternate Spark configuration templates\",\n\"SPARK_WORKER_CORES_PER_NODE\": \"number of cores per worker node\",\n\"SPARK_WORKER_MEMORY_PER_NODE\": \"memory per worker node in MB\",\n\"SPARK_WORKER_DIRECTORY\": \"path to directory for Spark workers\",\n\"SPARK_JOB_MEMORY\": \"memory for Spark jobs in MB\",\n\"SPARK_DRIVER_MEMORY\": \"memory for Spark driver in MB\",\n\"SPARK_DAEMON_HEAP_MAX\": \"maximum heap size for Spark daemons in MB\",\n\"SPARK_ENVIRONMENT_EXTRA_PATH\": \"path to file containing extra environment variables\",\n\"SPARK_JOB\": \"name of the Spark job to run\",\n\"SPARK_DEFAULT_PARALLELISM\": \"number of tasks for distributed shuffle operations\",\n\"SPARK_MEMORY_FRACTION\": \"fraction of heap space for execution and storage\",\n\"SPARK_MEMORY_STORAGE_FRACTION\": \"fraction of storage memory immune to eviction\",\n\"SPARK_STORAGE_MEMORY_FRACTION\": \"fraction of Java heap for Spark memory cache\",\n\"SPARK_SHUFFLE_MEMORY_FRACTION\": \"fraction of Java heap for aggregation and cogroups during shuffles\",\n\"SPARK_RDD_COMPRESS\": \"boolean to enable/disable RDD compression\",\n\"SPARK_IO_COMPRESSION_CODEC\": \"compression codec to use for IO\",\n\"SPARK_DEPLOY_SPREADOUT\": \"boolean to enable/disable application spreading\",\n\"SPARK_JOB_CLASSPATH\": \"classpath for Spark jobs\",\n\"SPARK_JOB_LIBRARY_PATH\": \"library path for Spark jobs\",\n\"SPARK_JOB_JAVA_OPTS\": \"Java options for Spark jobs\",\n\"SPARK_LOCAL_SCRATCH_DIR\": \"path to local scratch directory\",\n\"SPARK_LOCAL_SCRATCH_DIR_CLEAR\": \"boolean to clear local scratch directory after job completion\",\n\"SPARK_NETWORK_TIMEOUT\": \"timeout for network operations in seconds\",\n\"SPARK_YARN_STAGING_DIR\": \"path to staging directory for Spark on Yarn\",\n\"SPARK_SPARKPI_SLICES\": \"number of slices for SparkPi example\",\n\"SPARK_SPARKWORDCOUNT_FILE\": \"path to file for SparkWordCount example\",\n\"SPARK_SPARKWORDCOUNT_COPY_IN_FILE\": \"path to file to copy in for SparkWordCount example\"\n},\n\"dependencies\": {\n\"java\": {\n\"version\": \"1.8.0\"\n},\n\"python\": {\n\"version\": \"/usr/bin/python\"\n}\n},\n\"resource_requirements\": {\n\"nodes\": {\n\"description\": \"Number of nodes required for the job, including one for the master node.\",\n\"variable\": \"my_node_count\"\n},\n\"time\": {\n\"description\": \"Time limit for the job in hours:minutes.\",\n\"variable\": \"my_time_in_hours:minutes\"\n},\n\"queue\": {\n\"description\": \"Queue to launch job in.\",\n\"variable\": \"my_queue\"\n},\n\"job_name\": {\n\"description\": \"Name of the job, used for naming directories.\",\n\"variable\": \"my_job_name\"\n},\n\"mpirun_options\": {\n\"description\": \"Optional mpirun options to be passed to the job.\",\n\"variable\": \"MPIRUN_OPTIONS\"\n}\n},\n\"other\": {\n\"MAGPIE_SCRIPTS_HOME\": \"path to the directory where Magpie scripts are stored\",\n\"MAGPIE_LOCAL_DIR\": \"path to local directory for Magpie\",\n\"MAGPIE_JOB_TYPE\": \"type of job to run\",\n\"MAGPIE_JOB_SCRIPT\": \"path to script to run for 'script' job type\",\n\"MAGPIE_STARTUP_TIME\": \"startup time for the job in minutes\",\n\"MAGPIE_SHUTDOWN_TIME\": \"shutdown time for the job in minutes\",\n\"MAGPIE_ONE_TIME_RUN\": \"boolean to indicate if the job is a one-time run\",\n\"MAGPIE_PRE_JOB_RUN\": \"path to script to run before the job\",\n\"MAGPIE_POST_JOB_RUN\": \"path to script to run after the job\",\n\"MAGPIE_PRE_EXECUTE_RUN\": \"path to script to run before executing the job\",\n\"MAGPIE_POST_EXECUTE_RUN\": \"path to script to run after executing the job\",\n\"MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT\": \"path to file for environment variables\",\n\"MAGPIE_ENVIRONMENT_VARIABLE_SCRIPT_SHELL\": \"shell type for environment variable script\",\n\"MAGPIE_REMOTE_CMD\": \"remote shell command\",\n\"MAGPIE_REMOTE_CMD_OPTS\": \"options for the remote shell command\",\n\"JAVA_HOME\": \"path to Java installation\",\n\"MAGPIE_PYTHON\": \"path to Python interpreter\",\n\"ALLUXIO_SETUP\": \"yes/no\",\n\"ALLUXIO_VERSION\": \"version string\",\n\"ALLUXIO_HOME\": \"path to Alluxio binaries\",\n\"ALLUXIO_WORKER_ON_MASTER\": \"yes/no\",\n\"ALLUXIO_LOCAL_DIR\": \"path to local directory for Alluxio\",\n\"ALLUXIO_UNDER_FS_DIR\": \"path to Alluxio Under File System directory\",\n\"ALLUXIO_DATA_CLEAR\": \"yes/no\",\n\"ALLUXIO_WORKER_MEMORY_SIZE\": \"memory size for Alluxio workers\",\n\"ALLUXIO_WORKER_TIER0_PATH\": \"path to tiered storage level 0\",\n\"ALLUXIO_RAMFS_MOUNT_OPTION\": \"mount option for RamFS\",\n\"ALLUXIO_READ_TYPE\": \"default read type for Alluxio files\",\n\"ALLUXIO_WRITE_TYPE\": \"default write type for Alluxio files\",\n\"ALLUXIO_JOB\": \"name of the Alluxio job to run\"\n}\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 8895,
        "candidates_token_count": 1582,
        "total_token_count": 10477,
        "cached_content_token_count": 0
    }
}