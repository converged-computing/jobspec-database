{
    "application": "SLURM",
    "details": {
        "job_name": "llmcompr",
        "partition": "ais-gpu",
        "mail_type": "ALL",
        "mail_user": "V.Moskvoretskii@skoltech.ru",
        "output": "zh_logs/gptvq_log.txt",
        "time": "0-05",
        "memory": "32G",
        "nodes": 1,
        "cores": 8,
        "gpus": 1,
        "singularity_image": "/trinity/home/v.moskvoretskii/images/gptvq.sif",
        "python_script": "llama.py",
        "model": "meta-llama/Llama-2-7b-hf",
        "dataset": "wikitext2",
        "environment_variables": {
            "HF_TOKEN": "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",
            "SAVING_DIR": "/home/cache/",
            "HF_HOME": "/home/cache/",
            "TRANSFORMERS_CACHE": "/home/cache/",
            "WANDB_API_KEY": "2b740bffb4c588c7274a6e8cf4e39bd56344d492",
            "CUDA_LAUNCH_BLOCKING": 1
        },
        "script_arguments": {
            "columns-per-group": 128,
            "use-vq": true,
            "kmeans-iters": 100,
            "kmeans-init-method": "mahalanobis",
            "hessian-weighted-lookups": true,
            "include-m-step": true,
            "wbits": 2,
            "vq-dim": 2,
            "groupsize": 2048,
            "codebook-bitwidth": 8,
            "quantize-per-codebook": true,
            "output-dir": "/home/cache/gptvq_llama7b/"
        }
    }
}