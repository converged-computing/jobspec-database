{
    "application": "SLURM",
    "details": {
        "cluster": "gpu",
        "gpu_count": 1,
        "partition": "titanx",
        "job_name": "attn_concat.input_feeding.copy",
        "output_file": "/zfs1/pbrusilovsky/rum20/seq2seq-keyphrase-pytorch/slurm_output/attn_concat.input_feeding.copy.out",
        "nodes": 1,
        "tasks_per_node": 1,
        "cpus_per_task": 1,
        "memory": "64GB",
        "python_module": "train",
        "data_path": "data/kp20k/kp20k",
        "vocab_path": "data/kp20k/kp20k.vocab.pt",
        "exp_path": "/zfs1/pbrusilovsky/rum20/seq2seq-keyphrase-pytorch/exp/attn_concat.input_feeding.copy/%s.%s",
        "model_path": "/zfs1/pbrusilovsky/rum20/seq2seq-keyphrase-pytorch/model/attn_concat.input_feeding.copy/%s.%s",
        "pred_path": "/zfs1/pbrusilovsky/rum20/seq2seq-keyphrase-pytorch/pred/attn_concat.input_feeding.copy/%s.%s",
        "experiment": "kp20k",
        "batch_size": 64,
        "bidirectional": true,
        "copy_model": true,
        "run_valid_every": 4000,
        "save_model_every": 10000,
        "beam_size": 16,
        "beam_search_batch_size": 16,
        "train_ml": true,
        "attention_mode": "concat",
        "input_feeding": true
    }
}