{
    "application": "SLURM",
    "details": {
        "job_name": "train_mml_pgg_off_fold_1",
        "account": "def-afyshe-ab",
        "nodes": 1,
        "tasks_per_node": 1,
        "gpu": "a100:1",
        "memory": "24000M",
        "time": "0-01:00",
        "cpus_per_task": 3,
        "modules": [
            "StdEnv/2020",
            "gcc/9.3.0",
            "cuda/11.4",
            "arrow/5.0.0"
        ],
        "environment": {
            "NCCL_BLOCKING_WAIT": 1,
            "MASTER_ADDR": "hostname"
        },
        "python_script": "src/re_gold_qa_train.py",
        "dependencies": [
            "dreamscape-qa/env/bin/activate",
            "python",
            "src/re_gold_qa_train.py"
        ],
        "parameters": [
            "--mode re_qa_train",
            "--model_path $SCRATCH/april-1/fold_1/mml-pgg-off-sim/",
            "--answer_checkpoint _response_pretrained",
            "--question_checkpoint _fold_1_question_pretrained",
            "--training_steps 5200",
            "--learning_rate 0.0005",
            "--max_epochs 1",
            "--num_search_samples 8",
            "--batch_size 16",
            "--gpu True",
            "--train $SCRATCH/QA-ZRE/zero-shot-extraction/relation_splits/train.0",
            "--gpu_device 0",
            "--seed 12321",
            "--train_method MML-PGG-Off-Sim",
            "--mode fewrl_dev",
            "--model_path /home/saeednjf/scratch/feb-15-2022-arr/fold_${fold_num}/mml-mml-off-sim/",
            "--answer_checkpoint _0_answer_step_${step}",
            "--question_checkpoint _0_question_step_${step}",
            "--num_search_samples 8",
            "--batch_size 16",
            "--gpu True",
            "--dev $SCRATCH/QA-ZRE/zero-shot-extraction/relation_splits/dev.${fold_data_id}",
            "--gpu_device 0",
            "--seed 12321",
            "--prediction_file /home/saeednjf/scratch/feb-15-2022-arr/fold_${fold_num}/mml-mml-off-sim/relation.mml-mml-off-sim.run.0.dev.predictions.step.${step}.csv",
            "--predict_type relation",
            "--mode fewrl_dev",
            "--model_path /home/snajafi/march-23-models/fold_1/mml-pgg-off-sim/",
            "--answer_checkpoint _${e}_answer_step_${step}",
            "--question_checkpoint _fold_1_question_pretrained",
            "--num_search_samples 8",
            "--batch_size 8",
            "--gpu True",
            "--dev ./zero-shot-extraction/relation_splits/dev.0",
            "--gpu_device 0",
            "--seed 12321",
            "--prediction_file /home/snajafi/march-23-models/fold_1/mml-pgg-off-sim/init_q.relation.mml-pgg-off-sim.run.${e}.dev.predictions.step.${step}.csv",
            "--predict_type relation",
            "--mode re_qa_test",
            "--model_path $SCRATCH/fold_1/mml-pgg-off-sim/",
            "--answer_checkpoint _0_answer_full",
            "--question_checkpoint _0_question_full",
            "--num_search_samples 8",
            "--batch_size 64",
            "--gpu True",
            "--ignore_unknowns True",
            "--train zero-shot-extraction/relation_splits/train.very_small.0",
            "--dev zero-shot-extraction/relation_splits/dev.0",
            "--gpu_device 0",
            "--seed 12321",
            "--prediction_file $SCRATCH/fold_1/mml-pgg-off-sim/mml_pgg_off_sim.dev.predictions.step.${step}.csv",
            "--mode re_qa_test",
            "--model_path $SCRATCH/fold_1/mml-pgg-off-sim/",
            "--answer_checkpoint _0_answer_step_500",
            "--question_checkpoint _0_question_step_500",
            "--num_search_samples 8",
            "--batch_size 64",
            "--gpu True",
            "--ignore_unknowns True",
            "--train zero-shot-extraction/relation_splits/train.very_small.0",
            "--dev zero-shot-extraction/relation_splits/test.0",
            "--gpu_device 0",
            "--seed 12321",
            "--prediction_file $SCRATCH/fold_1/mml-pgg-off-sim/mml_pgg_off_sim.test.predictions.step.500.csv"
        ]
    }
}