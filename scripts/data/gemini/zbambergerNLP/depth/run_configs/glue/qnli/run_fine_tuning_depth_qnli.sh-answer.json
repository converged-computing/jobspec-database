{
    "application": "SLURM",
    "details": {
        "job_name": "principled-pre-training",
        "nodes": 1,
        "gpus": 2,
        "cpus_per_task": 32,
        "account": "nlp",
        "partition": "nlp",
        "nodes_list": "nlp-ada-[1,2]",
        "stdout": "fine_tuning_runs/slurm_%N_%j_out.txt",
        "stderr": "fine_tuning_runs/slurm_%N_%j_err.txt",
        "mail_type": "fail",
        "mail_user": "zachary@campus.technion.ac.il",
        "virtual_environment": ".depth/bin/activate",
        "environment_variables": {
            "DS_SKIP_CUDA_CHECK": 1,
            "OMP_NUM_THREADS": "$SLURM_CPUS_PER_TASK"
        },
        "software": {
            "nvidia-smi": "Used for checking GPU availability",
            "deepspeed": "For distributed training",
            "accelerate": "For mixed precision training",
            "train_encoder_decoder.py": "The main script for training the model",
            "wandb": "For logging and visualization"
        },
        "model": "DEPTH",
        "downstream_task": "QNLI",
        "precision": "bf16",
        "data_collator": "depth",
        "input_length": 512,
        "target_length": 16,
        "optimizer": "adamwscale",
        "learning_rate": 0.0001,
        "batch_size": 64,
        "gradient_accumulation_steps": 1,
        "total_steps": 10000,
        "warmup_steps": 1000,
        "evaluation_frequency": 500,
        "logging_frequency": 50,
        "checkpoint_frequency": 12000,
        "checkpoint_path": "checkpoints/pre_train/from_scratch/depth/c4_en/lr_0_0001_linear_bsz_200_shuffle_p_0_5/2024-03-11_18-50/checkpoint-2000"
    }
}