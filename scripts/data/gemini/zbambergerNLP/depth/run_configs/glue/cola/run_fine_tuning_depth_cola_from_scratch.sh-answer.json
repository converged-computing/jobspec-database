{
    "application": "Slurm",
    "details": {
        "job_name": "principled-pre-training",
        "nodes": 1,
        "gpus": 2,
        "cpus_per_task": 32,
        "partition": "nlp",
        "account": "nlp",
        "nodes_list": "nlp-ada-2,nlp-a40-1",
        "stdout": "fine_tuning_runs/slurm_%N_%j_out.txt",
        "stderr": "fine_tuning_runs/slurm_%N_%j_err.txt",
        "mail_type": "fail",
        "mail_user": "zachary@campus.technion.ac.il",
        "environment": {
            "virtual_env": ".depth/bin/activate",
            "DS_SKIP_CUDA_CHECK": 1,
            "OMP_NUM_THREADS": "$SLURM_CPUS_PER_TASK"
        },
        "software": {
            "deepspeed": "deepspeed",
            "python_script": "train_encoder_decoder.py"
        },
        "resources": {
            "model_checkpoint": "checkpoints/pre_train/from_scratch/depth/c4_en/lr_0_0001_linear_bsz_200_shuffle_p_0_5/2024-03-11_18-50/checkpoint-1000000",
            "dataset": "cola"
        },
        "training_parameters": {
            "mode": "ft",
            "num_gpus": 2,
            "num_cpus": 32,
            "precision": "bf16",
            "model_implementation": "depth",
            "use_deepspeed": true,
            "wandb": true,
            "compile": false,
            "input_length": 256,
            "target_length": 16,
            "data_collator": "depth",
            "total_steps": 3000,
            "warmup_steps": 300,
            "base_lr": 1e-05,
            "batch_size": 16,
            "grad_acc": 1,
            "evaluate_every_steps": 100,
            "logging_every_steps": 10,
            "checkpoint_every_steps": 10000,
            "lr_scheduler": "constant_with_warmup"
        }
    }
}