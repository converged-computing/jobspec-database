{
    "application": "SLURM",
    "details": {
        "software": [
            "deepspeed",
            "nvidia-smi"
        ],
        "resources": {
            "nodes": 1,
            "gpus": 2,
            "cpus": 32,
            "partition": "nlp",
            "account": "nlp",
            "nodes_list": "nlp-ada-2,nlp-a40-1",
            "virtual_environment": ".depth/bin/activate",
            "environment_variables": {
                "DS_SKIP_CUDA_CHECK": "1",
                "OMP_NUM_THREADS": "$SLURM_CPUS_PER_TASK"
            }
        },
        "output": {
            "stdout": "fine_tuning_runs/slurm_%N_%j_out.txt",
            "stderr": "fine_tuning_runs/slurm_%N_%j_err.txt",
            "email_type": "fail",
            "email_address": "zachary@campus.technion.ac.il"
        },
        "job_name": "principled-pre-training",
        "command": "deepspeed --no_local_rank --master_port=16702 --num_gpus=2 train_encoder_decoder.py mode=ft num_gpus=2 num_cpus=32 precision=bf16 model.model_implementation=hf_t5 model.compile=false data.input_length=512 data.target_length=32 data.num_workers=32 data.data_collator=custom_t5 downstream.benchmark_constants=OfekGlick/DiscoEval downstream.benchmark_dataset=SPwiki dataset.streaming=false optim.name=adamw_torch optim.base_lr=1e-5 optim.batch_size=64 optim.total_steps=1_500 optim.warmup_steps=100 optim.grad_acc=1 optim.lr_scheduler=linear checkpoint.checkpoint_path=checkpoints/pre_train/from_pretrained/hf_t5/allenai/c4_en/lr_0_0001_inverse_sqrt_bsz_200_shuffle_p_0_5/2024-04-03_20-31/checkpoint-256000 checkpoint.resume=false checkpoint.every_steps=4_000 checkpoint.save_total_limit=3 logging.every_steps=10 logging.wandb=true evaluate.every_steps=100"
    }
}