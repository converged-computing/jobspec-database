{
    "application": "Slurm",
    "details": {
        "nodes": 1,
        "tasks_per_node": 1,
        "partition": "small-g",
        "time": "48:00:00",
        "cpus_per_task": 8,
        "gpus_per_node": "mi250:1",
        "exclusive": "user",
        "hint": "nomultithread",
        "account": "project_462000241",
        "output": "logs/%j.out",
        "error": "logs/%j.err",
        "environment": {
            "virtual_env": "/pfs/lustrep2/scratch/project_462000241/muennighoff/venv",
            "working_directory": "/pfs/lustrep2/scratch/project_462000185/muennighoff/bigcode-evaluation-harness"
        },
        "command": "accelerate launch --config_file config_1gpus_bf16.yaml --main_process_port 25900 main.py --model starcoder --tasks humanevalfixtests-python --do_sample True --temperature 0.2 --n_samples 20 --batch_size 5 --allow_code_execution --save_generations --trust_remote_code --prompt instruct --save_generations_path generations_humanevalfixpython_starcoder.json --metric_output_path evaluation_humanevalfixpython_starcoder.json --max_length_generation 1800 --precision bf16",
        "software": [
            "accelerate",
            "starcoder"
        ]
    }
}