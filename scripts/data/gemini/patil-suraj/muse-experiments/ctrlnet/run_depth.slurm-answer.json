{
    "application": "ControlNet",
    "software": [
        "Python",
        "accelerate",
        "deepspeed",
        "fsdp",
        "torch",
        "transformers",
        "xformers",
        "wandb",
        "aws s3",
        "conda",
        "bash",
        "srun",
        "slurm"
    ],
    "resources": {
        "nodes": 2,
        "tasks_per_node": 1,
        "cpus_per_task": 96,
        "gpus_per_node": 8,
        "gpu_type": "not specified",
        "storage": {
            "fsx": "//fsx/suraj/controlnet-sd-xl-1.0-depth-zoe",
            "s3": "s3://muse-datasets/laion-aesthetic6plus-min512-data"
        },
        "other": {
            "accelerate_config": {
                "compute_environment": "LOCAL_MACHINE",
                "deepspeed_config": {},
                "distributed_type": "MULTI_GPU",
                "fsdp_config": {},
                "machine_rank": 0,
                "main_process_ip": "MASTER_ADDR",
                "main_process_port": 6000,
                "main_training_function": "main",
                "num_machines": "SLURM_NNODES",
                "num_processes": "NUM_GPUS",
                "use_cpu": false
            },
            "model_dir": "stabilityai/stable-diffusion-xl-base-1.0",
            "pretrained_vae_model_name_or_path": "madebyollin/sdxl-vae-fp16-fix",
            "control_type": "depth",
            "resolution": 1024,
            "learning_rate": 1e-05,
            "max_train_steps": 50000,
            "max_train_samples": 12000000,
            "dataloader_num_workers": 8,
            "validation_image": "/admin/home/suraj/code/muse-experiments/ctrlnet/zoe-depth-images",
            "validation_prompt": [
                "beautiful room",
                "two paradise birds",
                "a snowy house behind a forest",
                "a couple watching a romantic sunset",
                "boats in the Amazonas",
                "a beautiful face of a woman",
                "a skater in Brooklyn",
                "a tornado in Iowa"
            ],
            "train_shards_path_or_url": "pipe:aws s3 cp s3://muse-datasets/laion-aesthetic6plus-min512-data/{00000..01210}.tar -",
            "eval_shards_path_or_url": "pipe:aws s3 cp s3://muse-datasets/laion-aesthetic6plus-min512-data/{01209..01210}.tar -",
            "proportion_empty_prompts": 0.5,
            "validation_steps": 500,
            "train_batch_size": 8,
            "gradient_checkpointing": true,
            "use_8bit_adam": true,
            "enable_xformers_memory_efficient_attention": true,
            "gradient_accumulation_steps": 1,
            "seed": 42,
            "report_to": "wandb",
            "resume_from_checkpoint": "latest",
            "push_to_hub": true
        }
    }
}