{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"SLURM\",\n  \"details\": {\n    \"software\": [\n      \"Python\",\n      \"Bash\",\n      \"SLURM\",\n      \"main.py\"\n    ],\n    \"resources\": {\n      \"partition\": \"YOUR_PARTITION_HERE\",\n      \"cpus\": 10,\n      \"gpus\": 1,\n      \"memory\": \"0GB\",\n      \"time\": \"03:00:00\"\n    },\n    \"model\": [\n      \"codellama/CodeLlama-7b-hf\",\n      \"codellama/CodeLlama-13b-hf\",\n      \"codellama/CodeLlama-34b-hf\"\n    ],\n    \"parameters\": {\n      \"temperature\": [\n        0.2,\n        0.8\n      ],\n      \"batch_size\": 10,\n      \"n_samples\": 10,\n      \"max_length_generation\": 2048,\n      \"precision\": \"bf16\",\n      \"limit\": 800,\n      \"save_generations\": true,\n      \"save_generations_path\": \"model_generations_raw/${dir}/shard_$(($i)).json\",\n      \"cot\": true,\n      \"shuffle\": true\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 658,
        "candidates_token_count": 316,
        "total_token_count": 974,
        "cached_content_token_count": 0
    }
}