{
    "application": "llama.cpp",
    "details": {
        "model": "mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf",
        "libraries": [
            "CUDA 11.8.0",
            "pandas"
        ],
        "resources": {
            "time": "10:00",
            "cores": 20,
            "memory": "16G",
            "gpu": 1
        },
        "environment": "SLURM"
    }
}