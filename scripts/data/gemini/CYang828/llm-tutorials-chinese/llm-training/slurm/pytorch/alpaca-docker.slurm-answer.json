{
    "application": "Alpaca",
    "software": [
        "Docker",
        "PyTorch",
        "Torchrun",
        "Alpaca",
        "Llama"
    ],
    "resources": {
        "compute": {
            "nodes": 1,
            "tasks_per_node": 20,
            "cpus_per_task": 3
        },
        "gpu": {
            "gpus_per_node": 8
        },
        "memory": {
            "shm_size": "4G"
        },
        "storage": {
            "data_path": "/workspaces/alpaca_data_cleaned.json",
            "model_path": "/workspaces/llama-7b",
            "output_dir": "/workspaces/output"
        }
    }
}