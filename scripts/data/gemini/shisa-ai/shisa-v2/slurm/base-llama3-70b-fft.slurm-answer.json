{
    "application": "Axolotl",
    "details": {
        "framework": "PyTorch",
        "model": "Llama 3 70B",
        "config": "llama3-70b-fft.yaml",
        "accelerator": "GPU",
        "resources": {
            "nodes": 2,
            "tasks_per_node": 1,
            "gpus_per_node": 8,
            "memory": "Not Specified",
            "storage": "/fsx/user02/logs/"
        },
        "libraries": [
            "Axolotl",
            "Accelerate",
            "Transformers",
            "Hugging Face Hub",
            "Weights and Biases"
        ],
        "slurm": {
            "partition": "dev",
            "job_name": "base-llama3-70b",
            "output": "/fsx/user02/logs/%x-%j.out",
            "error": "/fsx/user02/logs/%x-%j.err"
        }
    }
}