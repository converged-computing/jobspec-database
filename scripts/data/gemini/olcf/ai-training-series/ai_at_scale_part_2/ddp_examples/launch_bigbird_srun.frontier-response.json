{
    "candidates": [
        {
            "content": {
                "parts": [
                    {
                        "text": "```json\n{\n  \"application\": \"Slurm\",\n  \"details\": {\n    \"software\": [\n      \"Miniconda3\",\n      \"Conda\",\n      \"Python 3.10\",\n      \"PyTorch\",\n      \"DeepSpeed\",\n      \"Transformers\",\n      \"Hugging Face Datasets\",\n      \"gcc 11.2.0\",\n      \"ROCm 5.4.0\",\n      \"srun\",\n      \"ssh\",\n      \"sed\"\n    ],\n    \"resources\": {\n      \"nodes\": 10,\n      \"cores_per_node\": 8,\n      \"gpus_per_node\": 8,\n      \"wall_time\": \"00:20:00\",\n      \"queue\": \"batch\",\n      \"environment_variables\": [\n        \"PATH\",\n        \"LD_PRELOAD\",\n        \"ROCM_HOME\",\n        \"TORCH_EXTENSIONS_DIR\",\n        \"HF_HOME\",\n        \"OMP_NUM_THREADS\",\n        \"TRANSFORMERS_OFFLINE\",\n        \"HF_DATASETS_OFFLINE\",\n        \"MASTER_ADDR\"\n      ],\n      \"modules\": [\n        \"PrgEnv-gnu\",\n        \"gcc/11.2.0\",\n        \"rocm/5.4.0\"\n      ]\n    }\n  }\n}\n```"
                    }
                ],
                "role": "model"
            },
            "finish_reason": 1,
            "index": 0,
            "safety_ratings": [
                {
                    "category": 9,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 8,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 7,
                    "probability": 1,
                    "blocked": false
                },
                {
                    "category": 10,
                    "probability": 1,
                    "blocked": false
                }
            ],
            "token_count": 0,
            "grounding_attributions": []
        }
    ],
    "usage_metadata": {
        "prompt_token_count": 1040,
        "candidates_token_count": 320,
        "total_token_count": 1360,
        "cached_content_token_count": 0
    }
}