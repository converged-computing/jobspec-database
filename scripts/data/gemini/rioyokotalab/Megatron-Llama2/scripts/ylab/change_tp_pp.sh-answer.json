{
    "application": "SLURM",
    "details": {
        "job_name": "megatron-hf-convert",
        "time": "6:00:00",
        "output": "outputs/checkpoint-convert/%j.out",
        "error": "errors/checkpoint-convertk/%j.err",
        "modules": [
            "cuda/11.8",
            "cudnn/cuda-11.x/8.9.0",
            "nccl/cuda-11.7/2.14.3",
            "openmpi/4.0.5"
        ],
        "python_virtualenv": "/home/kazuki/llama/Megatron-LM/.env/bin/activate",
        "target_tensor_parallel_size": 1,
        "target_pipeline_parallel_size": 1,
        "base_tensor_parallel_size": 8,
        "base_pipeline_parallel_size": 8,
        "base_checkpoint_dir": "/home/kazuki/checkpoints/llama-2-70b-base/tp8-pp8",
        "target_checkpoint_dir": "/home/kazuki/checkpoints/llama-2-70b-base/tp1-pp1",
        "tokenizer_model": "/home/kazuki/hf_models/Llama-2-7b-hf/tokenizer.model",
        "iteration": 5000,
        "python_script": "tools/checkpoint/util.py",
        "model_type": "GPT",
        "loader": "megatron",
        "saver": "megatron",
        "megatron_path": "/home/kazuki/llama/Megatron-LM"
    }
}