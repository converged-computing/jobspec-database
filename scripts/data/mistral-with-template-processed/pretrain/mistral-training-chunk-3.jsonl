{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 8\n#SBATCH -J pre_1\n#SBATCH --exclusive\n#SBATCH -o Pre1.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_O_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_S_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TF_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TK_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TP_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TV_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_P_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TB_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TG_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TL_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TQ_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_U_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_Q_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TD_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TH_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TM_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TS_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_V_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_R_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TE_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TJ_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TN_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TU_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_X_512.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --init_checkpoint /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_model.ckpt \\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre1_cscd_all_512_from_bert\\\n --max_seq_length 512\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 8\\\n --learning_rate 2e-5\\\n --num_train_steps 2000000\\\n --save_checkpoints_steps 1000\\"}, {"role": "assistant", "content": {"application": "horovod", "software": ["mpirun", "python", "tensorflow"], "modules": [], "environment_variables": {"MIOPEN_USER_DB_PATH": "/tmp/tensorflow-miopen-${USER}-2.8", "MIOPEN_DEBUG_DISABLE_FIND_DB": "1", "HOROVOD_HIERARCHICAL_ALLREDUCE": "1"}, "resources": {"gres": "dcu:4", "cpus_per_task": "8", "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": true, "cpus_per_gpu": null, "gpu_type": null, "time": null, "ntasks_per_node": "4", "nodes": "8", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 8\n#SBATCH -J pre_4\n#SBATCH --exclusive\n#SBATCH -o Pre4.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_O_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_S_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TF_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TK_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TP_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TV_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_P_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TB_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TG_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TL_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TQ_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_U_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_Q_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TD_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TH_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TM_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TS_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_V_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_R_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TE_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TJ_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TN_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TU_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_X_512_wwm.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre4_cscd_all_512_wwm_from_scratch\\\n --max_seq_length 512\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 8\\\n --learning_rate 2e-5\\\n --num_train_steps 2000000\\\n --save_checkpoints_steps 1000\\"}, {"role": "assistant", "content": {"application": "tensorflow", "software": ["mpirun", "python", "horovod"], "modules": [], "environment_variables": {"MIOPEN_USER_DB_PATH": "/tmp/tensorflow-miopen-${USER}-2.8", "MIOPEN_DEBUG_DISABLE_FIND_DB": "1", "HOROVOD_HIERARCHICAL_ALLREDUCE": "1"}, "resources": {"gres": "dcu:4", "cpus_per_task": "8", "tasks": "32", "ntasks_per_code": null, "gpus": "4", "gpus_per_node": "4", "cores_per_socket": null, "gpus_per_task": "1", "exclusive": "True", "cpus_per_gpu": "8", "gpu_type": "dcu", "time": null, "ntasks_per_node": "4", "nodes": "8", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 4\n#SBATCH -J pre_scrach\n#SBATCH -o pre_cscd_r_128_from_scrach.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file /public/home/zzx6320/lh/Projects/bert/data/cscibert_pre_training/pre_training_R_cscd_128.tfrecord\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --output_dir output/Pre1_cscd_R_128_64_from_scrach\\\n --max_seq_length 128\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 64\\\n --learning_rate 2e-5\\\n --num_train_steps 500000\\\n --save_checkpoints_steps 1000\\"}, {"role": "assistant", "content": {"application": "tensorflow", "software": ["mpirun", "python", "horovod", "miopen"], "modules": [], "environment_variables": {"MIOPEN_USER_DB_PATH": "/tmp/tensorflow-miopen-${USER}-2.8", "MIOPEN_DEBUG_DISABLE_FIND_DB": "1", "HOROVOD_HIERARCHICAL_ALLREDUCE": "1"}, "resources": {"gres": "dcu:4", "cpus_per_task": "8", "tasks": "16", "ntasks_per_code": "4", "gpus": "4", "gpus_per_node": "4", "cores_per_socket": null, "gpus_per_task": "1", "exclusive": null, "cpus_per_gpu": "2", "gpu_type": null, "time": null, "ntasks_per_node": "4", "nodes": "4", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 4\n#SBATCH -J pre_7\n#SBATCH --exclusive\n#SBATCH -o Sbatch7.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_O_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_S_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TF_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TK_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TP_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TV_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_P_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TB_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TG_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TL_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TQ_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_U_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_Q_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TD_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TH_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TM_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TS_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_V_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_R_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TE_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TJ_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TN_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_TU_cscd_128_wwm_cmesh.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all_wwm/pre_training_X_cscd_128_wwm_cmesh.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre7_cscd_all_128_64_from_scratch\\\n --max_seq_length 128\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 64\\\n --learning_rate 2e-5\\\n --num_train_steps 3000000\\\n --save_checkpoints_steps 1000\\"}, {"role": "assistant", "content": {"application": "tensorflow", "software": ["mpirun", "python", "horovod", "tensorflow", "miopen"], "modules": [], "environment_variables": {"MIOPEN_USER_DB_PATH": "/tmp/tensorflow-miopen-${USER}-2.8", "MIOPEN_DEBUG_DISABLE_FIND_DB": "1", "HOROVOD_HIERARCHICAL_ALLREDUCE": "1"}, "resources": {"gres": "dcu:4", "cpus_per_task": "8", "tasks": "32", "ntasks_per_code": null, "gpus": null, "gpus_per_node": "4", "cores_per_socket": null, "gpus_per_task": null, "exclusive": true, "cpus_per_gpu": null, "gpu_type": "dcu", "time": null, "ntasks_per_node": "4", "nodes": "4", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 4\n#SBATCH -J pre_6\n#SBATCH --exclusive\n#SBATCH -o Sbatch6.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_O_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_S_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TF_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TK_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TP_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TV_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_P_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TB_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TG_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TL_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TQ_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_U_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_Q_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TD_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TH_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TM_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TS_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_V_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_R_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TE_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TJ_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TN_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_TU_cscd_128.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_all/pre_training_X_cscd_128.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --init_checkpoint /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_model.ckpt \\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre6_cscd_all_128_64_from_bert\\\n --max_seq_length 128\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 64\\\n --learning_rate 2e-5\\\n --num_train_steps 3000000\\\n --save_checkpoints_steps 1000\\"}, {"role": "assistant", "content": {"application": "tensorflow", "software": ["mpirun", "python", "horovod", "miOpen"], "modules": [], "environment_variables": {"MIOPEN_USER_DB_PATH": "/tmp/tensorflow-miopen-${USER}-2.8", "MIOPEN_DEBUG_DISABLE_FIND_DB": "1", "HOROVOD_HIERARCHICAL_ALLREDUCE": "1"}, "resources": {"gres": "dcu:4", "cpus_per_task": "8", "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": true, "cpus_per_gpu": null, "gpu_type": null, "time": null, "ntasks_per_node": "4", "nodes": "4", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash \n#SBATCH -t 48:30:00\n#SBATCH -N 1\n#SBATCH -p gpu_titanrtx\n# Loading modules\nmodule purge #Unload all loaded modules\nmodule load 2019\nmodule load TensorFlow\n\necho Running on Lisa System\n\n#Copy input file to scratch\n#cp $HOME/$NAME \"$TMPDIR\"\n\n# Execute a python program \npython3 $HOME/main.py\n"}, {"role": "assistant", "content": {"application": "python", "software": ["TensorFlow"], "modules": ["2019", "TensorFlow"], "environment_variables": {}, "resources": {"gres": null, "cpus_per_task": null, "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": null, "cpus_per_gpu": null, "gpu_type": "titanrtx", "time": "48:30:00", "ntasks_per_node": null, "nodes": "1", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {"TensorFlow": null}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p park\n#SBATCH -A park_contrib\n#SBATCH -t 0-12:00\n#SBATCH -n 1\n#SBATCH -N 1\n#SBATCH --mem=12G\n#SBATCH -o %j.generate_lesion_sequence.txt #stdout file\n#SBATCH -e %j.generate_lesion_sequence.txt #stderr file\n\nmodule load \\\nbedtools/2.27.1 \\\nsamtools/1.9 \\\npython/3.6.0\n\nintervals=$1\nconfig=$2\njobtask=$3\ngene=$4\n\n# get relevant entries from config\ngenegtf=$(grep -v \"#\" $config | grep -s \"genegtf\" | cut -f2)\nexongtf=$(grep -v \"#\" $config | grep -s \"exongtf\" | cut -f2)\ngenomefa=$(grep -v \"#\" $config | grep -s \"fasta\" | cut -f2)\ngenomefile=$(grep -v \"#\" $config | grep -s \"genomefile\" | cut -f2)\n# get the coordinate system\ncoordsys=$(grep -v \"#\" $config | grep -s \"coord_sys\" | cut -f2)\nneoaIdistlimit=$(grep -v \"#\" $config | grep -s \"mhcI_neoa_dist_limit\" | cut -f2)\n# neoaIIdistlimit=$(grep -v \"#\" $config | grep -s \"mhcI_neoa_dist_limit\" | cut -f2)\n\necho $intervals\n\n# we want to list out the sequences that the lesion represents\n# then, we wish to find the exons closest the lesions, get the sequence within some limit of their distance, and tile them\n\n# clear files\necho -e \"#\" > $jobtask.$gene.fa\necho -e \"#\" > $jobtask.$gene.bed\necho -e \"#\" > $jobtask.$gene.lesion.bed\necho -e \"#\" > $jobtask.$gene.lesion_control_seq.bed.temp\n\n# go line by line\nwhile read line; do\n    echo $line\n    # first, figure out the rule\n    seqtype=$(echo $line | tr ' ' '\\t' | cut -f6)\n    echo $seqtype\n    nameseq=$(echo $line | tr ' ' '\\t' | cut -f4)\n    # lesiontype\n    lesiontype=$(echo $line | tr ' ' '\\t' | cut -f5)\n    # match the rule\n    ruletype=$(grep -v \"#\" $config | grep -s $seqtype | cut -f2)\n    # current line\n    echo $line | tr ' ' '\\t' > .temp.line.bed\n    # now, determine the next course of action. Only act of the sequence is to keep, swap, or reverse\n    # if remove, then we do not return a sequence\n    if [[ $ruletype == \"keep\" ]]; then\n        # echo $line | tr ' ' '\\t' > .temp.line.bed\n        bedtools getfasta -name -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.fa\n        bedtools getfasta -name -bedOut -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.bed\n    elif [[ $ruletype = \"copy\" ]]; then\n        # will fix this later for duplications\n        # echo -e $line > .temp.line.bed\n        bedtools getfasta -name -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.fa\n        bedtools getfasta -name -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.fa\n        # store the line\n        bedtools getfasta -name -bedOut -s -fi $genomefa -bed .temp.line.bed > .temp.lesion.bed\n        cat .temp.lesion.bed >> $jobtask.$gene.bed\n        cat .temp.lesion.bed >> $jobtask.$gene.bed # no more than 2 copies\n        # bedtools getfasta -name -bedOut -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.bed\n        # bedtools getfasta -name -s -fi $genomefa -bed .temp.line.bed >> $jobtask.$gene.fa # make no more than two copies\n    elif [[ $ruletype == \"swap\" ]]; then\n            # get reference allele\n        ref=$(echo $line | tr ' ' '\\t' | cut -f7)\n        # get the allele that we need to substitute\n        alt=$(echo $line | tr ' ' '\\t' | cut -f8-9)\n        for i in $alt; do\n            if [[ $i != $ref ]]; then\n                # print out the allele\n                seqname=$(cut -f1-3 .temp.line.bed | sed \"s/\\t/_/g\")\n                # seqname=\">allele_\"$nameseq\n                echo -e \">$seqname(MUT_$nameseq)\" >> $jobtask.$gene.fa\n                echo -e $i >> $jobtask.$gene.fa\n                # echo -e \">$seqname(MUT_$nameseq)\" >> .lesion.$gene.fa\n                # echo -e $i >> $jobtask.$gene.fa >> .lesion.$gene.fa\n                echo -e \"$line $i\" | tr ' ' '\\t' >> $jobtask.$gene.lesion.bed # store the lesion\n                cat $jobtask.$gene.lesion.bed >> $jobtask.$gene.bed\n            fi\n        # generate the control sequence so that we can identify \"WT\" peptides in the frames and filter them out\n        # if ref is \"-\", then write a space\n        if [[ $ref == \"-\" ]]; then\n            echo -e \"$line Z\" | tr ' ' '\\t' >> $jobtask.$gene.lesion_control_seq.bed.temp\n        else\n            echo -e \"$line $ref\" | tr ' ' '\\t' >> $jobtask.$gene.lesion_control_seq.bed.temp\n        fi\n        # \n        done\n    elif [[ $ruletype == \"remove\" ]]; then\n        # in the case of remove\n        seqname=$(cut -f1-3 .temp.line.bed | sed \"s/\\t/_/g\")\n        echo -e \">$seqname(MUT_$nameseq)\" >> $jobtask.$gene.fa\n        echo -e \"\" >> $jobtask.$gene.fa\n        echo -e \"$line Z\" | tr ' ' '\\t' > $jobtask.$gene.lesion.bed # store the lesion\n        cat $jobtask.$gene.lesion.bed >> $jobtask.$gene.bed\n        # generate the control sequence for identifying WT peptides\n        ref=$(echo $line | tr ' ' '\\t' | cut -f7)\n        echo -e \"$line $ref\" | tr ' ' '\\t' >> $jobtask.$gene.lesion_control_seq.bed.temp\n        # \n    # dont worry about reversal for now\n    fi    \ndone < $intervals\n\n# adjust the lesion_control_seq so that they all read \"WT\"\nawk 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$3,$4,$5,\"WT\",$7,$8,$9,$10}' $jobtask.$gene.lesion_control_seq.bed.temp > $jobtask.$gene.lesion_control_seq.bed\n\n# go lesion by lesion\nwhile read lesion; do\n    echo -e $lesion | tr ' ' '\\t' > .temp.lesion_line.bed\n    # lesion name\n    lesioname=$(cut -f1-3 .temp.lesion_line.bed | sed \"s/\\t/_/g\")\n    bedtools closest -D \"ref\" -fu -a .temp.lesion_line.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_upstream_exons.bed\n    bedtools closest -D \"ref\" -fd -a .temp.lesion_line.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_downstream_exons.bed\n    \n    # obtain the sequences representing where mhcI neoa's may arise\n    # do 8-12 mers\n    \n    cat <(awk -v k=$neoaIdistlimit -v lname=$lesioname 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3,lname,$5,$6,$7,$8,$9}' .temp.closest_upstream_exons.bed ) \\\n                   <(awk -v k=$neoaIdistlimit -v lname=$lesioname 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k,lname,$5,$6,$7,$8,$9}' .temp.closest_downstream_exons.bed) | \\\n                   sort -k1,1 -k2,2 | uniq | \\\n                   bedtools getfasta -name -bedOut -s -fi $genomefa -bed - > .mhcIneoa.template.temp #$jobtask.$gene.mhcIneoa.template.bed\n    # cat the lesion bed and the template\n    cat .temp.lesion_line.bed .mhcIneoa.template.temp | sort -k1,1 -k2,2n > $jobtask.$gene.seq_around_lesion.$lesioname.bed\n    \n    # convert the full sequence into a fasta\n    echo -e \">$lesioname\" > $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    outseq=\"\"\n    for i in $(cut -f10 $jobtask.$gene.seq_around_lesion.$lesioname.bed); do\n        outseq=$outseq\"\"$i\n    done\n    echo -e $outseq >> $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    \n    # after printing out the sequence remove the \"Z\" placeholder if a deletion exists in the mutant\n    sed -i \"s/Z//g\" $jobtask.$gene.seq_around_lesion.$lesioname.fa # > $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    \n    # cut -f10 $jobtask.$gene.seq_around_lesion.$lesioname.bed | tr '\\n' '' >> $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    #paste <(cut -f4 $jobtask.$gene.seq_around_lesion.$lesioname.bed | sed \"s/^/>/g\") \\\n    #<(cut -f10 $jobtask.$gene.seq_around_lesion.$lesioname.bed) | \\\n    #sed \"s/\\t/\\n/g\" > $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    \n    # generate peptides\n    python /n/data1/hms/dbmi/park/vinay/pipelines/mutagenesis/tile_peptides_from_sequence_dev.py $jobtask.$gene.seq_around_lesion.$lesioname.fa\n    cat $jobtask.$gene.seq_around_lesion.$lesioname.fa_peptides_*aa.txt > $jobtask.$gene.seq_around_lesion.$lesioname.proposed_neoantigens.txt\n    mv $jobtask.$gene.seq_around_lesion.$lesioname.fa_peptides_*aa.txt peptide_sequences/\n    \ndone < <(grep -v \"#\" $jobtask.$gene.lesion.bed)\n\n\n# repeat for control sequences\nwhile read lesion; do\n    echo -e $lesion | tr ' ' '\\t' > .temp.lesion_line.bed\n    # lesion name\n    lesioname=$(cut -f1-3 .temp.lesion_line.bed | sed \"s/\\t/_/g\")\n    bedtools closest -D \"ref\" -fu -a .temp.lesion_line.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_upstream_exons.bed\n    bedtools closest -D \"ref\" -fd -a .temp.lesion_line.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_downstream_exons.bed\n    \n    # obtain the sequences representing where mhcI neoa's may arise\n    # do 8-12 mers\n    \n    cat <(awk -v k=$neoaIdistlimit -v lname=$lesioname 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3,lname,$5,$6,$7,$8,$9}' .temp.closest_upstream_exons.bed ) \\\n                   <(awk -v k=$neoaIdistlimit -v lname=$lesioname 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k,lname,$5,$6,$7,$8,$9}' .temp.closest_downstream_exons.bed) | \\\n                   sort -k1,1 -k2,2 | uniq | \\\n                   bedtools getfasta -name -bedOut -s -fi $genomefa -bed - > .mhcIneoa.template.temp #$jobtask.$gene.mhcIneoa.template.bed\n    # cat the lesion bed and the template\n    cat .temp.lesion_line.bed .mhcIneoa.template.temp | sort -k1,1 -k2,2n > $jobtask.$gene.seq_around_lesion_control.$lesioname.bed\n    \n    # convert the full sequence into a fasta\n    echo -e \">$lesioname\" > $jobtask.$gene.seq_around_lesion_control.$lesioname.fa\n    \n    # convert the full sequence into a fasta\n    outseq=\"\"\n    for i in $(cut -f10 $jobtask.$gene.seq_around_lesion_control.$lesioname.bed); do\n        outseq=$outseq\"\"$i\n    done\n    echo -e $outseq >> $jobtask.$gene.seq_around_lesion_control.$lesioname.fa\n    \n    # after printing out the sequence remove the \"Z\" placeholder if an insertion exists in the mutant\n    sed -i \"s/Z//g\" $jobtask.$gene.seq_around_lesion_control.$lesioname.fa\n    \n    # generate peptides\n    python /n/data1/hms/dbmi/park/vinay/pipelines/mutagenesis/tile_peptides_from_sequence_dev.py $jobtask.$gene.seq_around_lesion_control.$lesioname.fa\n    cat $jobtask.$gene.seq_around_lesion_control.$lesioname.fa_peptides_*aa.txt > $jobtask.$gene.seq_around_lesion_control.$lesioname.proposed_neoantigens.txt\n    mv $jobtask.$gene.seq_around_lesion_control.$lesioname.fa_peptides_*aa.txt peptide_sequences/\n    \ndone < <(grep -v \"#\" $jobtask.$gene.lesion_control_seq.bed)\n\n# get diffs\ndiff $jobtask.$gene.seq_around_lesion_control.$lesioname.proposed_neoantigens.txt $jobtask.$gene.seq_around_lesion.$lesioname.proposed_neoantigens.txt > .temp.diff_neoas\ngrep -s \">\" .temp.diff_neoas | sed \"s/> //g\" > $jobtask.$gene.seq_around_lesion.$lesioname.unique_neoas_mutant.txt\ngrep -s \"<\" .temp.diff_neoas | sed \"s/< //g\" > $jobtask.$gene.seq_around_lesion.$lesioname.lost_neoas_mutant.txt\n\necho -e \"$jobtask\\t$gene\\t$PWD/$jobtask.$gene.fa\\t$jobtask.$gene.bed\\t$jobtask.$gene.lesion.bed\\t$jobtask.$gene.seq_around_lesion.$lesioname.bed\\t$jobtask.$gene.seq_around_lesion.$lesioname.fa\\t$jobtask.$gene.seq_around_lesion.$lesioname.unique_neoas_mutant.txt\\t$jobtask.$gene.seq_around_lesion.$lesioname.lost_neoas_mutant.txt\" >> jobtask_gene_fasta.txt\n\na=$(grep -v -c \"\\*\" $jobtask.$gene.seq_around_lesion.$lesioname.unique_neoas_mutant.txt)\necho -e \"$a mutant-specific neoantigens predicted for $gene\"\na=$(grep -c \"^\" $jobtask.$gene.seq_around_lesion.$lesioname.lost_neoas_mutant.txt)\necho -e \"$a WT-specific peptides lost in mutant and predicted for $gene\"\n\n\n# add an option\n\n## find the WT sequences closest to the lesion\n#bedtools closest -D \"ref\" -fu -a $jobtask.$gene.lesion.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_upstream_exons.bed\n#bedtools closest -D \"ref\" -fd -a $jobtask.$gene.lesion.bed -b <(grep -P \"\\tWT\\t\" $intervals) | cut -f11- > .temp.closest_downstream_exons.bed\n#\n## obtain the sequences representing where mhcI neoa's may arise\n#cat <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3,$4,$5,$6,$7,$8,$9}' .temp.closest_upstream_exons.bed ) \\\n#               <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k,$4,$5,$6,$7,$8,$9}' .temp.closest_downstream_exons.bed) | \\\n#               sort -k1,1 -k2,2 | uniq | \\\n#               bedtools getfasta -name -bedOut -s -fi $genomefa -bed - > .mhcIneoa.template.temp #$jobtask.$gene.mhcIneoa.template.bed\n## cat the lesion bed and the template\n#cat $jobtask.$gene.lesion.bed .mhcIneoa.template.temp | sort -k1,1 -k2,2n > $jobtask.$gene.seq_around_lesion.bed \n#\n## bedtools getfasta -name -s -fi $genomefa -bed <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3}' .temp.closest_upstream_exons.bed) > .mhcIneoa.template.temp\n## bedtools getfasta -name -s -fi $genomefa -bed <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k}' .temp.closest_downstream_exons.bed) >> .mhcIneoa.template.temp\n#\n#\n#\n#\n\n#cat lesion_test.bed <(cat <(bedtools closest -D \"ref\" -fu -a lesion_test.bed -b .temp.lesion_gene.bed) <(bedtools closest -D \"ref\" -fd -a lesion_test.bed -b .temp.lesion_gene.bed) | cut -f10-) | sort -k1,1 -k2,2n\n#\n#\n#\n#echo -e \"$jobtask\\t$gene\\t$PWD/$jobtask.$gene.fa\\t$jobtask.$gene.bed\\t$jobtask.$gene.mhcIneoa.template.bed\\t$jobtask.$gene.mhcIneoa.template.fa\" >> jobtask_gene_fasta.txt\n#\n## for brevity, we will just isolate the sequences immediately before and after the mutations\n#\n#    # to simplify interval computations, we get the features nearest the bases and pull distlimit bases from their ends\n#bedtools closest -D \"ref\" -fu -a $jobtask.$gene.lesion.bed -b $intervals | cut -f10- > .temp.closest_upstream_exons.bed\n#bedtools closest -D \"ref\" -fd -a $jobtask.$gene.lesion.bed -b $intervals | cut -f10- > .temp.closest_downstream_exons.bed\n#    # cat $jobtask.$gene.lesion.bed .temp.closest_upstream_exons.bed .temp.closest_downstream_exons.bed | sort -k1,1 -k2,2n > .temp.lesion_closest_exons.bed\n#    cat <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3}' .temp.closest_upstream_exons.bed ) \\\n#                   <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k}' .temp.closest_downstream_exons.bed) | \\\n#                   sort -k1,1 -k2,2 | uniq > $jobtask.$gene.mhcIneoa.template.bed\n#    \n#    # get upstream sequence\n#    bedtools getfasta -name -s -fi $genomefa -bed <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3}' .temp.closest_upstream_exons.bed) > .mhcIneoa.template.temp\n#    bedtools getfasta -name -s -fi $genomefa -bed <(awk -v k=$neoaIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k}' .temp.closest_downstream_exons.bed) >> .mhcIneoa.template.temp\n#    # append .mhcIneoa.template.temp to $jobtask.$gene.lesion.bed\n#    cat .mhcIneoa.template.temp \n#    \n#    # cat .mhcIneoa.template.upstream.temp $jobtask.$gene.fa \n#    \n#    bedtools getfasta -name -s -fi $genomefa -bed $jobtask.$gene.mhcIneoa.template.bed >> $jobtask.$gene.mhcIneoa.template.fa\n#    # cat <(awk -v k=$neoaIIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$3-k,$3}') <(awk -v k=$neoaIIdistlimit 'BEGIN {FS=OFS=\"\\t\"} {print $1,$2,$2+k}') | sort -k1,1 -k2,2 | uniq > $jobtask.$gene.mhcIIneoa.template.bed\n#    \n#    # cat <(bedtools closest -D \"ref\" -fu -a lesion_test.bed -b .temp.lesion_gene.bed) <(bedtools closest -D \"ref\" -fd -a lesion_test.bed -b .temp.lesion_gene.bed) | cut -f10- | sort -k1,1 -k2,2n > .temp.closest_exons.bed\n#    \n#    # bedtools slop -b 36 -g $genomefile -i lesion_test.bed | bedtools intersect -a .temp.lesion_gene.bed -b -\n#\n"}, {"role": "assistant", "content": {"application": "bedtools", "software": ["bedtools", "samtools", "python"], "modules": ["bedtools/2.27.1", "samtools/1.9", "python/3.6.0"], "environment_variables": {"intervals": "", "config": "", "jobtask": "", "gene": "", "genegtf": "", "exongtf": "", "genomefa": "", "genomefile": "", "coordsys": "", "neoaIdistlimit": "", "neoaIIdistlimit": ""}, "resources": {"gres": "", "cpus_per_task": "1", "tasks": "1", "ntasks_per_code": "1", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "0-12:00", "ntasks_per_node": "1", "nodes": "1", "memory": "12G", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {"bedtools": "2.27.1", "samtools": "1.9", "python": "3.6.0"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -p priopark\n#SBATCH -A park_contrib\n#SBATCH -t 120:00:00\n#SBATCH --mem=32G\n\nword=$1\nshift\n\n# Always require slurm-drmaa. The SCAN2 commands implicitly require it.\nmodule load slurm-drmaa\n\n# Ensure sentieon is set up\nwhich sentieon\nif [ \"x$?\" == \"x1\" ]; then\n    echo \"sentieon is not on your \\$PATH and might not be properly enabled. be sure to set the\"\n    echo \"following environment variables:\"\n    echo \"export SENTIEON_LICENSE=address_of_license_server:portnumber\"\n    echo \"export SENTIEON_INSTALL_DIR=/path/to/sentieon_toplevel\"\n    echo \"export PATH=\\$PATH:/path/to/sentieon_toplevel/bin\"\n    exit 1\nfi\n\n# $flags is always built added to, never taken from\nflags='-s=snakemake/Snakefile --dir=. --latency-wait=60 --resources localjob=1 roadmap_download=10 encode_download=10 ucsc_download=10 --rerun-incomplete'\n        #--restart-times 2 \\  # This is NECESSARY for some jobs that have step-up memory reqs\njobflag='-j=10'\nkgflag=''\ndrmaaflag=''\nusedrmaa='false'\n\nif [ \"x$word\" == 'xdry' ]; then\n    flags=\"$flags $@ --dryrun --quiet\"\nelif [ \"x$word\" == 'xdryreason' ]; then\n    flags=\"$flags $@ --dryrun --reason\"\nelif [ \"x$word\" == 'xunlock' ]; then\n    flags=\"$flags --unlock\"\nelif [ \"x$word\" == 'xmake_pcawg_metadata' ]; then\n    flags=\"$flags --config make_pcawg_metadata=1 --until metadata/pcawg_metadata.csv\"\nelif [ \"x$word\" == 'xtest' ]; then\n    flags=\"$flags $@\"\n    jobflag='-j=1'\n    kgflag=''\nelif [ \"x$word\" == 'xlocal' ]; then\n    flags=\"$flags $@\"\n    jobflag='-j=6' #20'\n    kgflag='--keep-going'\nelif [ \"x$word\" == \"xcluster\" ]; then\n    #echo \"be sure to run: module load slurm-drmaa\"\n\n    mkdir -p cluster-logs\n    usedrmaa='true'\n    jobflag='-j=1000'\n    kgflag='--keep-going'\n    flags=\"$flags $@ --max-status-checks-per-second=0.5\" # --restart-times=2\"  # this is handled earlier\n    #flags=\"--max-jobs-per-second 0.05 --max-status-checks-per-second 0.1 --restart-times 2\"\nelse\n    echo \"usage: $0 {dry,unlock,make_pcawg_metadata,test,local,cluster} [optional snakemake arguments]\"\n    exit 1\nfi\n\n\n# I can't get $drmaaflags to substitute properly because of the internal 's\nif [ $usedrmaa == \"true\" ]; then\n    snakemake $flags $kgflag \\\n        $jobflag \\\n        --slurm --default-resources slurm_account=park_contrib slurm_partition=priopark runtime=2880\n        #--drmaa=' -p priopark -A park_contrib --mem={resources.mem_mb} -c {threads} -t 4:00:00 -o cluster-logs/slurm-%A.log'\n        #--max-threads=12 $jobflag \\\nelse\n    echo \"snakemake $flags $kgflag --max-threads=12 $jobflag\"\n    snakemake $flags $kgflag --max-threads=12 $jobflag\nfi\n"}, {"role": "assistant", "content": {"application": "snakemake", "software": ["sentieon", "slurm-drmaa", "snakemake"], "modules": ["slurm-drmaa"], "environment_variables": {"SENTIEON_LICENSE": "address_of_license_server:portnumber", "SENTIEON_INSTALL_DIR": "/path/to/sentieon_toplevel", "PATH": "/path/to/sentieon_toplevel/bin"}, "resources": {"gres": "", "cpus_per_task": "", "tasks": "", "ntasks_per_code": "", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "120:00:00", "ntasks_per_node": "", "nodes": "", "memory": "32G", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -n 8\n#SBATCH -t 0-12:00                         # Runtime of 5 minutes, in D-HH:MM format\n#SBATCH -p park                           # Run in short partition\n#SBATCH -A park_contrib\n#SBATCH -o slurm_%j.out                 # File to which STDOUT + STDERR will be written, including job ID in filename\n#SBATCH --mail-type=FAIL                    # ALL email notification type\n#SBATCH --mem=16G\n\nmodule load gcc  conda2/4.2.13 bedtools gatk python/3.7.4 R/4.0.1\nmodule load perl/5.30.0\nmodule load samtools\n\nfilepath=$1\nstem=$2\necho $filepath\necho $stem\n\nmkdir readpos/$stem/\nmkdir temp/$stem/\nmkdir bins/$stem/\nconfig=cfg/$stem.cfg\ntemp=temp/$stem.tmp\n\n\necho \"start of get_readpos\"\nfor i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X; do\n    echo $i\n    samtools view -q 30  -F 1284 $filepath $i | perl -ane 'print $F[3], \"\\n\";' > readpos/$stem/${i}.readpos.seq &\ndone\nwait\necho \"end of get_readpos\"\n\necho \"start of bicseq-norm\"\n/n/data1/hms/dbmi/park/yifan/tools/NBICseq-norm_v0.2.4/NBICseq-norm.pl  -b=500000  --gc_bin  -p=0.0002   $config $temp\necho \"end of bicseq-norm\"\n\n"}, {"role": "assistant", "content": {"application": "SLURM", "software": ["samtools", "bedtools", "gatk", "perl", "NBICseq-norm", "python", "R"], "modules": ["gcc", "conda2/4.2.13", "bedtools", "gatk", "python/3.7.4", "R/4.0.1", "perl/5.30.0", "samtools"], "environment_variables": {"filepath": "$1", "stem": "$2", "config": "cfg/$stem.cfg", "temp": "temp/$stem.tmp"}, "resources": {"gres": "", "cpus_per_task": "8", "tasks": "", "ntasks_per_code": "", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "0-12:00", "ntasks_per_node": "", "nodes": "", "memory": "16G", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {"NBICseq-norm": "v0.2.4"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n\n#SBATCH -p priopark\n#SBATCH -A park_contrib\n#SBATCH -t 120:00:00\n#SBATCH --mem 4000\n\n/n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/bin/scansnv \\\n    --ref /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/human_g1k_v37_decoy.fasta \\\n    --dbsnp /home/ljl11/balance/resources/dbsnp_147_b37_common_all_20160601.vcf \\\n    --snakefile /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/snakemake/Snakefile \\\n    --scripts /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/scripts \\\n    --shapeit-panel /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/1000GP_Phase3 \\\n    --bam 5823-tempmusc-1b1_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823-tempmusc-1b1_20170221-WGS-final-all.bam \\\n    --bulk-sample 5823-tempmusc-1b1_20170221-WGS \\\n    --bam 5823_20160810-dg-1cp2E1_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160810-dg-1cp2E1_20170221-WGS-final-all.bam \\\n    --bam 5823_20160810-dg-1cp3D11_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160810-dg-1cp3D11_20170221-WGS-final-all.bam \\\n    --bam 5823_20160810-dg-1cp3H1_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160810-dg-1cp3H1_20170221-WGS-final-all.bam \\\n    --bam 5823_20160824-pfc-1cp1F11_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160824-pfc-1cp1F11_20170221-WGS-final-all.bam \\\n    --sc-sample 5823_20160824-pfc-1cp1F11_20170221-WGS \\\n    --bam 5823_20160824-pfc-1cp2E1_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160824-pfc-1cp2E1_20170221-WGS-final-all.bam \\\n    --sc-sample 5823_20160824-pfc-1cp2E1_20170221-WGS \\\n    --bam 5823_20160824-pfc-1cp2G5_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/5823_20160824-pfc-1cp2G5_20170221-WGS-final-all.bam \\\n    --sc-sample 5823_20160824-pfc-1cp2G5_20170221-WGS \\\n    --bam 5823PFC-A /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5823PFC-A.b37.bam \\\n    --sc-sample 5823PFC-A \\\n    --bam 5823PFC-B /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5823PFC-B.b37.bam \\\n    --sc-sample 5823PFC-B \\\n    --bam 5823PFC-C /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5823PFC-C.b37.bam \\\n    --sc-sample 5823PFC-C \\\n    --regions-file /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/scan-snv/regions.noX.txt \\\n    --output-dir scansnv_fdr01_noX \\\n    --abmodel-chunks 4 \\\n    --abmodel-samples-per-chunk 5000 \\\n    --target-fdr 0.01 \\\n    --joblimit 1000 \\\n    --drmaa ' -p park -A park_contrib --mem={resources.mem} -t 8:00:00 -o %logdir/slurm-%A.log' \\\n    --somatic-indel-pon /n/data1/hms/dbmi/park/jluquette/pta/panels/mda_pta_panel.partial_98pct.mmq60.indels.rda \\\n    --resume --somatic-indels #--snakemake-args ' --quiet --dryrun'\n    #--resume --snakemake-args ' --quiet --touch --until abmodel_fit'\n\n    #--resume --snakemake-args ' --until shapeit_gather --forcerun shapeit_prepare'\n    #--resume --snakemake-args ' --restart-times 1' #' --quiet --dryrun'\n"}, {"role": "assistant", "content": {"application": "scansnv", "software": ["scansnv", "snakemake", "shapeit"], "modules": [], "environment_variables": {}, "resources": {"gres": "", "cpus_per_task": "", "tasks": "", "ntasks_per_code": "", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "120:00:00", "ntasks_per_node": "", "nodes": "", "memory": "4000", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {}}}]}
