{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n\n#SBATCH -p priopark\n#SBATCH -A park_contrib\n#SBATCH -t 120:00:00\n#SBATCH --mem 4000\n\n/n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/bin/scansnv \\\n    --ref /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/human_g1k_v37_decoy.fasta \\\n    --dbsnp /home/ljl11/balance/resources/dbsnp_147_b37_common_all_20160601.vcf \\\n    --shapeit-panel /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/1000GP_Phase3 \\\n    --regions-file /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/scan-snv/regions.noX.txt \\\n    --snakefile /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/snakemake/Snakefile \\\n    --scripts /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/scripts \\\n    --bam 5657-bulk /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0717-hrt-1b1.bam \\\n    --bulk-sample 5657-bulk \\\n    --bam 5657-pfc1D2 /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0902-pfc-1cp1D2.bam \\\n    --sc-sample 5657-pfc1D2 \\\n    --bam 5657-pfc1E11 /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0902-pfc-1cp1E11.bam \\\n    --sc-sample 5657-pfc1E11 \\\n    --bam 5657-pfc2A6 /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0902-pfc-1cp2A6.bam \\\n    --sc-sample 5657-pfc2A6 \\\n    --bam 5657-pfc2F1 /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0902-pfc-1cp2F1.bam \\\n    --sc-sample 5657-pfc2F1 \\\n    --bam 5657-pfc2G9 /n/data1/bch/genetics/walsh-park/data/Hippocampus/Alignment/20151226_Macrogen/5657_0902-pfc-1cp2G9.bam \\\n    --sc-sample 5657-pfc2G9 \\\n    --bam 5657PFC-A /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5657PFC-A.b37.bam \\\n    --sc-sample 5657PFC-A \\\n    --bam 5657PFC-B /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5657PFC-B.b37.bam \\\n    --sc-sample 5657PFC-B \\\n    --bam 5657PFC-C /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/5657PFC-C.b37.bam \\\n    --sc-sample 5657PFC-C \\\n    --output-dir scansnv_fdr01_noX \\\n    --abmodel-chunks 4 \\\n    --abmodel-samples-per-chunk 5000 \\\n    --target-fdr 0.01 \\\n    --joblimit 1000 \\\n    --drmaa ' -p park -A park_contrib --mem={resources.mem} -t 8:00:00 -o %logdir/slurm-%A.log' \\\n    --somatic-indel-pon panel_52_pta_neurons_042521.partial_100pct.mmq60.indels.tab \\\n    --resume --somatic-indels\n"}, {"role": "assistant", "content": {"application": "scansnv", "software": ["scansnv", "snakemake", "drmaa"], "modules": [], "environment_variables": {}, "resources": {"gres": null, "cpus_per_task": null, "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": null, "cpus_per_gpu": null, "gpu_type": null, "time": "120:00:00", "ntasks_per_node": null, "nodes": null, "memory": "4000", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n\n#SBATCH -p priopark\n#SBATCH -A park_contrib\n#SBATCH -t 120:00:00\n#SBATCH --mem 4000\n\n\n/n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/bin/scansnv \\\n    --ref /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/human_g1k_v37_decoy.fasta \\\n    --dbsnp /home/ljl11/balance/resources/dbsnp_147_b37_common_all_20160601.vcf \\\n    --snakefile /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/snakemake/Snakefile \\\n    --scripts /n/data1/hms/dbmi/park/jluquette/pta/scan-snv2/scripts \\\n    --shapeit-panel /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/resources/1000GP_Phase3 \\\n    --regions-file /n/data1/hms/dbmi/park/jluquette/genotyper1/paper/scan-snv/regions.noX.txt \\\n    --bam 936-hrt-1b1_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/936-hrt-1b1_20170221-WGS-final-all.bam \\\n    --bulk-sample 936-hrt-1b1_20170221-WGS \\\n    --bam 936_20141001-pfc-1cp1G11_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/936_20141001-pfc-1cp1G11_20170221-WGS-final-all.bam \\\n    --sc-sample 936_20141001-pfc-1cp1G11_20170221-WGS \\\n    --bam 936_20141001-pfc-1cp1H9_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/936_20141001-pfc-1cp1H9_20170221-WGS-final-all.bam \\\n    --sc-sample 936_20141001-pfc-1cp1H9_20170221-WGS \\\n    --bam 936_20141001-pfc-1cp2F6_20170221-WGS /n/data1/bch/genetics/walsh-park/data/Aging/Alignment/20170420_Alignment/936_20141001-pfc-1cp2F6_20170221-WGS-final-all.bam \\\n    --sc-sample 936_20141001-pfc-1cp2F6_20170221-WGS \\\n    --bam 936PFC-A /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/936PFC-A.b37.bam \\\n    --sc-sample 936PFC-A \\\n    --bam 936PFC-B /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/936PFC-B.b37.bam \\\n    --sc-sample 936PFC-B \\\n    --bam 936PFC-C /n/data1/bch/genetics/walsh-park/PTA/NewData/.PreProcessing/936PFC-C.b37.bam \\\n    --sc-sample 936PFC-C \\\n    --output-dir scansnv_fdr01_noX \\\n    --abmodel-chunks 4 \\\n    --abmodel-samples-per-chunk 5000 \\\n    --target-fdr 0.01 \\\n    --add-chr-prefix \\\n    --joblimit 1000 \\\n    --drmaa ' -p park -A park_contrib --mem={resources.mem} -t 5:00:00 -o %logdir/slurm-%A.log' \\\n    --somatic-indels \\\n    --somatic-indel-pon panel_52_pta_neurons_042521.partial_100pct.mmq60.indels.tab \\\n    --resume\n"}, {"role": "assistant", "content": {"application": "scansnv", "software": ["scansnv", "snakemake", "shapeit"], "modules": [], "environment_variables": {}, "resources": {"gres": "", "cpus_per_task": null, "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": null, "cpus_per_gpu": null, "gpu_type": null, "time": "120:00:00", "ntasks_per_node": null, "nodes": null, "memory": "4000", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -c 8                               # Request 16 cores\n#SBATCH -t 1-00:00                        # Runtime in D-HH:MM format\n#SBATCH -A park\n#SBATCH -p medium                           # Partition to run in\n#SBATCH --mem=64G                         # Memory total in MB (for all cores)\n#SBATCH -o log/TCGA_%A_%a.out                 # File to which STDOUT will be written, including job ID (%j)\n#SBATCH -e log/TCGA_%A_%a.err                 # File to which STDERR will be written, including job ID (%j)\n#SBATCH --array=2-8                                        # You can change the filenames given with -o and -e to any filenames you'd like\n\n\nLNO=${SLURM_ARRAY_TASK_ID}\n\nSAMPLE_TABLE_FN=/home/dg204/park_dglodzik/TCGA/ATM_seq_since2022.jobs.tsv\nLNO=${SLURM_ARRAY_TASK_ID}\nNTH_LINE=$(cat ${SAMPLE_TABLE_FN} | head -${LNO} | tail -1)\n# the line should be: tumor ID, tumor bam, normal ID, normal bam, (37|38)\nCASE_ID=$(echo $NTH_LINE | awk -F\" \" '{ print $1}') \nTUMOR_UUID=$(echo $NTH_LINE | awk -F\" \" '{ print $3}') \nTUMOR_ID=$(echo $NTH_LINE | awk -F\" \" '{ print $7}') \nTUMOR_FILE_TCGA_ID=$(echo $NTH_LINE | awk -F\" \" '{ print $9}') \n\nTUMOR_BAM=$(echo $NTH_LINE | awk -F\" \" '{ print $5}') \nREFERENCE_UUID=$(echo $NTH_LINE | awk -F\" \" '{ print $2}') \nREFERENCE_BAM=$(echo $NTH_LINE | awk -F\" \" '{ print $4}') \nREFERENCE_ID=$(echo $NTH_LINE | awk -F\" \" '{ print $6}') \nREFERENCE_FILE_TCGA_ID=$(echo $NTH_LINE | awk -F\" \" '{ print $8}') \n\nGENOME_VERSION=\"38gdc\"\n\necho \"$TUMOR_ID $TUMOR_BAM $REFERENCE_ID $REFERENCE_BAM $GENOME_VERSION\" \n\nSCRATCH_FOLDER=/n/scratch/users/d/dg204/TCGAbams/\n\n# make a sample folder\nCASE_PATH=/n/data1/hms/dbmi/park/dglodzik/TCGA/ATM/${TUMOR_ID}/\nmkdir -p $CASE_PATH\nOUT_PATH=${CASE_PATH}/tnscope/\nmkdir -p $OUT_PATH\n\nREF_DIRECTORY=/n/data1/hms/dbmi/park/dglodzik/home_ref/hmf/\n\nif [ \"$GENOME_VERSION\" = \"38gdc\" ]\nthen\n    hmfHetPonLoci=${REF_DIRECTORY}/38/GermlineHetPon.38.vcf.gz\n    hmfGcProfile=${REF_DIRECTORY}/38/GC_profile.1000bp.38.cnp\n    # this one is different!\n    reference=/n/data1/hms/dbmi/park/dglodzik/TCGA/reference/GRCh38.d1.vd1.fa\n    hmfBreakendPon=${REF_DIRECTORY}/38/gridss_pon_single_breakend.38.bed\n    hmfBreakpointPon=${REF_DIRECTORY}/38/gridss_pon_breakpoint.38.bedpe\n    hmfBreakpointHotspot=${REF_DIRECTORY}/38/known_fusions.38.bedpe\n    linxGenomeVersion=38\n    hmfFragileSites=${REF_DIRECTORY}/38/fragile_sites_hmf.38.csv\n    hmfLineElements=${REF_DIRECTORY}/38/line_elements.38.csv\n    hmfKnownFusionData=${REF_DIRECTORY}/38/known_fusion_data.38.csv\n    path_to_ensembl_data_cache=${REF_DIRECTORY}/38/ensembl/\n    driverGenePanel_fn=${REF_DIRECTORY}/38/DriverGenePanel.38.tsv\n    somatic_hotspots_fn=${REF_DIRECTORY}/38/KnownHotspots.somatic.38.vcf\nfi\n\ncd $SCRATCH_FOLDER\n\n\nTUMOR_BAM_FP=\"$SCRATCH_FOLDER/$TUMOR_UUID/$TUMOR_BAM\"\nNORMAL_BAM_FP=\"$SCRATCH_FOLDER/$REFERENCE_UUID/$REFERENCE_BAM\"\n\n# download tumor\nif [ ! -f \"$TUMOR_BAM_FP\" ]; then\n    /n/data1/hms/dbmi/park/dglodzik/TCGA/gdc-client download -m  /n/data1/hms/dbmi/park/dglodzik/TCGA/ATM_seq_since2022.manifest.txt -t /home/dg204/projects/somagenome/data/external/GDCtokens/gdc-user-token.2024-02-23T00_15_03.846Z.txt \"$TUMOR_UUID\"\nfi\n\n# download normal\nif [ ! -f \"$NORMAL_BAM_FP\" ]; then\n    /n/data1/hms/dbmi/park/dglodzik/TCGA//gdc-client download -m  /n/data1/hms/dbmi/park/dglodzik/TCGA/ATM_seq_since2022.manifest.txt -t /home/dg204/projects/somagenome/data/external/GDCtokens/gdc-user-token.2024-02-23T00_15_03.846Z.txt \"$REFERENCE_UUID\"\nfi\n\n# run TNScope\nexport LD_LIBRARY_PATH=\"/n/data1/hms/dbmi/park/SOFTWARE/Sentieon/sentieon-genomics-202112.06/lib:$LD_LIBRARY_PATH\"\nexport SENTIEON_LICENSE=license.rc.hms.harvard.edu:8990\nexport SENTIEON_INSTALL_DIR=/n/data1/hms/dbmi/park/SOFTWARE/Sentieon/sentieon-genomics-202112.06\n\ndbsnp=/home/dg204/park_dglodzik/ref/CGAP/TNScope/known-sites-snp/known-sites-snp.vcf.gz\npon=/home/dg204/park_dglodzik/ref/CGAP/TNScope/panel_of_normals/panel_of_normal.vcf.gz\n\n# if the TNScope result does not exist\nif [ ! -f \"$OUT_PATH/output.vcf\" ]; then\n    cd $OUT_PATH\n    /home/dg204/repos/cgap-pipeline-somatic-sentieon/dockerfiles/somatic_sentieon/somatic_sentieon_tumor_normal.sh \\\n    \"$TUMOR_BAM_FP\" \\\n    \"$TUMOR_FILE_TCGA_ID\" \\\n    \"$NORMAL_BAM_FP\" \\\n    \"$REFERENCE_FILE_TCGA_ID\" \\\n    \"$reference\" \\\n    \"$dbsnp\" \\\n    \"$pon\"\nfi\n\n\n# separate the VCF file by mutation type\nSNV_VCF_FP=\"$OUT_PATH/${TUMOR_ID}_snv.vcf.gz\"\nif [ ! -f \"$SNV_VCF_FP\" ]; then\n    conda deactivate\n    export LD_LIBRARY_PATH=/n/app/python/3.8.12/lib\n    module load gcc/9.2.0 python/3.10.11\n    module load samtools/1.15.1\n    CGAP_SCRIPT_FOLDER=\"/home/dg204/repos/cgap-somatic-utils/scr/\"\n    source /home/dg204/jupytervenv3.10/bin/activate\n    $CGAP_SCRIPT_FOLDER/somatic_sentieon_vcf_splitter.py \\\n        -i \"$OUT_PATH/output.vcf\"  \\\n        -p \"$OUT_PATH/$TUMOR_ID\" \\\n        -o snv \\\n        -f\nfi\n\n# Hartwig\ncd /home/dg204/projects/somagenome/src\n\n/home/dg204/projects/somagenome/src/script_purple2_args.sh \\\n\"$TUMOR_ID\" \\\n\"$TUMOR_BAM_FP\" \\\n\"$REFERENCE_ID\" \\\n\"$NORMAL_BAM_FP\" \\\n\"$GENOME_VERSION\" \\\n\"\" \\\n\"${CASE_PATH}/hmf/\"\n\n\n"}, {"role": "assistant", "content": {"application": "slurm", "software": ["gdc-client", "samtools", "conda", "somatic_sentieon", "tnscope", "script_purple2_args.sh", "somatic_sentieon_vcf_splitter.py"], "modules": ["gcc/9.2.0", "python/3.10.11", "samtools/1.15.1"], "environment_variables": {"LD_LIBRARY_PATH": "/n/data1/hms/dbmi/park/SOFTWARE/Sentieon/sentieon-genomics-202112.06/lib:$LD_LIBRARY_PATH", "SENTIEON_LICENSE": "license.rc.hms.harvard.edu:8990", "SENTIEON_INSTALL_DIR": "/n/data1/hms/dbmi/park/SOFTWARE/Sentieon/sentieon-genomics-202112.06"}, "resources": {"gres": null, "cpus_per_task": "8", "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": null, "cpus_per_gpu": null, "gpu_type": null, "time": "1-00:00", "ntasks_per_node": null, "nodes": null, "memory": "64G", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {"samtools": "1.15.1", "python": "3.10.11", "gcc": "9.2.0"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH -c 8                               # Request 16 cores\n#SBATCH -t 5-00:00                         # Runtime in D-HH:MM format\n#SBATCH -p medium                           # Partition to run in\n#SBATCH --mem=48G                         # Memory total in MB (for all cores)\n#SBATCH -o log/gridss_%j.out                 # File to which STDOUT will be written, including job ID (%j)\n#SBATCH -e log/gridss_%j.err                 # File to which STDERR will be written, including job ID (%j)\n#SBATCH --array=2-2                                        # You can change the filenames given with -o and -e to any filenames you'd like\n\n\nGRIDSS_JAR_PATH=/usr/local/bin/gridss-2.13.2.jar\n\nTUMOR_ID='TCGA-HC-A6HX-01A-11D-A755-36'\nREFERENCE_ID='TCGA-HC-A6HX-10A-01D-A755-36'\nOUT_PATH=/n/data1/hms/dbmi/park/dglodzik/hmf_gridss_test/${TUMOR_ID}/\nGRIDSS_PATH=$OUT_PATH/gridss/\n\nTEMP_FOLDER=/n/scratch/users/d/dg204/temp/\n\nmkdir -p \"$OUT_PATH\"\nmkdir -p \"$GRIDSS_PATH\"\n\n\ngridssJvmHeap=44g\notherjvmheap=4g\n\ngridssOutput=\"$GRIDSS_PATH/$TUMOR_ID.gridss.sv.vcf\"\ngridssAssembly=$TEMP_FOLDER/$TUMOR_ID.bam\ngridssThreads=8\ngridssTmpDir=$TEMP_FOLDER\n\nreference=/n/data1/hms/dbmi/park/dglodzik/TCGA/reference/GRCh38.d1.vd1.fa\n\nTUMOR_BAM=/n/data1/hms/dbmi/park/dglodzik/TCGA/5555b571-6e03-4564-a0cf-05996b3f52c5/2f5d2e1e-110d-4058-bfe5-17d40b5f2583_wgs_gdc_realn.bam \nREFERENCE_BAM=/n/data1/hms/dbmi/park/dglodzik/TCGA/a550b72d-4290-4def-be69-ba40f36b71f9/7718ad9b-1ded-4d0c-abe8-3095b73e5cde_wgs_gdc_realn.bam\n\nsingularity exec -B /n/scratch,/n/data1 /n/app/singularity/containers/gridss_cgap.sif \\\ngridss \\\n-r ${reference} \\\n--jar  ${GRIDSS_JAR_PATH} \\\n--jvmheap ${gridssJvmHeap} \\\n--otherjvmheap ${otherjvmheap} \\\n--output ${gridssOutput} \\\n--assembly ${gridssAssembly} \\\n--threads ${gridssThreads} \\\n--workingdir ${gridssTmpDir} \\\n--labels ${TUMOR_ID},${REFERENCE_ID} \\\n$TUMOR_BAM \\\n$REFERENCE_BAM\n"}, {"role": "assistant", "content": {"application": "gridss", "software": ["gridss"], "modules": [], "environment_variables": {"GRIDSS_JAR_PATH": "/usr/local/bin/gridss-2.13.2.jar", "TUMOR_ID": "TCGA-HC-A6HX-01A-11D-A755-36", "REFERENCE_ID": "TCGA-HC-A6HX-10A-01D-A755-36", "OUT_PATH": "/n/data1/hms/dbmi/park/dglodzik/hmf_gridss_test/TCGA-HC-A6HX-01A-11D-A755-36/", "GRIDSS_PATH": "/n/data1/hms/dbmi/park/dglodzik/hmf_gridss_test/TCGA-HC-A6HX-01A-11D-A755-36/gridss/", "TEMP_FOLDER": "/n/scratch/users/d/dg204/temp/", "gridssJvmHeap": "44g", "otherjvmheap": "4g", "gridssOutput": "/n/data1/hms/dbmi/park/dglodzik/hmf_gridss_test/TCGA-HC-A6HX-01A-11D-A755-36/gridss/TCGA-HC-A6HX-01A-11D-A755-36.gridss.sv.vcf", "gridssAssembly": "/n/scratch/users/d/dg204/temp/TCGA-HC-A6HX-01A-11D-A755-36.bam", "gridssThreads": "8", "gridssTmpDir": "/n/scratch/users/d/dg204/temp/", "reference": "/n/data1/hms/dbmi/park/dglodzik/TCGA/reference/GRCh38.d1.vd1.fa", "TUMOR_BAM": "/n/data1/hms/dbmi/park/dglodzik/TCGA/5555b571-6e03-4564-a0cf-05996b3f52c5/2f5d2e1e-110d-4058-bfe5-17d40b5f2583_wgs_gdc_realn.bam", "REFERENCE_BAM": "/n/data1/hms/dbmi/park/dglodzik/TCGA/a550b72d-4290-4def-be69-ba40f36b71f9/7718ad9b-1ded-4d0c-abe8-3095b73e5cde_wgs_gdc_realn.bam"}, "resources": {"gres": "", "cpus_per_task": "8", "tasks": "1", "ntasks_per_code": "1", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "5-00:00", "ntasks_per_node": "", "nodes": "1", "memory": "48G", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH --job-name=distr\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=1000M\n#SBATCH\t--time=03:59:00\n#SBATCH --mail-type=begin\n#SBATCH --mail-type=end\n#SBATCH --mail-type=fail\n#SBATCH --output=logs/R-%x.%j.out\n#SBATCH --error=logs/R-%x.%j.err\n#SBATCH --mail-user=****\n#SBATCH --array=0-999\n\nmodule purge\nmodule load anaconda3/2021.5\n\npython main.py $SLURM_ARRAY_TASK_ID 2 100 2000\n"}, {"role": "assistant", "content": {"application": "python", "software": ["python", "main.py"], "modules": ["anaconda3/2021.5"], "environment_variables": {"SLURM_ARRAY_TASK_ID": "The current task ID in the array"}, "resources": {"gres": "", "cpus_per_task": "1", "tasks": "1000", "ntasks_per_code": "1", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "03:59:00", "ntasks_per_node": "1", "nodes": "1", "memory": "1000M", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "1000M", "gres_flags": ""}, "versions": {"anaconda3": "2021.5"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH --job-name=novel\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=300M\n#SBATCH\t--time=03:02:00\n#SBATCH --mail-type=begin\n#SBATCH --mail-type=end\n#SBATCH --mail-type=fail\n#SBATCH --output=logs/R-%x.%j.out\n#SBATCH --error=logs/R-%x.%j.err\n#SBATCH --mail-user=****\n#SBATCH --array=0-99\n\nmodule purge\nmodule load anaconda3/2021.5\n\npython main.py $SLURM_ARRAY_TASK_ID 0 100 2000\n"}, {"role": "assistant", "content": {"application": "slurm", "software": ["python"], "modules": ["anaconda3/2021.5"], "environment_variables": {"SLURM_ARRAY_TASK_ID": ""}, "resources": {"gres": "", "cpus_per_task": "1", "tasks": "100", "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": null, "cpus_per_gpu": null, "gpu_type": null, "time": "03:02:00", "ntasks_per_node": "1", "nodes": "1", "memory": "300M", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": "300M", "gres_flags": ""}, "versions": {"python": null, "anaconda3": "2021.5"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#SBATCH --partition=g80n140\n#SBATCH --job-name=testlongcontext\n#SBATCH --nodes 2\n#SBATCH --ntasks-per-node=8\n#SBATCH --cpus-per-task=12\n#SBATCH --output=gpt_neox_20.out\n#SBATCH --comment=laion\n#SBATCH --open-mode=append\n#SBATCH --exclusive\n\nmodule load openmpi\nmodule load cuda/11.7\n\nexport PYTHONFAULTHANDLER=1\nexport CUDA_LAUNCH_BLOCKING=0\nexport HOSTNAMES=`scontrol show hostnames \"$SLURM_JOB_NODELIST\"`\nexport MASTER_ADDR=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1)\nexport MASTER_PORT=12802\nexport COUNT_NODE=`scontrol show hostnames \"$SLURM_JOB_NODELIST\" | wc -l`\n\necho go $COUNT_NODE\necho $HOSTNAMES\n\nhostfile=\"hostfile.txt\"\nrm -f $hostfile\nfor node in $HOSTNAMES; do\n  echo $node slots=8 >> $hostfile\ndone\n\nsource /fsx/home-kaizhaol/long-context-transformers/venv/bin/activate\n\nHF_MODULES_CACHE=./cache/ HF_DATASETS_CACHE=./cache/ TRANSFORMERS_CACHE=./cache/ deepspeed --master_addr $MASTER_ADDR --hostfile='/fsx/home-kaizhaol/long-context-transformers/hostfile.txt' --launcher OpenMPI finetune.py --model_name_or_path=\"EleutherAI/gpt-neox-20b\" --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --output_dir gpt-neox-20b --gradient_accumulation_steps 8 --fp16 --evaluation_strategy \"epoch\" --max_steps 100000 --deepspeed ds_config.json --gradient_checkpointing\n"}, {"role": "assistant", "content": {"application": "deepspeed", "software": ["deepspeed", "openmpi", "cuda", "python", "transformers"], "modules": ["openmpi", "cuda/11.7"], "environment_variables": {"PYTHONFAULTHANDLER": "1", "CUDA_LAUNCH_BLOCKING": "0", "HOSTNAMES": "scontrol show hostnames \"$SLURM_JOB_NODELIST\"", "MASTER_ADDR": "scontrol show hostnames \"$SLURM_JOB_NODELIST\" | head -n 1", "MASTER_PORT": "12802", "COUNT_NODE": "scontrol show hostnames \"$SLURM_JOB_NODELIST\" | wc -l", "HF_MODULES_CACHE": "./cache/", "HF_DATASETS_CACHE": "./cache/", "TRANSFORMERS_CACHE": "./cache/"}, "resources": {"gres": null, "cpus_per_task": "12", "tasks": null, "ntasks_per_code": null, "gpus": null, "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": null, "exclusive": true, "cpus_per_gpu": null, "gpu_type": null, "time": null, "ntasks_per_node": "8", "nodes": "2", "memory": null, "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {"cuda": "11.7"}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n# normal cpu stuff: allocate cpus, memory\n#SBATCH --job-name=infer-pixelsum\n#SBATCH --ntasks=1 --cpus-per-task=48 --mem=70000M\n#SBATCH -p gpu --gres=gpu:a100:1\n#SBATCH --time=3:00:00\n\nnvidia-smi\n\nexport ENCODER=\"Team-PIXEL/pixel-base\"\nexport DECODER=\"gpt2\"\nexport DATASET=\"xsum\"\nexport EXPERIMENT_DIR=\"experiments/inference/$DECODER/\"`date +%Y-%m-%d_%H-%M-%S`\n\nmkdir -p ${EXPERIMENT_DIR}\n\npython3 -m scripts.training.run_inference \\\n                --model_path \"\" \\\n                --encoder_name ${ENCODER} \\\n                --decoder_name ${DECODER} \\\n                --processor_name ${ENCODER} \\\n                --tokenizer_name ${DECODER} \\\n                --fallback_fonts_dir \"fonts\" \\\n                --dataset_name ${DATASET} \\\n                --dataloader_num_workers 32 \\\n                --do_train false \\\n                --do_eval false \\\n                --do_predict true \\\n                --train_decoder false \\\n                --train_encoder false \\\n                --output_dir ${EXPERIMENT_DIR} \\\n                --log_predictions true \\\n                --eval_accumulation_steps 8 \\\n                --per_device_eval_batch_size 1 \\\n                --num_beams 1 \\\n                --max_predict_samples 1500 \\\n                --data_cache_dir 'cached_data' \\"}, {"role": "assistant", "content": {"application": "slurm", "software": ["python3", "nvidia-smi"], "modules": [], "environment_variables": {"ENCODER": "Team-PIXEL/pixel-base", "DECODER": "gpt2", "DATASET": "xsum", "EXPERIMENT_DIR": "experiments/inference/$DECODER/`date +%Y-%m-%d_%H-%M-%S`"}, "resources": {"gres": "gpu:a100:1", "cpus_per_task": "48", "tasks": "1", "ntasks_per_code": null, "gpus": "1", "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": "1", "exclusive": null, "cpus_per_gpu": null, "gpu_type": "a100", "time": "3:00:00", "ntasks_per_node": null, "nodes": null, "memory": "70000M", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n# normal cpu stuff: allocate cpus, memory\n#SBATCH --job-name=pretrain-pixel\n#SBATCH --ntasks=1 --cpus-per-task=48 --mem=70000M\n#SBATCH -p gpu --gres=gpu:a100:1\n#SBATCH --time=75:00:00\n\nnvidia-smi\n\nexport ENCODER=\"Team-PIXEL/pixel-base\"\nexport DECODER=\"gpt2-large\"\nexport DATASET=\"zuzannad1/pixelsum_wiki\"\nexport EXPERIMENT_DIR=\"experiments/pretraining/$DECODER/\"`date +%Y-%m-%d_%H-%M-%S`\n\nmkdir -p ${EXPERIMENT_DIR}\n\npython3 -m scripts.training.run_pretraining \\\n                   --encoder_name ${ENCODER} \\\n                   --decoder_name ${DECODER} \\\n                   --processor_name ${ENCODER} \\\n                   --tokenizer_name ${DECODER} \\\n                   --fallback_fonts_dir \"fonts\" \\\n                   --dataset_name ${DATASET} \\\n                   --remove_unused_columns false \\\n                   --dataloader_num_workers 32 \\\n                   --do_train true \\\n                   --do_eval true \\\n                   --do_predict true \\\n                   --train_decoder true \\\n                   --train_encoder true \\\n                   --evaluation_strategy \"steps\" \\\n                   --eval_steps 10000 \\\n                   --predict_with_generate true \\\n                   --logging_strategy \"steps\" \\\n                   --logging_steps 50 \\\n                   --save_strategy \"steps\" \\\n                   --save_steps 10000 \\\n                   --fp16 true \\\n                   --fp16_full_eval true \\\n                   --output_dir ${EXPERIMENT_DIR} \\\n                   --overwrite_output_dir false \\\n                   --log_predictions true \\\n                   --per_device_train_batch_size 16 \\\n                   --gradient_accumulation_steps 2 \\\n                   --learning_rate 1.5e-4 \\\n                   --weight_decay 0.05 \\\n                   --warmup_ratio 0.05 \\\n                   --lr_scheduler_type \"cosine\" \\\n                   --warmup_steps 15000 \\\n                   --max_steps 300000 \\\n                   --val_max_target_length 50 \\\n                   --max_target_length 50 \\\n                   --load_best_model_at_end true \\\n                   --use_fast_tokenizer true \\\n                   --num_beams 1 \\\n                   --report_to \"wandb\" \\\n                   --max_eval_samples 100 \\\n                   --data_cache_dir 'cached_data' \\\n                   "}, {"role": "assistant", "content": {"application": "slurm", "software": ["python3", "scripts.training.run_pretraining", "nvidia-smi"], "modules": [], "environment_variables": {"ENCODER": "Team-PIXEL/pixel-base", "DECODER": "gpt2-large", "DATASET": "zuzannad1/pixelsum_wiki", "EXPERIMENT_DIR": "experiments/pretraining/$DECODER/`date +%Y-%m-%d_%H-%M-%S`"}, "resources": {"gres": "gpu:a100:1", "cpus_per_task": "48", "tasks": "1", "ntasks_per_code": null, "gpus": "1", "gpus_per_node": null, "cores_per_socket": null, "gpus_per_task": "1", "exclusive": null, "cpus_per_gpu": null, "gpu_type": "a100", "time": "75:00:00", "ntasks_per_node": null, "nodes": null, "memory": "70000M", "sockets_per_node": null, "ntasks_per_socket": null, "mem_per_gpu": null, "mem_per_cpu": null, "gres_flags": null}, "versions": {}}}]}
{"messages": [{"role": "user", "content": "Can you tell me what application this script is running and put the answer as a single term on the first line, followed by more detail about the other software and resource requirements in the script? And can you give me an output format in raw json\n#!/bin/bash\n#PBS -l nodes=1:ppn=16\n#PBS -l vmem=50gb\n#PBS -l walltime=00:30:00\n\nset -xe\n\nBOLD=$(jq -r .bold config.json)\nEVENTS=$(jq -r '.events // \"\"' config.json)\nSTIM=$(jq -r .stim config.json)\n\nSUB=$(jq -r '._inputs[0].meta.subject' config.json)\nSES=$(jq -r '._inputs[0].meta.session // \"1\"' config.json)\n\necho $SUB\necho $SES\n\nrm -Rf output\nmkdir output\n\nCPUS=$(grep 'cpu cores' /proc/cpuinfo | uniq | sed -re 's/cpu cores\\s*:\\s*([0-9]+)/\\1/')\nCMD=\"time singularity run docker://anibalsolon/bl-app-prfmodel:v0.0.1\"\n\n$CMD \\\n3dDeconvolve -nodata 18 1.5 -polort -1 \\\n    -num_stimts 1 -stim_times 1 '1D:0' SPMG1 \\\n    -x1D output/conv.ref.spmg1.1D\n\n$CMD \\\n3dTstat -mean -prefix output/bold_mean.nii.gz $BOLD\n\n$CMD \\\n3dAutomask -prefix output/bold_automask.nii.gz $BOLD\n\n$CMD \\\n3dcalc -a $BOLD -b output/bold_mean.nii.gz -c output/bold_automask.nii.gz \\\n    -expr '100*c*(a-b)' -prefix output/bold_demean.nii.gz\n\nexport AFNI_CONVMODEL_REF=output/conv.ref.spmg1.1D\nexport AFNI_MODEL_PRF_STIM_DSET=$STIM\nexport AFNI_MODEL_PRF_ON_GRID=YES\nexport AFNI_MODEL_DEBUG=2\n\n$CMD \\\n3dNLfim -input output/bold_demean.nii.gz \\\n  -mask output/bold_automask.nii.gz \\\n  -noise Zero \\\n  -signal Conv_PRF \\\n  -sconstr 0 -10.0 10.0 \\\n  -sconstr 1 -1.0 1.0 \\\n  -sconstr 2 -1.0 1.0 \\\n  -sconstr 3 0.0 1.0 \\\n  -SIMPLEX \\\n  -nrand 10000 \\\n  -nbest 5 \\\n  -bucket 0 output/Buck.PRF.nii.gz \\\n  -snfit output/snfit.PRF.nii.gz \\\n  -jobs $CPUS\n\n$CMD \\\n3dcalc -a output/Buck.PRF.nii.gz'[1]' -b output/Buck.PRF.nii.gz'[2]' -expr 'sqrt(a^2+b^2)' -prefix output/polor.mag.nii.gz\n\n$CMD \\\n3dcalc -a output/Buck.PRF.nii.gz'[1]' -b output/Buck.PRF.nii.gz'[2]' -expr 'atan2(-b,a)' -prefix output/polor.phase.nii.gz\n"}, {"role": "assistant", "content": {"application": "afni", "software": ["3dDeconvolve", "3dTstat", "3dAutomask", "3dcalc", "3dNLfim"], "modules": [], "environment_variables": {"AFNI_CONVMODEL_REF": "output/conv.ref.spmg1.1D", "AFNI_MODEL_PRF_STIM_DSET": "STIM", "AFNI_MODEL_PRF_ON_GRID": "YES", "AFNI_MODEL_DEBUG": "2"}, "resources": {"gres": "", "cpus_per_task": "16", "tasks": "1", "ntasks_per_code": "1", "gpus": "", "gpus_per_node": "", "cores_per_socket": "", "gpus_per_task": "", "exclusive": "", "cpus_per_gpu": "", "gpu_type": "", "time": "00:30:00", "ntasks_per_node": "1", "nodes": "1", "memory": "50gb", "sockets_per_node": "", "ntasks_per_socket": "", "mem_per_gpu": "", "mem_per_cpu": "", "gres_flags": ""}, "versions": {}}}]}
