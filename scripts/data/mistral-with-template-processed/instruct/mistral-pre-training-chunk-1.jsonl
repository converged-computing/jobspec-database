{"text": "#!/bin/bash\n#SBATCH -p astyanax,small,amdsmall,cavefish\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=120gb\n#SBATCH -t 12:00:00\n#SBATCH -J surf.discoal\n#SBATCH --array=1-23\n\ncd /home/mcgaughs/shared/Software/diploSHIC\ndiscoal=\"/home/mcgaughs/shared/Software/discoal/discoal\"\n\n\nCMD_LIST=\"Surface_discoal_commands_w_3popsizes_2.txt\"\n#CMD_LIST=\"discoal_commands_orig_params_w_popsize.txt\"\nCMD=\"$(sed \"${SLURM_ARRAY_TASK_ID}q;d\" ${CMD_LIST})\"\neval ${CMD}\n"}
{"text": "#!/bin/bash\n#SBATCH -p  small,amdsmall\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=62gb\n#SBATCH -t 2:00:00\n#SBATCH -J fvecVCF\n#SBATCH --array=0-26\n\n\nsource /home/mcgaughs/rmoran/miniconda3/etc/profile.d/conda.sh\nconda activate diplo\n\n#generating feature vector stats\ncd /home/mcgaughs/shared/Software/diploSHIC\n\n#vcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/246Indvs_RepsMasked/phased_masked/Split_All_Scafolds_VCFs\"\n\n#vcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/246Indvs_RepsMasked/phased_masked/biallelicSNPs_wInvar_noIndels_phased_masked_ExcludeHet\"\n\nvcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/filtered_snps/HardFilteredSNPs_250Samples\"\nPop=\"Tinaja\"\n\nCMD_LIST=\"HardFiltered_All_Commands_fvecVCF.txt\"\n\nCMD=\"$(sed \"${SLURM_ARRAY_TASK_ID}q;d\" ${CMD_LIST})\"\neval ${CMD}\n\n"}
{"text": "#!/bin/bash\n#SBATCH -p ram256g,ram1t,amd2tb,amdlarge,amdsmall,small,astyanax,cavefish\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=230gb\n#SBATCH -t 28:00:00\n#SBATCH -J fvecVCF\n#SBATCH -e CMS_fvecVCF.err\n#SBATCH -o CMS_fvecVCF.out\n#SBATCH --array=1001-2360\n\n#2360 total\n\nsource /home/mcgaughs/rmoran/miniconda3/etc/profile.d/conda.sh\nconda activate diplo\n\n#generating feature vector stats\ncd /home/mcgaughs/shared/Software/diploSHIC\n\n#vcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/246Indvs_RepsMasked/phased_masked/Split_All_Scafolds_VCFs\"\n\n#vcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/246Indvs_RepsMasked/phased_masked/biallelicSNPs_wInvar_noIndels_phased_masked_ExcludeHet\"\n\n\n#HardFiltered SNPs\n#vcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/filtered_snps/HardFilteredSNPs_250Samples\"\nvcf=\"/home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/250_samples\"\n\nPop=\"CabMoroSurface\"\n\n#CMD_LIST=\"HardFiltered_All_wInvar_Commands_fvecVCF_5kb_803scaffs_w_data.txt\"\n#CMD_LIST=\"HardFiltered_All_wInvar_Commands_fvecVCF_5kb_Escon1797.txt\"\nCMD_LIST=\"HardFiltered_All_wInvar_Commands_fvecVCF_5kb.txt\"\n#CMD_LIST=\"HardFiltered_All_Commands_fvecVCF.txt\"\n\nCMD=\"$(sed \"${SLURM_ARRAY_TASK_ID}q;d\" ${CMD_LIST})\"\neval ${CMD}\n\n"}
{"text": "#!/bin/bash\n#SBATCH -p small,amdsmall,astyanax\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=60gb\n#SBATCH -t 3:00:00\n#SBATCH -J fvecSim\n#SBATCH --array=1-23\n\n#generating feature vector stats\ncd /home/mcgaughs/shared/Software/diploSHIC\n\nCMD_LIST=\"Surface.fvecSim.commnads.txt\"                                                                                                                                                               \n#CMD_LIST=\"Pachon.fvecSim.commnads.txt\"\n#CMD_LIST=\"Pachon.fvecSim.commnads.test.txt\"\n#CMD_LIST=\"fvecSim.commnads.retry.txt\"\n\nCMD=\"$(sed \"${SLURM_ARRAY_TASK_ID}q;d\" ${CMD_LIST})\"\neval ${CMD}\n"}
{"text": "#!/bin/bash\n#PBS -l nodes=1:ppn=1,walltime=2:00:00 \n#PBS -m abe \n#PBS -j oe\n#PBS -M rmoran@umn.edu \n#PBS -q mesabi\n#PBS -N par_combine_unpaired_Jineo\n\n\n#This script is used to combine unpaired reads from R1 and R2 fastq files prior to alignment with bwa\n\n\n#       The home folder\nexport HOME=/home/mcgaughs/shared/Datasets/Reads_ready_to_align/Jineo\n\nmodule load parallel\n\n#       Define a bash function for doing the processing\n\nparcomb() {\n        #sample basename from the <POP>_SampID.txt file supplied to parallel with the -a flag\n        SAMP=${1}\n        cat ${SAMP}_adtrim_trim_unpair_R1.fastq.gz ${SAMP}_adtrim_trim_unpair_R2.fastq.gz > ${SAMP}_adtrim_trim_unpair_all.fastq.gz\n}\n\n#   Export function so we can call it with parallel\nexport -f parcomb\n#       cd into the reads directory\ncd ${HOME}\n\nparallel --joblog Jineo_combunpair_parallel_logfile.txt -a Jineo_SampID.txt parcomb\n"}
{"text": "#!/bin/bash\n#PBS -l nodes=1:ppn=1,mem=126gb,walltime=96:00:00\n#PBS -j oe\n#PBS -q mangi\n#PBS -N RmvIndels\n#PBS -M rmoran@umn.edu \n#PBS -m abe\n#PBS -t 1-35\n\nmodule load bcftools\nexport PATH=$PATH:/home/mcgaughs/rmoran/software/tabix-0.2.6\n\n# We have defined a file-of-files that lists regions to operate over. This is\n# because we separated variant calling by chromosome. Chromosomes 1-25\n# have their own files and the unmapped contigs get their own files (broken up into Un 1-10)\nREGFOF=\"/home/mcgaughs/shared/References/2017-09_Astyanax_mexicanus/GATK_Regions_final.fof\"\nREGION=$(sed \"${PBS_ARRAYID}q;d\" ${REGFOF})\n# We define the output region based on the basename of the intervals file that\n# was read from the file-of-files\nREG_BNAME=$(basename ${REGION})\nREG_OUT=${REG_BNAME/.intervals/}\n\ncd /home/mcgaughs/shared/Datasets/all_sites_LARGE_vcfs/filtered_surfacefish/combined_filtered/246Indvs_RepsMasked\n\nmodule load python2\n\ngunzip ${REG_OUT}_HardFiltered_246Indv_SurfaceRef_wInvar.RepsRemoved.vcf.gz\n\npython2 Remove_indels_for_VCFtools.py ${REG_OUT}_HardFiltered_246Indv_SurfaceRef_wInvar.RepsRemoved.vcf > Indels_to_remove/${REG_OUT}_indels_to_remove.bed\n\nbgzip ${REG_OUT}_HardFiltered_246Indv_SurfaceRef_wInvar.RepsRemoved.vcf\n"}
{"text": "#!/bin/bash\n#PBS -l mem=22gb,nodes=1:ppn=12,walltime=24:00:00 \n#PBS -m abe \n#PBS -j oe\n#PBS -M rmoran@umn.edu \n#PBS -q mesabi\n#PBS -N bamg_cov_depth\n\nmodule load parallel/20160822\nmodule load samtools/1.7\n\n#Can use any bam aligned to the cavefish genome for this step\nexport CAVE_GENOME_SIZE=$(samtools view -H /home/mcgaughs/shared/Datasets/bams/cave.fish.reference.genome/v1_cavefish_raw_bams/Jineo_1_dupsmarked_rgadd.bam | grep -P '^@SQ' | cut -f 3 -d ':' | awk '{sum+=$1} END {print sum}')\nexport HOME=/home/mcgaughs/shared/Datasets/bams/cave.fish.reference.genome/v1_cavefish_raw_bams\n\n#Can use any bam aligned to the surface fish genome for this step\n#export SURFACE_GENOME_SIZE=$(samtools view -H /home/mcgaughs/shared/Datasets/bams/surface.fish.reference.genome/v2_surfacefish_raw_bams/Jineo_1_dupsmarked_rgadd.bam | grep -P '^@SQ' | cut -f 3 -d ':' | awk '{sum+=$1} END {print sum}')\n#export HOME=/home/mcgaughs/shared/Datasets/bams/surface.fish.reference.genome/v2_surfacefish_raw_bams\n\n\nbam_depth() {\n    BAM=${1}\n    BASE=$(basename $BAM)\n    ONAME=${BASE/.bam/}\n    samtools depth -aa ${BAM} | awk -v name=$ONAME -v size=$CAVE_GENOME_SIZE '{sum+=$3} END {print \"Cave\\t\"name\"\\t\"sum/size}' >> ${HOME}/cave_genome_depths.txt\n}\n\nexport -f bam_depth\n\necho -n \"Ran: \"\ndate\n\nfind /home/mcgaughs/shared/Datasets/bams/cave.fish.reference.genome/v1_cavefish_raw_bams -type f -name *.bam | parallel bam_depth > ${HOME}/cave_genome_depths.txt\n#find /home/mcgaughs/shared/Datasets/bams/surface.fish.reference.genome/v2_surfacefish_raw_bams -type f -name *.bam | parallel bam_depth > ${HOME}/surface_genome_depths.txt\n\necho -n \"Done: \"\ndate\n"}
{"text": "#!/bin/bash\n#PBS -l mem=126gb,nodes=1:ppn=16,walltime=96:00:00\n#PBS -m abe\n#PBS -j oe\n#PBS -M rmoran@umn.edu\n#PBS -q sb128\n\n# Load modules\nmodule load zlib/1.2.8\nmodule load xz-utils/5.2.2_intel2015update3\nmodule load parallel/20160822\nmodule load bwa/0.7.4\nmodule load samtools/1.7 \n\n\n# Specify the job command list to use (cave or surface)\n#CMD_LIST=\"/home/mcgaughs/shared/Datasets/Reads_ready_to_align/raw_bwa_commands_surface.txt\"\nCMD_LIST=\"/home/mcgaughs/shared/Datasets/Reads_ready_to_align/raw_bwa_commands_cavefish.txt\"\n\nCMD=\"$(sed \"${PBS_ARRAYID}q;d\" ${CMD_LIST})\"\neval ${CMD}\n"}
{"text": "#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 8\n#SBATCH -J pre_3\n#SBATCH --exclusive\n#SBATCH -o Pre3.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_O_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_S_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TF_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TK_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TP_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TV_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_P_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TB_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TG_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TL_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TQ_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_U_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_Q_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TD_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TH_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TM_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TS_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_V_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_R_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TE_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TJ_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TN_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_TU_512_wwm.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre_wwm/pre_training_X_512_wwm.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --init_checkpoint /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_model.ckpt \\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre3_cscd_all_512_wwm_from_bert\\\n --max_seq_length 512\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 8\\\n --learning_rate 2e-5\\\n --num_train_steps 2000000\\\n --save_checkpoints_steps 1000\\"}
{"text": "#!/bin/bash\n#SBATCH -p normal\n#SBATCH -N 8\n#SBATCH -J pre_2\n#SBATCH --exclusive\n#SBATCH -o Pre2.out\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=8\n#SBATCH --gres=dcu:4\n\nDIR=`pwd`\nhostfile=${DIR}/tmp\nscontrol show hostnames $SLURM_JOB_NODELIST > ${hostfile}\n\nfor i in `cat ${hostfile}`\ndo\n    echo ${i} slots=4\ndone > ${DIR}/hostfile-tmp\n\nnum_node=`cat ${hostfile} | uniq | wc -l`\n((num_DCU=${num_node}*4))\n\nexport MIOPEN_USER_DB_PATH=/tmp/tensorflow-miopen-${USER}-2.8\nexport MIOPEN_DEBUG_DISABLE_FIND_DB=1\nexport HOROVOD_HIERARCHICAL_ALLREDUCE=1\n\ninput_files=/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_O_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_S_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TF_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TK_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TP_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TV_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_P_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TB_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TG_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TL_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TQ_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_U_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_Q_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TD_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TH_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TM_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TS_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_V_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_R_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TE_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TJ_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TN_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_TU_512.tfrecord,/work1/zzx6320/lh/Projects/bert/data/cscd_pre/pre_training_X_512.tfrecord\n\nmpirun -np ${num_DCU} --hostfile ${DIR}/hostfile-tmp -mca pml ucx -x UCX_TLS=sm,rc,rocm_cpy,rocm_gdr,rocm_ipc -x LD_LIBRARY_PATH -mca coll_hcoll_enable 0 --bind-to none \\\n    python run_pretraining_hvd.py\\\n --input_file ${input_files}\\\n --bert_config_file /public/home/zzx6320/lh/Projects/bert/models/chinese_L-12_H-768_A-12/chinese_L-12_H-768_A-12/bert_config.json\\\n --output_dir /work1/zzx6320/lh/Projects/bert/outputs/Pre2_cscd_all_512_from_scratch\\\n --max_seq_length 512\\\n --do_train True\\\n --do_eval True \\\n --train_batch_size 8\\\n --learning_rate 2e-5\\\n --num_train_steps 2000000\\\n --save_checkpoints_steps 1000\\"}
