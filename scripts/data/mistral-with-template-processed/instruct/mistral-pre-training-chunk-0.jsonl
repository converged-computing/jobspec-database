{"text": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\n#SBATCH --job-name=train\n#SBATCH --comment=\"GLDv2 lr\"\n#SBATCH --partition=learnfair\n#SBATCH --output=/checkpoint/pillutla/pfl/outs/%A_%a.out\n#SBATCH --array=0-4  # TODO: count\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=10\n#SBATCH --mem=40G\n#SBATCH --gres=gpu:1\n#SBATCH --time=2:00:00\n#SBATCH --open-mode=append\n\nsource ~/.bashrc  # load all modules\nsource activate pyt19  # load environment\n\n\necho \"Running [ ${0} ${@} ] on $(hostname), starting at $(date)\"\necho \"Job id = ${SLURM_JOB_ID}, task id = ${SLURM_ARRAY_TASK_ID}\"\necho \"PWD = $(pwd)\"\necho \"python path = $(which python)\"\n\nset -exu\n\n# Default arguments\nlogdir=\"/checkpoint/pillutla/pfl/outputs3\"\nsavedir=\"/checkpoint/pillutla/pfl/saved_models3\"\ncommon_args=\"--dataset gldv2  --model_name resnet18 --train_batch_size 64 --eval_batch_size 128 \"\ncommon_args=\"${common_args} --lr 1e-3  \"\n\n\n# Populate the array\nlist_of_jobs=()\n\nseed=1\nstate=\"stateful\"\ninit=\"pretrained\"\npfl_algo=\"fedalt\"\ntrain_mode=\"adapter\"\n\nfor seed in 1\ndo\nfor reg_param in 1000 100 10 1 0.1\ndo\npretrained_name=\"gldv2b_resnetgn_${train_mode}_${pfl_algo}_reg${reg_param}_${init}_${state}_seed${seed}\"\nfor ne in 5\ndo\n    name=\"${pretrained_name}_ne${ne}\"\n    task_params=\"--num_epochs_personalization ${ne} \\\n        --client_var_l2_reg_coef ${reg_param} --client_var_prox_to_init \\\n        --pretrained_model_path ${savedir}/${pretrained_name}/checkpoint.pt \\\n        --seed ${seed} --personalize_on_client ${train_mode} \\\n        --logfilename ${logdir}/${name} --savedir ${savedir}/${name}\"\n    list_of_jobs+=(\"${task_params}\")\ndone # ne\ndone # reg_param\ndone # seed\n\n\n# Run\nnum_jobs=${#list_of_jobs[@]}\njob_id=${SLURM_ARRAY_TASK_ID}\nif [ ${job_id} -ge ${num_jobs} ] ; then\n    echo \"Invalid job id; qutting\"\n    exit 2\nfi\necho \"-------- STARTING JOB ${job_id}/${num_jobs}\"\nargs=${list_of_jobs[${job_id}]}\n\ntime python -u train_finetune.py \\\n        ${common_args} \\\n        ${args}\n\necho \"Job completed at $(date)\"\n"}
{"text": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\n#SBATCH --job-name=train\n#SBATCH --comment=\"GLDv2 reg param\"\n#SBATCH --partition=learnfair\n#SBATCH --output=/checkpoint/pillutla/pfl/outs/%A_%a.out\n#SBATCH --array=0-24  # TODO: count\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=10\n#SBATCH --mem=40G\n#SBATCH --gres=gpu:1\n#SBATCH --time=10:00:00\n#SBATCH --open-mode=append\n\nsource ~/.bashrc  # load all modules\nsource activate pyt19  # load environment\n\n\necho \"Running [ ${0} ${@} ] on $(hostname), starting at $(date)\"\necho \"Job id = ${SLURM_JOB_ID}, task id = ${SLURM_ARRAY_TASK_ID}\"\necho \"PWD = $(pwd)\"\necho \"python path = $(which python)\"\n\nset -exu\n\n# Default arguments\nlogdir=\"/checkpoint/pillutla/pfl/outputs3\"\nsavedir=\"/checkpoint/pillutla/pfl/saved_models3\"\ncommon_args=\"--dataset gldv2  --model_name resnet18 --train_batch_size 64 --eval_batch_size 128 \"\ncommon_args=\"${common_args} --num_communication_rounds 600 --num_clients_per_round 50 --num_local_epochs 1\"\ncommon_args=\"${common_args} --client_scheduler const --use_pretrained_model --log_test_every_n_rounds 150 \\\n            --global_scheduler linear --server_optimizer adam --server_lr 5e-5 --client_lr 1e-3  \\\n            --pretrained_model /checkpoint/pillutla/pfl/saved_models2/gldv2b_pretrain_2500/checkpoint.pt \\\n            \"\n\n# Populate the array\nlist_of_jobs=()\n\npfl_algo=\"fedalt\"\ntrain_mode=\"adapter\"\n\nfor seed in 1 2 3 4 5\ndo\nfor reg_param in 1000 100 10 1 0.1\ndo\n    name=\"gldv2b_resnetgn_${train_mode}_${pfl_algo}_reg${reg_param}_pretrained_stateful_seed${seed}\"\n    task_params=\"--client_var_l2_reg_coef ${reg_param} --client_var_prox_to_init\"\n    task_params=\"${task_params} --seed ${seed} --pfl_algo ${pfl_algo} --personalize_on_client ${train_mode} --logfilename ${logdir}/${name} --savedir ${savedir}/${name}\"\n    list_of_jobs+=(\"${task_params}\")\ndone # reg param\ndone # seed\n\n\n# Run\nnum_jobs=${#list_of_jobs[@]}\njob_id=${SLURM_ARRAY_TASK_ID}\nif [ ${job_id} -ge ${num_jobs} ] ; then\n    echo \"Invalid job id; qutting\"\n    exit 2\nfi\necho \"-------- STARTING JOB ${job_id}/${num_jobs}\"\nargs=${list_of_jobs[${job_id}]}\n\ntime python -u train_pfl.py \\\n        ${common_args} \\\n        ${args}\n\necho \"Job completed at $(date)\"\n"}
{"text": "#!/bin/bash\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\n#SBATCH --job-name=train\n#SBATCH --comment=\"EMNIST pfedme\"\n#SBATCH --partition=learnfair\n#SBATCH --output=/checkpoint/pillutla/pfl/outs/%A_%a.out\n#SBATCH --array=0-4  # TODO: count\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=10\n#SBATCH --mem=40G\n#SBATCH --gres=gpu:1\n#SBATCH --time=3:30:00\n#SBATCH --open-mode=append\n\nsource ~/.bashrc  # load all modules\nsource activate pyt19  # load environment\n\necho \"Running [ ${0} ${@} ] on $(hostname), starting at $(date)\"\necho \"Job id = ${SLURM_JOB_ID}, task id = ${SLURM_ARRAY_TASK_ID}\"\necho \"PWD = $(pwd)\"\necho \"python path = $(which python)\"\n\nset -exu\n\n# Default arguments\nlogdir=\"/checkpoint/pillutla/pfl/outputs3\"\nsavedir=\"/checkpoint/pillutla/pfl/saved_models3\"\ncommon_args=\"--dataset emnist  --model_name resnet_gn --train_batch_size 32 --eval_batch_size 256 \"\ncommon_args=\"${common_args} --num_communication_rounds 500 --num_clients_per_round 10 --num_local_epochs 1\"\ncommon_args=\"${common_args}  --client_scheduler const --server_optimizer sgd --server_lr 1.0 --server_momentum 0.0 \\\n    --client_lr 0.01 --global_scheduler const_and_cut --global_lr_decay_factor 0.5 --global_lr_decay_every 500 \\\n        --pretrained_model_path /checkpoint/pillutla/pfl/saved_models2/emnist_pretrain_2000/checkpoint.pt \\\n    \"\n\n\n# Populate the array\nlist_of_jobs=()\n\nl2reg=\"0.1\"\n\nfor seed in 1 2 3 4 5\ndo\n    name=\"emnist_resnetgn_pfedme2_seed${seed}\"\n    task_params=\"--seed ${seed} --pfl_algo pfedme --pfedme_l2_reg_coef ${l2reg} --logfilename ${logdir}/${name} --savedir ${savedir}/${name}\"\n    list_of_jobs+=(\"${task_params}\")\ndone  # l2reg\n\n\n# Run\nnum_jobs=${#list_of_jobs[@]}\njob_id=${SLURM_ARRAY_TASK_ID}\nif [ ${job_id} -ge ${num_jobs} ] ; then\n    echo \"Invalid job id; qutting\"\n    exit 2\nfi\necho \"-------- STARTING JOB ${job_id}/${num_jobs}\"\nargs=${list_of_jobs[${job_id}]}\n\ntime python -u train_pfl.py \\\n        ${common_args} \\\n        ${args}\n\necho \"Job completed at $(date)\"\n"}
{"text": "#!/bin/bash\n#SBATCH -J gps_paper_pipeline_scheduler\n#SBATCH -A MRC-BSU-SL2-CPU\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=4\n#SBATCH --time=6:00:00\n#SBATCH --mail-type=FAIL\n#SBATCH -p cclake\n#SBATCH -o logs/gps_paper_pipeline_scheduler/%j.out\n\n#! Number of nodes and tasks per node allocated by SLURM (do not change):\nnumnodes=$SLURM_JOB_NUM_NODES\nnumtasks=$SLURM_NTASKS\nmpi_tasks_per_node=$(echo \"$SLURM_TASKS_PER_NODE\" | sed -e  's/^\\([0-9][0-9]*\\).*$/\\1/')\n\n#! Optionally modify the environment seen by the application\n#! (note that SLURM reproduces the environment at submission irrespective of ~/.bashrc):\n. /etc/profile.d/modules.sh                # Leave this line (enables the module command)\nmodule purge                               # Removes all modules still loaded\nmodule load rhel7/default-peta4            # REQUIRED - loads the basic environment\n\nworkdir=\"$SLURM_SUBMIT_DIR\"\n\n#! Are you using OpenMP (NB this is unrelated to OpenMPI)? If so increase this\n#! safe value to no more than 32:\nexport OMP_NUM_THREADS=5\n\n#! Number of MPI tasks to be started by the application per node and in total (do not change):\nnp=$[${numnodes}*${mpi_tasks_per_node}]\n\n#! The following variables define a sensible pinning strategy for Intel MPI tasks -\n#! this should be suitable for both pure MPI and hybrid MPI/OpenMP jobs:\nexport I_MPI_PIN_DOMAIN=omp:compact # Domains are $OMP_NUM_THREADS cores in size\nexport I_MPI_PIN_ORDER=scatter # Adjacent domains have minimal sharing of caches/sockets\n\n###############################################################\n### You should not have to change anything below this line ####\n###############################################################\n\ncd $workdir\necho -e \"Changed directory to `pwd`.\\n\"\n\nJOBID=$SLURM_JOB_ID\n\necho -e \"JobID: $JOBID\\n======\"\necho \"Time: `date`\"\necho \"Running on mcadr node: `hostname`\"\necho \"Current directory: `pwd`\"\n\nif [ \"$SLURM_JOB_NODELIST\" ]; then\n        #! Create a machine file:\n        export NODEFILE=`generate_pbs_nodefile`\n        cat $NODEFILE | uniq > logs/machine.file.$JOBID\n        echo -e \"\\nNodes allocated:\\n================\"\n        echo `cat logs/machine.file.$JOBID | sed -e 's/\\..*$//g'`\nfi\n\necho -e \"\\nnumtasks=$numtasks, numnodes=$numnodes, mpi_tasks_per_node=$mpi_tasks_per_node (OMP_NUM_THREADS=$OMP_NUM_THREADS)\"\n\necho -e \"\\nExecuting command:\\n==================\\n\\n\"\n\n__conda_setup=\"$('/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/bin/conda' 'shell.bash' 'hook' 2> /dev/null)\"\nif [ $? -eq 0 ]; then\n    eval \"$__conda_setup\"\nelse\n    if [ -f \"/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/etc/profile.d/conda.sh\" ]; then\n        . \"/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/etc/profile.d/conda.sh\"\n    else\n        export PATH=\"/rds/project/rds-csoP2nj6Y6Y/tw395/mambaforge/bin:$PATH\"\n    fi\nfi\nunset __conda_setup\n\nunset R_LIBS\n\nconda activate snakemake_env\n\nsnakemake --profile profile \"${@}\"\n"}
{"text": "#!/bin/bash\n\n# Check if input is a number. If not, exit the script.\nvalidate_number() {\n    if ! [[ \"$1\" =~ ^[0-9]+$ ]] || [ \"$1\" -le 0 ]; then\n        echo \"Error: Input is not a valid positive number. Exiting the script.\"\n        exit 1\n    fi\n}\n\n# Parse command-line arguments\n# Check if the number of arguments is equal to 6, otherwise print usage instruction\nif [ \"$#\" -ne 6 ]; then\n    echo \"Usage: $0 <file_type> <array_size> <num_threads> <job_name> <num_nodes> <ntasks-per-node>\"\n    echo \"Available file types: cNoThread, cPThread, cOpenMP, pythonNoThreads, pythonWithThreads\"\n    echo \"Max number of threads: 256 (128 cores * 2 threads per core)\"\n    exit 1\nfi\n\nfile_type=$1\narray_size=$2\nnum_threads=$3 # Max = 256\njob_name=$4\nnum_nodes=$5\nntasks_per_node=$6\n\n# Validate file type\ncase \"$file_type\" in\n    \"cNoThread\" | \"cPThread\" | \"cOpenMP\" | \"pythonNoThreads\" | \"pythonWithThreads\" | \"cNoThread.c\" | \"cPThread.c\" | \"cOpenMP.c\" | \"pythonNoThreads.py\" | \"pythonWithThreads.py\") ;;\n    *)\n\techo \"Error: Unsupported file type: $file_type. Exiting.\"\n\texit 1\n\t;;\nesac\n\n# Validate array size and number of threads\nvalidate_number \"$array_size\"\nvalidate_number \"$num_threads\"\nvalidate_number \"$num_nodes\"\nvalidate_number \"$ntasks_per_node\"\n\n# Check that the number of threads is less than or equal to 256.\nif [ \"$num_threads\" -gt 256 ]; then\n    echo \"Error: The number of threads cannot exceed 256. Exiting.\"\n    exit 1\nfi\n\n# Calculate the number of cores needed\nnum_cores=$((num_threads + 1 / 2)) # Hyperthreading (2 threads per core)\n\nprogram_type=\"\"\ncase \"$file_type\" in\n    \"cNoThread\" | \"cNoThread.c\")\n        program_type=\"${job_name}_cNoThread.c\"\n        if [ -f \"./compiled-programs/$program_type\" ]; then\n            rm \"./compiled-programs/$program_type\"\n        fi\n        gcc -o \"./compiled-programs/$program_type\" cNoThread.c ;;\n    \"cPThread\" | \"cPThread.c\")\n        program_type=\"${job_name}_cPThread.c\"\n        if [ -f \"./compiled-programs/$program_type\" ]; then\n            rm \"./compiled-programs/$program_type\"\n        fi\n        gcc -o \"./compiled-programs/$program_type\" cPThread.c -lpthread ;;\n    \"cOpenMP\" | \"cOpenMP.c\")\n        program_type=\"${job_name}_cOpenMP.c\"\n        if [ -f \"./compiled-programs/$program_type\" ]; then\n            rm \"./compiled-programs/$program_type\"\n        fi\n        gcc -o \"./compiled-programs/$program_type\" cOpenMP.c -fopenmp ;;\n    \"pythonNoThreads\" | \"pythonNoThreads.py\")\n        program_type=\"pythonNoThreads.py\" ;;\n    \"pythonWithThreads\" | \"pythonWithThreads.py\")\n        program_type=\"pythonWithThreads.py\" ;;\nesac\n\n\n# Generate Slurm batch job script\nbatch_job_script=\"job_${job_name}.sbatch\"\n\n# Write the Slurm batch job script with either C program or Python script execution\nif [[ \"$program_type\" == *.c ]]; then\n    cat <<EOF >\"./batch-jobs/$batch_job_script\"\n#!/bin/bash\n#SBATCH --job-name=$job_name\n#SBATCH --nodes=$num_nodes\n#SBATCH --ntasks-per-node=$ntasks_per_node\n#SBATCH --cpus-per-task=$num_cores\n#SBATCH --time=4:00:00\n#SBATCH -o ./slurm-output/output.%j.out # STDOUT\n\nmodule load gcc\n\n./compiled-programs/$program_type $array_size $num_threads $num_cores $job_name $num_nodes $ntasks_per_node\nEOF\nelse\n    cat <<EOF >\"./batch-jobs/$batch_job_script\"\n#!/bin/bash\n#SBATCH --job-name=$job_name\n#SBATCH --nodes=$num_nodes\n#SBATCH --ntasks-per-node=$ntasks_per_node\n#SBATCH --cpus-per-task=$num_cores\n#SBATCH --time=4:00:00\n#SBATCH -o ./slurm-output/output.%j.out # STDOUT\n\nmodule load python\n\npython \"$program_type\" $array_size $num_threads $num_cores $job_name $num_nodes $ntasks_per_node\nEOF\nfi\n\n# Submit the Slurm batch job\necho \"Submitting Slurm batch job with program $file_type and array size $array_size with $num_threads threads..\"\n\nsbatch \"./batch-jobs/$batch_job_script\"\n\necho \"Slurm batch job submitted successfully.\"\n"}
{"text": "#!/bin/bash\n#PBS -P xe2\n#PBS -q expressbw\n#PBS -l ncpus=28\n#PBS -l walltime=24:00:00\n#PBS -l other=gdata1\n#PBS -l mem=126G\n#PBS -l jobfs=100G\n#PBS -l wd\n\nlogdir=raijin/log\nif [ -d $logdir ]\nthen\n  pushd $logdir >/dev/null\n  if [ -n \"$(ls *.ER *.OU 2>/dev/null)\" ]\n  then\n    tar cf `date +%y%m%d_%H%M%S`.tar *.OU *.ER 2>/dev/null\n    rm *.OU *.ER\n  fi\n  popd >/dev/null\nelse\n  mkdir -p $logdir\nfi\n\n. raijin/modules.sh\n\nQSUB=\"qsub -q {cluster.queue} -l ncpus={threads} -l jobfs={cluster.jobfs}\"\nQSUB=\"$QSUB -l walltime={cluster.time} -l mem={cluster.mem}\"\nQSUB=\"$QSUB -l wd -o $logdir -e $logdir -P xe2\"\n\nsnakemake                                \\\n    -j 500                               \\\n    --cluster-config raijin/cluster.yaml \\\n    --js raijin/jobscript.sh             \\\n    --local-cores 16                     \\\n    --rerun-incomplete                   \\\n    --keep-going                         \\\n    --cluster \"$QSUB\"                    \\\n   all                                   \\\n   >raijin/log/snakemake.log\n"}
{"text": "#!/bin/bash\n#PBS -P xe2\n#PBS -q hugemem\n#PBS -l ncpus=28\n#PBS -l walltime=24:00:00\n#PBS -l other=gdata1\n#PBS -l mem=800G\n#PBS -l wd\n#PBS -m abe\n#PBS -M kevin.murray@anu.edu.au\n\n. raijin/modules.sh\n\nmkdir -p data/log\n\nsnakemake --unlock\n\nsnakemake                         \\\n    -j ${PBS_NCPUS}               \\\n    --rerun-incomplete            \\\n    --keep-going                  \\\n    ${target:-all}                \\\n    |& tee data/log/snakemake.log \\\n\n"}
{"text": "#!/bin/bash\n#SBATCH -N 3\n#SBATCH -q regular\n#SBATCH -t 05:00:00\n#SBATCH -C haswell\n#SBATCH -J prob-multiproc\n#SBATCH -o logs/%x-%j.out\nmodule load pytorch/v1.6.0\nsrun -n 96 -c 2 python $HOME/mldas/mldas/assess.py probmap -c $HOME/mldas/configs/assess.yaml -o $SCRATCH/probmaps --mpi\n"}
{"text": "#!/bin/bash\n#SBATCH --nodes=3\n#SBATCH --gpus-per-node=a100:2\n#SBATCH --tasks-per-node=2 \n#SBATCH --cpus-per-task=8       # There are 24 CPU cores on P100 Cedar GPU nodes\n#SBATCH --mem=64G               # Request the full memory of the node\n#SBATCH --time=11:50:00\n#SBATCH --account=rrg-lsigal\n#SBATCH --output=PKD_PM_FT-%j.out\n\nsource ../env_dpl/bin/activate\nnvidia-smi\n\nexport NCCL_BLOCKING_WAIT=1  #Set this environment variable if you wish to use the NCCL backend for inter-GPU communication.\nexport MASTER_ADDR=$(hostname) #Store the master node\u2019s IP address in the MASTER_ADDR environment variable.\n\necho \"$SLURM_NODEID master: $MASTER_ADDR world_size: $SLURM_NTASKS\"\necho \"$SLURM_NODEID Launching python script\"\n\nexp_name=\"PKD_nw_PM_FT\"\n\nEXP_pre=exp/${exp_name}\nEXP_fine=exp/${exp_name}_FT\n\n#python -m wandb login 749dd8035d38a54262549bdfdc68bc3822b7522c\n\npretrain=0\n\nif [[ $pretrain -gt 0 ]]\nthen\necho \"Phase 1 pre-training ...\" ${exp_name}\nsrun python -u ../main_dpvit.py --data_path ../data/mini_imagenet/train_comb \\\n    --output_dir ${EXP_pre} --evaluate_freq 50 --visualization_freq 50 --init_method=tcp://$MASTER_ADDR:3466 \\\n    --prod_mode=False --use_fp16 True --lr 0.0005 --epochs 1800 --image_path ../SMKD/img_viz \\\n    --global_crops_scale 0.4 1 --local_crops_scale 0.05 0.4 --num_workers=4 --n_gpus=$SLURM_NTASKS \\\n    --lr_mix 0 --lr_noise 1 --K 64 --num_fore 40 --use_parts 0 \\\n    --lambda1 1 --lambda2 0 --lambda3 1 --batch_size_per_gpu 100 --use_DDP=1\n\nelse\necho \"Phase 2 tuning ...\" ${exp_name}\nsrun python -u ../main_dpvit.py --data_path ../data/mini_imagenet/train_comb \\\n    --pretrained_path ${EXP_pre} --pretrained_file checkpoint.pth --init_method=tcp://$MASTER_ADDR:3456 \\\n    --output_dir ${EXP_fine} --evaluate_freq 5 --visualization_freq 5 --use_fp16 True --image_path ../SMKD/img_viz \\\n    --lr 0.0005 --epochs 150 --lambda1 1 --lambda2 0.45 --num_workers=4 --n_gpus=$SLURM_NTASKS \\\n    --lambda3 0 --supervised_contrastive --batch_size_per_gpu 90 --global_crops_scale 0.4 1 \\\n    --lr_mix 1 --lr_noise 1 --K 64 --num_fore 40 \\\n    --local_crops_scale 0.05 0.4 --partition test --saveckp_freq 5 --use_DDP=1\n\nfi"}
{"text": "#!/bin/bash\n#SBATCH -p small,amdsmall\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=62gb\n#SBATCH -t 80:00:00\n#SBATCH -J BUSCO\n\n\nmodule load python/2\n\nsrc=/home/research/genome/assemblies_configs/\n\ninput=/home/research/genome/final_assembly/pilon_final_122418.fa  #genome assembly fasta\nlineage=/home/research/genome/assemblies_configs/lineage/actinopterygii_odb9 #Visit http://busco.ezlab.org for lineages - pick one that's closest to your study organism and save somewhere in your h\nbusco=/home/software/busco/2.0/bin/BUSCO.py #this is the correct path for BUSCO v2.0  \n\n\n#usage: python BUSCO.py -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]\n#choose a species (-sp) that is a close relative of your study orgnaism; list available here: /panfs/roc/msisoft/augustus/3.2.3.CentOS7/config/species\n\n\npython2 $busco -i $input -o 122418_final_assembly -l $lineage -f -m geno -sp zebrafish\n\n"}
