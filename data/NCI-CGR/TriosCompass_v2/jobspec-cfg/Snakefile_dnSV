import os
import uuid
import peds
import glob
from itertools import compress

pepfile: "pep/cgr_config.yaml"
pepschema: "schemas/cgr_manifest_schema.yaml"

samples = pep.sample_table
# samples = samples.loc[ samples['CGF_ID'].isin( ['SC108472','SC730933'])]

# print(samples)
# print(pep.config.output_dir)


# get unique value of a list
# print(list(set(samples["FLOWCELL"].tolist())))

flowcells = list(set(samples["FLOWCELL"].tolist()))
subjs = list(set(samples["CGF_ID"].tolist()))
ids = samples["sample_name"].tolist()
# print(len(ids))
# print(subjs)
# print(len(list(set(ids))))
# exit()

# print (samples)


# 'SC742296': ['BH2HYTDSX5', 'BH2JN2DSX5']
subj_flowcell_dict=samples[['CGF_ID','FLOWCELL']].drop_duplicates().groupby('CGF_ID')['FLOWCELL'].apply(list).to_dict()

ref_dict=os.path.splitext(pep.config.hg38_ref)[0]+'.dict'

# print (subj_flowcell_dict)


### Define trios
ped_files = glob.glob(pep.config.ped_dir + "/*.ped")

### make more compatible
output_dir = pep.config.output_dir

### It seems order of the family member is as the order of entries in the pedigree file
# see https://github.com/jeremymcrae/peds/blob/master/peds/ped.py
# Therefore, it is likely to be the order: father, mother and kid
# t0334   SC074198        0       0       1       1
# t0334   SC074199        0       0       2       1
# t0334   SC074201        SC074198        SC074199        1       1
families = {}
SEX_DICT={}
for fn in ped_files:
    f=peds.open_ped(fn)[0]
    families[f.id]=f
    for person in f:
        SEX_DICT[person.id] = 'M' if person.is_male() else 'F'

fam_ids = list(families.keys()) 

fam_ids2=  [f for f in fam_ids if f != 't0588c1' ]
# print(fam_ids)


### to link with the section of rules from the workflow Snakefile_chernobyl
output_dir = pep.config.output_dir
callers=['DV', 'GATK', "D_and_G"]
fam_ids=fam_ids2 # remove the subject t0588c1
hg38_ref = pep.config.hg38_ref
ref_dict=os.path.splitext(hg38_ref)[0]+'.dict'
wgs_interval= pep.config.wgs_interval
ped_dir = pep.config.ped_dir

### for dnSTR calling
gangstr_panel = pep.config.gangstr_panel
hipstr_panel = pep.config.hipstr_panel
hipstr_filters= pep.config.hipstr_filters
gangstr_filters= pep.config.gangstr_filters
dup_reg = pep.config.dup_reg
STR_CALLERS=["hipstr", "gangstr"]
split_total = pep.config.split_total
CHUNKS =[str(x).zfill(5) for x in range(split_total)]
final_subjs = list(set([p.id for f in fam_ids2 for p  in families[f] ]))

### Settings for dnSTR
# ref_fai = hg38_ref +'.fai'
child_ids = [[person.id for person in families[fid] if families[fid].get_father(person) ][0] for fid in fam_ids2]
CHILD_DICT=dict(zip(fam_ids2,child_ids))
PHASE_WIN = pep.config.phase_window

#### Above is the same as Snakefile_CGRv2

EXCLUDE_BED = "ref/exclude.cnvnator_100bp.GRCh38.20170403.bed"

SV_CALLERS=["smoove", "gt2"]

rule all:
    input: 
        expand(output_dir + "/joint_dnSV/{fam}.dnSV.vcf", fam=fam_ids2)

### Below is copy from MineSV
rule manta_create_run_script:
    input:
        bam = output_dir + '/cram/{sample}.cram',
        bai = output_dir + '/cram/{sample}.cram.crai',
        ref = hg38_ref
    output:
        output_dir + '/manta/{sample}/runWorkflow.py',
        output_dir + '/manta/{sample}/runWorkflow.py.config.pickle'
    resources:
        runtime="4h",
        mem_mb=10000
    params:
        prefix = output_dir + '/manta/{sample}'
    singularity: 'library://weizhu365/mocca-sv/manta_1-4-0:1.0.0'
    shell:
        'configManta.py \
            --bam {input.bam} \
            --referenceFasta {input.ref} \
            --runDir {params.prefix}'

rule manta_call:
    input:
        cmd = output_dir + '/manta/{sample}/runWorkflow.py',
        pickle = output_dir + '/manta/{sample}/runWorkflow.py.config.pickle'
    output:
        multiext(output_dir + '/manta/{sample}/results/variants/', 'candidateSmallIndels.vcf.gz','candidateSmallIndels.vcf.gz.tbi', 'candidateSV.vcf.gz', 'candidateSV.vcf.gz.tbi','diploidSV.vcf.gz','diploidSV.vcf.gz.tbi'),
        multiext(output_dir + '/manta/{sample}/results/stats/', 
        'alignmentStatsSummary.txt', 'svCandidateGenerationStats.tsv','svCandidateGenerationStats.xml','svLocusGraphStats.tsv')
    threads: 10
    resources:
        runtime="24h",
        mem_mb=60000
    benchmark:
        "benchmarks/manta_call/{sample}.tsv"
    singularity: 'library://weizhu365/mocca-sv/manta_1-4-0:1.0.0'
    shell:
        '{input.cmd} -m local -j {threads}'

### make uniq SV id in manta
rule manta_sv: 
    input:
        output_dir + '/manta/{sample}/results/variants/diploidSV.vcf.gz'
    output: 
        gz = output_dir + "/manta_sv/{sample}.vcf.gz",
        tbi = output_dir + "/manta_sv/{sample}.vcf.gz.tbi"
    threads: 4
    resources:
        runtime="4h",
        mem_mb=40000
    envmodules: "bcftools"
    shell: """
        bcftools annotate --threads {threads} -I '{wildcards.sample}:%ID' {input} -Oz -o {output.gz}
        tabix -p vcf {output.gz}
    """

### make manta output list in the order: father, mother and child (the same order as the samples listed in the ped file)
rule trio_manta_list:
    input: 
        vcfs=lambda w: expand(output_dir + "/manta_sv/{id}.vcf.gz", id= [person.id for person in families[w.fam]])
    output: 
        output_dir + "/trio_manta_list/{fam}.manta_vcf.lst"
    shell: """
        # ls {input.vcfs} > {output}
        echo {input.vcfs} | awk '{{OFS="\\n"; $1=$1}}1' > {output}
    """



###  merge manta SV by svimmer
rule svimmer:
    input: 
        output_dir + "/trio_manta_list/{fam}.manta_vcf.lst"
    output:
        vcf = output_dir + "/svimmer/{fam}.merged.vcf.gz",
        tbi = output_dir + "/svimmer/{fam}.merged.vcf.gz.tbi"
    threads: 4
    resources:
        runtime="24h",
        mem_mb=60000
    benchmark:
        "benchmarks/svimmer/{fam}.tsv"
    shell: """
        ./svimmer/svimmer {input} chr{{1..22}} --ids --max_distance 50 --max_size_difference 100 | bgzip -c > {output.vcf}
        tabix -p vcf {output.vcf}
    """

rule graphtyper:
    input: 
        bams = lambda w: expand(output_dir + "/cram/{id}.cram", id= [person.id for person in families[w.fam]]),
        ref = hg38_ref,
        vcf = output_dir + "/svimmer/{fam}.merged.vcf.gz"
    output:
        bam_lst = output_dir+"/graphtyper/{fam}/{fam}.bam.lst",
        vcf_lst = output_dir+"/graphtyper/{fam}/{fam}.vcf.lst",
        vcf = output_dir+"/graphtyper/{fam}.gt2.vcf.gz",
        tbi = output_dir+"/graphtyper/{fam}.gt2.vcf.gz.tbi"
    threads: 40
    resources:
        runtime="72h",
        mem_mb=120000
    benchmark:
        "benchmarks/graphtyper/{fam}.tsv"
    envmodules: "bcftools"
    params: 
        prefix = output_dir + "/graphtyper/{fam}"
    shell: """
        # ls {input.bams} > {output.bam_lst}
        # To keep the sample in the order:father, mother, child
        echo {input.bams} | tr ' ' '\\n' > {output.bam_lst}

        seq 1 22 | sed -e "s/^/chr/" | parallel  'scripts/graphtyper genotype_sv {input.ref} {input.vcf} --sams={output.bam_lst} --threads=2 --region={{}} --output={params.prefix}'

        echo chr{{1..22}} | tr ' ' '\\n' | while read chrom; do if [[ ! -d {params.prefix}/${{chrom}} ]]; then continue; fi; find {params.prefix}/${{chrom}} -name "*.vcf.gz" | sort; done > {output.vcf_lst}

        bcftools concat --naive --file-list {output.vcf_lst} -Oz -o {output.vcf}
        tabix -p vcf {output.vcf}
    """

rule graphtyper_filter: 
    input: 
        vcf = output_dir+"/graphtyper/{fam}.gt2.vcf.gz"
    output:
        vcf = output_dir+"/graphtyper_filter/{fam}.gt2_filter.vcf.gz"
    threads: 4
    resources:
        runtime="4h",
        mem_mb=20000
    benchmark:
        "benchmarks/graphtyper_filter/{fam}.tsv"
    envmodules: "vcflib", "bcftools"
    shell: """
        vcffilter -f "( SVTYPE = BND & SVMODEL = AGGREGATED & QD > 20 & ( ABHet > 0.30 | ABHet < 0 ) & ( AC / NUM_MERGED_SVS ) < 10 & PASS_AC > 0 & PASS_ratio > 0.1 ) | ( SVTYPE = DEL & SVMODEL = AGGREGATED & QD > 12 & ( ABHet > 0.30 | ABHet < 0 ) & ( AC / NUM_MERGED_SVS ) < 25 & PASS_AC > 0 & PASS_ratio > 0.1 ) | ( SVTYPE = DUP & SVMODEL = AGGREGATED & QD > 5 & PASS_AC > 0 & ( AC / NUM_MERGED_SVS ) < 25 ) | ( SVTYPE = INS & SVMODEL = AGGREGATED & PASS_AC > 0 & ( AC / NUM_MERGED_SVS ) < 25 & PASS_ratio > 0.1 & ( ABHet > 0.25 | ABHet < 0 ) & MaxAAS > 4 ) | ( SVTYPE = INV & PASS_AC > 0 & ( AC / NUM_MERGED_SVS ) < 25 & PASS_ratio > 0.1 & ( ABHet > 0.25 | ABHet < 0 ) & MaxAAS > 4 )"  {input.vcf} | bgzip -c > {output.vcf}
        tabix -p vcf {output.vcf} 
    """

### smoove need unique output folder for each trio to have files like
# SC742298.histo
# output: {outdir}/{name}-smoove.vcf.gz
# using bam as input files
rule smoove:
    input: 
        # bams = lambda w: expand(output_dir + "/cram/{id}.cram", id= [person.id for person in families[w.fam]]),
        bams = lambda w: expand(output_dir + "/gatk_markdup/{id}.dedup.bam", id= [person.id for person in families[w.fam]]),
        exclude_bed = EXCLUDE_BED,
        ref = hg38_ref
    output:
        vcf = output_dir + "/smoove/{fam}/{fam}-smoove.genotyped.vcf.gz",
        csi = output_dir + "/smoove/{fam}/{fam}-smoove.genotyped.vcf.gz.csi"
    threads: 20
    resources:
        runtime="24h",
        mem_mb=100000
    benchmark:
        "benchmarks/smoove/{fam}.tsv"
    params: 
        prefix = "{fam}",
        out_dir =  output_dir + "/smoove/{fam}"    
    container: "docker://brentp/smoove"
    shell: """
        smoove call -x --name {params.prefix} -o {params.out_dir} --exclude {input.exclude_bed} --fasta  {input.ref} -p {threads} --genotype {input.bams}
    """

### filter out dnSV using bcftools
# Note that samples are in the order: father, mother, proband
rule call_dnSV:
    input : 
        output_dir + "/smoove/{fam}/{fam}-smoove.genotyped.vcf.gz"
    output: 
        output_dir + "/dnSV/{fam}.smoove.dnSV.vcf"
    envmodules: "bcftools"
    shell: """
        bcftools view -i 'GT[2]="het" && GT[1]="RR" && GT[0]="RR" ' -O v  {input} -o {output}
    """

use rule call_dnSV as call_dnSV_gt2 with:
    input: 
        output_dir+"/graphtyper_filter/{fam}.gt2_filter.vcf.gz"
    output: 
        output_dir + "/dnSV/{fam}.gt2.dnSV.vcf"

use rule trio_manta_list as make_dnSV_list with:
    input:
        vcfs = expand(output_dir + "/dnSV/{{fam}}.{caller}.dnSV.vcf", caller=SV_CALLERS)
    output:     
        output_dir + "/joint_dnSV/{fam}.dnSV.lst"

rule joint_dnSV:
    input: 
        output_dir + "/joint_dnSV/{fam}.dnSV.lst"
    output:
        vcf = output_dir + "/joint_dnSV/{fam}.dnSV.vcf",
        stats = output_dir + "/joint_dnSV/{fam}.dnSV.stats",
        others = multiext(output_dir+ "/joint_dnSV/{fam}.dnSV.stats", "_CHR", "support")
    envmodules: "survivor"
    shell: """
        SURVIVOR merge {input} 1000 2 0 0 0 50 {output.vcf}
        SURVIVOR stats {output.vcf} 50 -1 -1 {output.stats}
    """