export DDF_PIPELINE_CLUSTER=azimuth
export DATA_DIR=/home/azimuth/surveys/
export MACAROON_DIR=/home/azimuth/macaroons/
export LOFAR_SINGULARITY=/home/azimuth/software/singularity/lofar_sksp_v4.4.0_cascadelake_cascadelake_ddf_mkl_cuda.sif
export SOFTWAREDIR=/cosma/home/durham/dc-mora2/Software

## cluster options
export CLUSTER_OPTS="-A do011 -p cosma8-ska --output=${DATA_DIR}/logs/R-%x.%j.out" 
export CLUSTER_OPTS="-A do011 -p cosma8-dine2 --output=${DATA_DIR}/logs/R-%x.%j.out" 

## ddf-pipeline
export DDFPIPELINE_SINGULARITY=/home/azimuth/software/singularity/ddf.sif
export BOOTSTRAP_DIR=/cosma/home/durham/dc-mora2/Software/bootstrap
export DDF_PIPELINE_INSTALL=/cosma/home/durham/dc-mora2/Software/ddf-pipeline

## If you want to have untar and dysco as a job - eg. for COSMA in Durham
export UNPACK_AS_JOB=True

## pick the queueing system
export USE_TORQUE=False

## PYTHONPATH
export SOFTWAREDIR=/home/azimuth/software
export PYTHONPATH=${PYTHONPATH}:${SOFTWAREDIR}/lotss-query:${SOFTWAREDIR}/lofar_stager_api-1.7:${SOFTWAREDIR}/ddf-pipeline/utils:${SOFTWAREDIR}/lotss-hba-survey:${SOFTWAREDIR}/ddf-pipeline/scripts:${SOFTWAREDIR}/lofar-vlbi-pipeline
