generator:
  # kernel size of the first and last convolutions which transform the inputs and outputs
  # large_kernel_size: 9
  # # kernel size of all convolutions in-between, i.e. those in the residual and subpixel convolutional blocks
  # small_kernel_size: 3
  # n_channels: 64  # number of channels in-between, i.e. the input and output channels for the residual and subpixel convolutional blocks
  # n_blocks: 16  # number of residual blocks
  num_heads: 0 # number of heads for multihead attention.
  checkpoint: SRResNet.pth # name of checkpoint to load generator weights from
discriminator:
  discriminator_type: Default
  kernel_size: 3  # kernel size in all convolutional blocks
  n_channels: 64  # number of output channels in the first convolutional block, after which it is doubled in every 2nd block thereafter
  n_blocks: 8  # number of convolutional blocks
  fc_size: 1024  # size of the first fully connected layer
  checkpoint: null
train:
  # Learning parameters
  epochs: 100  # number of training epochs
  lr_g: 1e-4  # learning rate
  lr_d: 1e-6  # learning rate
  grad_clip: null  # clip if gradients are exploding
  alpha: 1e+0 # weight of mse loss
  beta: 1e-5 # weight of adversarial loss
  loss_type: WGAN
  lambda_gp: 10 # weight of gradient penalty term in WGAN-GP
dataset:
  # Data parameters
  data_folder_hyperion: ./data  # folder with JSON data files
  data_folder_local: /Users/youssefshaarawy/Documents/Datasets/INM705/data
  crop_size: 96  # crop size of target HR images
  scaling_factor: 4  # the scaling factor for the generator; the input LR images will be downsampled from the target HR images by this factor
  max_test_size: null # max size of test images in case of memory restrictions
train_dataloader:
  batch_size: 32
  shuffle: True
  num_workers: 4
test_dataloader:
  batch_size: 1
  shuffle: False
  num_workers: 4