#!/bin/bash

#SBATCH -n 6
#SBATCH -N 1
#SBATCH -t 0-0:30
#SBATCH -p huce_intel
#SBATCH --mem=50000
#SBATCH --mail-type=ALL

# Initial version: Lizzie Lundgren, 7/12/2018

# This run script is for use within gchp.multirun.sh which submits 
# multiple consecutive GCHP jobs to break up longer runs into smaller jobs of 
# shorter duration.
#
# NOTES:
#  1. This run script is used within gchp.multirun.sh and should not 
#     be used on its own. Use gchp.run instead if not doing multi-segmented runs.
#  2. All stdout is sent to gchp.log without deleting the existing file.
#  3. runConfig.sh is NOT sourced within this run script. Sourcing that file
#     is done in gchp.multirun.sh prior to submitting the very first job.
#  4. cap_restart is not deleted; the content is sent to the multirun log and is
#     used to determine if a GCHP run was successful. If it does not exist at the
#     end of the run, or if its content is the same prior to the run, then
#     all jobs will be cancelled

# See SLURM documentation for descriptions of the above settings as well
# as many other settings you may use.

# Define GEOS-Chem log files
gchplog="gchp.log"
multirunlog="multirun.log"
runconfiglog="runConfig.log"

# Define function to cancel all jobs. This is done if cap_restart does
# not exist after a run, or if its date string was not updated
cancel_all_jobs()
{
   msg="Submitted batch job"
   msgs=($(grep -hr "${msg}" ./${multirunlog}))
   for jobid in "${msgs[@]}"
   do
      if [[ ! "${msg}" = *"${jobid}"* ]]; then
         scancel ${jobid}
      fi
   done
}

# Set and source your bashrc. Change this to whatever env file
# used during GCHP compilation. You can copy or adapt sample bashrc
# files located in ./bashrcSamples subdirectory.
BASHRC=./set_your_gchp_env.bashrc
if [ ! -f ${BASHRC} ] 
then
   echo "ERROR: BASHRC environment variable in run script is not set!"
   echo "Copy or adapt a bashrc from the ./bashrcSamples subdirectory"
   echo "prior to running. Use the same environment file used for compilation."
   echo "Exiting."
   exit 1
fi

echo "WARNING: You are using environment settings in ${BASHRC}"
source ${BASHRC}

if [ -e cap_restart ]; then
   cap_rst=$(cat cap_restart)
   echo " "
   echo "Cap_restart prior to run: ${cap_rst}"
else
   cap_rst="none"
   echo " "
   echo "No cap_restart prior to run"
fi

source runConfig.sh > /dev/null


# Monthly diagnostic option automatically updates HISTORY.rc freq/duration
# with number of hours for the month of the run
# Requirements: 
#   1. run segment duration must be 1-month 
#   2. start date must be within the first 28 days of the month
# NOTE: turn on this feature manually here by setting Monthly_Diag to 1. 
#       If on, the diagnostic freq and duration do not need to be manually 
#       set in runConfig.sh
Monthly_Diag=0
if [ ${Monthly_Diag} = "1" ]; then
   if [ -e cap_restart ]; then    
      yr_str=${cap_rst:0:4}
      mo_str=$((10#${cap_rst:4:2}))
   else
      yr_str=${Start_Time:0:4}
      mo_str=$((10#${Start_Time:4:2}))
   fi
   feb_hrs=672
   if [ "$((yr_str%4))" = "0" ]; then
      if [ ! "$((yr_str%100))" = "0" ] | [ "$((yr_str%400))" = "0" ]; then
         feb_hrs=696   
      fi
      fi
   dpm=(744 $feb_hrs 744 720 744 720 744 744 720 744 720 744)
   hrs_str=${dpm[$((mo_str-1))]}
   sed -i "s|common_freq\=.*|common_freq\=\"${hrs_str}0000\"|" ./runConfig.sh
   sed -i "s|common_dur\=.*|common_dur\=\"${hrs_str}0000\"|"   ./runConfig.sh
fi

echo " "
echo "Settings from runConfig.sh: "
echo " "
source ./runConfig.sh

# Only run GCHP if runConfig.sh had no errors
if [[ $? == 0 ]]; then

   NX=$( grep NX GCHP.rc | awk '{print $2}' )
   NY=$( grep NY GCHP.rc | awk '{print $2}' )
   coreCount=$(( ${NX} * ${NY} ))
   # Note that $coreCount can be less than the requested cores in #SBATCH -n
   
   # Use SLURM to distribute tasks across nodes
   planeCount=$(( ${coreCount} / ${SLURM_NNODES} ))
   if [[ $(( ${coreCount} % ${SLURM_NNODES} )) > 0 ]]; then
   	${planeCount}=$(( ${planeCount} + 1 ))
   fi
   
   # Echo info from computational cores to log file for displaying results
   echo " "
   echo "Running GCHP:"
   echo "# of cores: ${coreCount}"
   echo "# of nodes: ${SLURM_NNODES}"
   echo "cores per nodes: ${planeCount}"
   
   # Echo start date
   echo '===> Run started at' `date` >> ${gchplog}
   
   # Run the simulation
   # SLURM_NTASKS is #SBATCH -n and SLURM_NNODES is #SBATCH -N above
   time srun -n ${coreCount} -N ${SLURM_NNODES} -m plane=${planeCount} --mpi=pmi2 ./geos >> ${gchplog}
   
   # Echo end date
   echo '===> Run ended at' `date` >> ${gchplog}
fi

# Check that cap_restart exists. If it does not, cancel all remaining jobs
if [ -f cap_restart ]; then    
   new_cap_rst=$(cat cap_restart)
   echo " "
   echo "cap_restart after run: ${new_cap_rst}" | tee -a ${multirunlog}
   if [ "${new_cap_rst}" = "${cap_rst}" ]; then
      echo " "
      echo "Error: cap_restart did not update to different date!" >> ${multirunlog}
      echo "Cancelling all jobs." >> ${multirunlog}
      cancel_all_jobs
   fi
else
   echo " "
   echo "Error: cap_restart does not exist after GCHP run!" >> ${multirunlog}
   echo "Cancelling all jobs." >> ${multirunlog}
   cancel_all_jobs
fi

# Exit normally
exit 0

