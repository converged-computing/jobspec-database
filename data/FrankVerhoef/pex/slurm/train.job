#!/bin/bash

#SBATCH --partition gpu
#SBATCH --nodes 1
#SBATCH --gpus 1
#SBATCH --job-name Train_PEX
#SBATCH --time 00:15:00
#SBATCH --mem 32G
#SBATCH --output slurm/outputs/train_%A.out

#source ./slurm/.secrets

module purge
module load 2022
module load Anaconda3/2022.05
module load PyTorch/1.12.0-foss-2022a-CUDA-11.7.0

source activate pex

#Copy data dir  to scratch
cp -r data  "$TMPDIR"/data
mkdir "$TMPDIR"/logs
mkdir "$TMPDIR"/checkpoints

srun python -u run/main.py \
        --device cuda  \
	--datadir "$TMPDIR"/data/ \
	--kg-datadir "$TMPDIR"/data/kg_data/ \
        --checkpoint_dir "$TMPDIR"/checkpoints/ \
	--task dialog  \
        --model kg_gen  \
        --kg kg.graph-sm  \
        --batch_size 16  \
        --learning_rate 0.0001 \
        --fixed_lm \
        --traindata msc/msc_dialogue/session_2/train.txt  \
        --validdata msc/msc_dialogue/session_2/valid.txt  \
        --testdata msc/msc_dialogue/session_2/test.txt \
        --train_samples 100  \
        --valid_samples 10 \
        --test_samples 10  \
        --decoder_max 25  \
        --epochs 1  \
        --save test  \
        --loglevel DEBUG  \
        --logdir "$TMPDIR"/logs/  \

cp "$TMPDIR"/logs/* ./logs
cp "$TMPDIR"/checkpoints/* ./checkpoints
