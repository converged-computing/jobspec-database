{
    "method": "baseline",
    "dataset_version": "full",
    "learning_rate": 1e-5,
    "freeze_level": 0,
    "t5_learning_rate": null,
    "num_train_epochs": 30,
    "output_dir": "outputs/templama",
    "wandb_log": true,
    "train_batch_size": 32,
<<<<<<< HEAD
    "ngpu": 1,
    "num_workers": 4,
    "strategy": "ddp",
    "precision": 32,
    "use_profiler": false,
=======
    "checkpoint_dir": "outputs/wmtbaseline_full",
>>>>>>> parent of b59b8ff (before ddp)

    "input_length": 50,
    "output_length": 25,
    "dataset": "templama",
    "prefix": true,
    "model": "google/t5-large-ssm",
    "resume_from_checkpoint": false,
    "wandb_project": "temporal_questions",
    "wandb_run_name": "baseline_2010",
    "mode": "pretrain",
    "use_lr_scheduling": false,
    "check_validation": false,
    "checkpoint_path": "",
    "output_hidden_states": true
}
