#!/bin/bash

#SBATCH --job-name=hc   # nom du job
#SBATCH --account=nkp@a100
#SBATCH -C a100
#SBATCH --gres=gpu:8
#SBATCH --cpus-per-task=16
#SBATCH --exclusive
#SBATCH --time=20:00:00          # temps d'ex√©cution maximum demande (HH:MM:SS) 
#SBATCH --output=log/hc_%j.log  # log file

module load pytorch-gpu/py3/2.1.1
conda activate aa

cd /gpfswork/rech/nkp/uaj64gk/attention_alt/brq-att-alt-exp

python -m torch.distributed.run --nproc_per_node=8 --rdzv_backend c10d --rdzv-endpoint=localhost:0 train.py hparams/hyperconformer.yaml --find_unused_parameters