#!/bin/bash

if [ -z "$1" ]
  then echo "Please provide the name of the game and a log name and a port, e.g.  ./run_gpu breakout basic1 5000 <optional subgoal> <optinal use_distance>"; exit 0
fi

subgoal_index=${4:-12} # a number between 2 to 11 for now, 12 means not use any subgoal
use_distance=${5:-false} #using distance to subgoal as a reward

learn_start=5000 #50000 
steps=50000000
eval_freq=30000 
eval_steps=10000 
prog_freq=10000 
save_freq=10000 
replay_memory=1000000
eps_end=0.1 #0.1
eps_endt=replay_memory

# learn_start=1024
# steps=50000000
# eval_freq=1024
# eval_steps=1024
# prog_freq=1024
# save_freq=1024
# replay_memory=2000
# eps_end=0.1 #0.1
# eps_endt=500000 #replay_memory

ENV=$1
FRAMEWORK="alewrap"
game_path=$PWD"/roms/"
env_params="useRGB=true"
agent="NeuralQLearner"
n_replay=1
netfile="\"convnet_atari3\""
# netfile="\"logs/smoooth_target_q_limited_steps/smoooth_target_q_limited_steps_montezuma_revenge_FULL_Y.t7\""
update_freq=4
actrep=4
discount=0.99
discount_internal=0.99
dynamic_discount=0.99  #starting value for dynamic discounting scheme
seed=$3 #using port as seed
pool_frms_type="\"max\""
pool_frms_size=2
initial_priority="false"

lr=0.00025
agent_type=$2
preproc_net="\"net_downsample_2x_full_y\""
agent_name=$agent_type"_"$1"_FULL_Y"
state_dim=7056
ncols=1
agent_params="use_distance="$use_distance",lr="$lr",ep=1,ep_end="$eps_end",ep_endt="$eps_endt",dynamic_discount="$dynamic_discount",discount="$discount",discount_internal="$discount_internal",hist_len=4,learn_start="$learn_start",replay_memory="$replay_memory",update_freq="$update_freq",n_replay="$n_replay",network="$netfile",preproc="$preproc_net",state_dim="$state_dim",minibatch_size=64,rescale_r=1,ncols="$ncols",bufferSize=512,valid_size=500,target_q=10000,clip_delta=10,min_reward=-1000,max_reward=1000"

gpu=1
random_starts=1  #need to make this 30 later for random starting points for comparison with original DQN
pool_frms="type="$pool_frms_type",size="$pool_frms_size
num_threads=4

mkdir dqn/logs/$agent_type;
args="-framework $FRAMEWORK -exp_folder logs/$agent_type -game_path $game_path -name logs/$agent_type/$agent_name -env $ENV -env_params $env_params -agent $agent -agent_params $agent_params -steps $steps -eval_freq $eval_freq -eval_steps $eval_steps -prog_freq $prog_freq -save_freq $save_freq -actrep $actrep -gpu $gpu -random_starts $random_starts -pool_frms $pool_frms -seed $seed -threads $num_threads -port $3 -subgoal_index $subgoal_index"
echo $args

cd dqn
qlua train_agent.lua $args
